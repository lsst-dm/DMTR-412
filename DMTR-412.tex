% generated from JIRA project LVV
% using template at /opt/hostedtoolcache/Python/3.11.13/x64/lib/python3.11/site-packages/docsteady/templates/tpr.latex.jinja2.
% using docsteady version 3.0.8
% Please do not edit -- update information in Jira instead
\documentclass[DM,STR,toc]{lsstdoc}
\usepackage{geometry}
\usepackage{longtable,booktabs}
\usepackage{enumitem}
\usepackage{arydshln}
\usepackage{attachfile}
\usepackage{array}
\usepackage{dashrule}
\usepackage{pdfpages}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}

\input{meta.tex}

\newcommand{\attachmentsUrl}{https://github.com/\gitorg/\lsstDocType-\lsstDocNum/blob/\gitref/attachments}
\providecommand{\tightlist}{
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\setcounter{tocdepth}{4}

\providecommand{\ul}[1]{\textbf{#1}}


% Pandoc >= 3.2.1 introduces \pandocbounded; fallback for older/custom templates
\providecommand{\pandocbounded}[1]{#1}

\begin{document}

\def\milestoneName{LDM-503-19a (All P1a DM requirements verified)}
\def\milestoneId{}
\def\product{Acceptance}

\setDocCompact{true}

\title{LVV-P117: LDM-503-19a (All P1a DM requirements verified) Test Plan and Report}
\setDocRef{\lsstDocType-\lsstDocNum}
\date{ 2025-09-10 }
\author{ Jeffrey Carlin }

\input{history_and_info.tex}


\setDocAbstract{
This is the test plan and report for
\textbf{ LDM-503-19a (All P1a DM requirements verified)},
an LSST milestone pertaining to the Data Management Subsystem.\\
This document is based on content automatically extracted from the Jira test database on \docDate.
The most recent change to the document repository was on \vcsDate.
}


\maketitle

\section{Introduction}
\label{sect:intro}


\subsection{Objectives}
\label{sect:objectives}

 This DM acceptance test campaign will verify all DM priority 1a
requirements that have not been verified as part of prior testing and
milestones.



\subsection{System Overview}
\label{sect:systemoverview}

 This test campaign is intended to verify that the DM system satisfies
all of the priority 1a requirements outlined in the Data Management
System Requirements (DMSR;~ \href{https://lse-61.lsst.io/}{LSE-61} ),
ensuring that we are progressing toward readiness for LSSTCam on-sky
observing. Additional DMSR requirements (priorities 1b, 2, and 3) will
be verified in later Acceptance Test Campaigns.\\
\strut \\
\textbf{Applicable Documents:}\\
\citeds{LSE-61}: Data Management System (DMS) Requirements\\
\citeds{LDM-503} Data Management Test Plan\\
\citeds{LDM-639}: Data Management Acceptance Test Specification\\
\strut \\
Tests in this campaign will use data products and artifacts from Data
Preview 0.2, which consists of DESC Data Challenge 2 (DC2) simulated
data reprocessed using the LSST Science Pipelines, on-sky data from
auxTel imaging campaigns, precursor data from Subaru+HyperSuprime-Cam
(HSC), and camera test-stand data, when appropriate.


\subsection{Document Overview}
\label{sect:docoverview}

This document was generated from Jira, obtaining the relevant information from the
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testPlan/LVV-P117}{LVV-P117}
~Jira Test Plan and related Test Cycles (
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/testPlayer/LVV-R275}{LVV-R275}
).

Section \ref{sect:intro} provides an overview of the test campaign, the system under test (\product{}),
the applicable documentation, and explains how this document is organized.
Section \ref{sect:testplan} provides additional information about the test plan, like for example the configuration
used for this test or related documentation.
Section \ref{sect:personnel} describes the necessary roles and lists the individuals assigned to them.

Section \ref{sect:overview} provides a summary of the test results, including an overview in Table \ref{table:summary},
an overall assessment statement and suggestions for possible improvements.
Section \ref{sect:detailedtestresults} provides detailed results for each step in each test case.

The current status of test plan \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testPlan/LVV-P117}{LVV-P117} in Jira is \textbf{ Completed }.

\subsection{References}
\label{sect:references}
\renewcommand{\refname}{}
\bibliography{lsst,refs,books,refs_ads,local}


\newpage
\section{Test Plan Details}
\label{sect:testplan}


\subsection{Data Collection}

  Observing is not required for this test campaign.

\subsection{Verification Environment}
\label{sect:hwconf}
  Most testing will be performed using the Rubin Science Platform (RSP)
and the development cluster at the USDF. All tests will use the most
recent available version of the Pipelines.

  \subsection{Entry Criteria}
  None

  \subsection{Exit Criteria}
  None


\subsection{Related Documentation}

Docushare collection where additional relevant documentation can be found:

\begin{itemize}
\item None
\end{itemize}


\subsection{PMCS Activity}

Primavera milestones related to the test campaign:
None


\newpage
\section{Personnel}
\label{sect:personnel}

The personnel involved in the test campaign is shown in the following table.

{\small
\begin{longtable}{p{3cm}p{3cm}p{3cm}p{6cm}}
\hline
\multicolumn{2}{r}{T. Plan \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testPlan/LVV-P117}{LVV-P117} owner:} &
\multicolumn{2}{l}{\textbf{ Jeffrey Carlin } }\\\hline
\multicolumn{2}{r}{T. Cycle \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/testPlayer/LVV-R275}{LVV-R275} owner:} &
\multicolumn{2}{l}{\textbf{
Jeffrey Carlin }
} \\\hline
\textbf{Test Cases} & \textbf{Assigned to} & \textbf{Executed by} & \textbf{Additional Test Personnel} \\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T83}{LVV-T83}
& {\small Jim Bosch } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T85}{LVV-T85}
& {\small Robert Lupton } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2303}{LVV-T2303}
& {\small Leanne Guy } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T33}{LVV-T33}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T38}{LVV-T38}
& {\small Eric Bellm } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T45}{LVV-T45}
& {\small Eric Bellm } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T153}{LVV-T153}
& {\small Leanne Guy } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T88}{LVV-T88}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T89}{LVV-T89}
& {\small Eli Rykoff } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T189}{LVV-T189}
& {\small Leanne Guy } & {\small Leanne Guy } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T197}{LVV-T197}
& {\small Leanne Guy } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T48}{LVV-T48}
& {\small Jim Bosch } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1862}{LVV-T1862}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T115}{LVV-T115}
& {\small Kian-Tat Lim } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T98}{LVV-T98}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2693}{LVV-T2693}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2699}{LVV-T2699}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1847}{LVV-T1847}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1843}{LVV-T1843}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1757}{LVV-T1757}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1841}{LVV-T1841}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1840}{LVV-T1840}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1838}{LVV-T1838}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1836}{LVV-T1836}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1746}{LVV-T1746}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1749}{LVV-T1749}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1750}{LVV-T1750}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1753}{LVV-T1753}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T129}{LVV-T129}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T30}{LVV-T30}
& {\small Leanne Guy } & {\small Leanne Guy } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T29}{LVV-T29}
& {\small Kian-Tat Lim } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2297}{LVV-T2297}
& {\small Leanne Guy } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1612}{LVV-T1612}
& {\small Leanne Guy } & {\small Cristián Silva } &
\begin{minipage}[]{6cm}
\smallskip
{\small Ron Lambert (LSST), Greg Thayer (SLAC) }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1168}{LVV-T1168}
& {\small Leanne Guy } & {\small Cristián Silva } &
\begin{minipage}[]{6cm}
\smallskip
{\small Ron Lambert (LSST), Albert Astudillo (REUNA), Mauricio Rojas
(CTIO/CISS), Raylex, Coriant, Telefonica contractors }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1097}{LVV-T1097}
& {\small Leanne Guy } & {\small Cristián Silva } &
\begin{minipage}[]{6cm}
\smallskip
{\small Ron Lambert (Rubin Observatory), Kian-Tat Lim (Rubin Observatory), Matt
Kollross (NCSA), Tony Johnson (SLAC), Gregg Thayer (SLAC) }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T192}{LVV-T192}
& {\small Leanne Guy } & {\small Leanne Guy } &
\begin{minipage}[]{6cm}
\smallskip
{\small Leanne Guy }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1751}{LVV-T1751}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1752}{LVV-T1752}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T3073}{LVV-T3073}
& {\small Jeffrey Carlin } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T191}{LVV-T191}
& {\small Leanne Guy } & {\small Leanne Guy } &
\begin{minipage}[]{6cm}
\smallskip
{\small Leanne Guy }
\medskip
\end{minipage}
\\ \hline

\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T3155}{LVV-T3155}
& {\small Leanne Guy } & {\small Jeffrey Carlin } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\end{longtable}
}

\newpage

\section{Test Campaign Overview}
\label{sect:overview}

\subsection{Summary}
\label{sect:summarytable}

{\small
\begin{longtable}{p{2cm}cp{2.3cm}p{8.6cm}p{2.3cm}}
\toprule
\multicolumn{2}{r}{ T. Plan \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testPlan/LVV-P117}{LVV-P117}:} &
\multicolumn{2}{p{10.9cm}}{\textbf{ LDM-503-19a (All P1a DM requirements verified) }} & Completed \\\hline
\multicolumn{2}{r}{ T. Cycle \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/testPlayer/LVV-R275}{LVV-R275}:} &
\multicolumn{2}{p{10.9cm}}{\textbf{ LDM-503-19a (All P1a DM requirements verified) }} & Done \\\hline
\textbf{Test Cases} &  \textbf{Ver.} & \textbf{Status} & \textbf{Comment} & \textbf{Issues} \\\toprule
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T83}{LVV-T83}
&
\\
 \hfill Execution & LVV-E3502
& Initial Pass &
\begin{minipage}[]{9cm}
\smallskip
Executed at the USDF using the DP1 butler repository and pipelines
version w\_2025\_27. The notebook containing the test execution is
attached to the Test Report repository as "test\_LVV-T83.ipynb".
\medskip
\end{minipage}
&
   \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T85}{LVV-T85}
&
\\
 \hfill Execution & LVV-E3503
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed using ComCam data as processed by pipelines version
w\_2025\_10. The results are shown in the notebook test\_LVV-T85.ipynb
attached to this document\textquotesingle s repository. Additional
verification of the effectiveness of the crosstalk correction can be
found on the higher-level (OSS and LSR) tests pertaining to the
following Verification Elements:

\begin{itemize}
\tightlist
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1624}{LVV-1624}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1621}{LVV-1621}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1642}{LVV-1642}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1633}{LVV-1633}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1634}{LVV-1634}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-9802}{LVV-9802}
\end{itemize}
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T2303}{LVV-T2303}
&
\\
 \hfill Execution & LVV-E3504
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Will be verified using DP1 data at /repo/dp1.
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T33}{LVV-T33}
&
\\
 \hfill Execution & LVV-E3505
& Pass &
\begin{minipage}[]{9cm}
\smallskip
The python script to execute this test is attached to the Test Report
github repository in scripts/test\_LVV-T33.py.
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T38}{LVV-T38}
&
\\
 \hfill Execution & LVV-E3506
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Executed at the USDF with pipelines version w\_2025\_29, using
LSSTComCam data from DP1. The resulting notebook is attached to the Test
Report repository as "test\_LVV-T38.ipynb".
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T45}{LVV-T45}
&
\\
 \hfill Execution & LVV-E3508
& Pass &
\begin{minipage}[]{9cm}
\smallskip
It was noted during this testing that a mechanism for exporting the
report to PDF would be useful. It is unclear whether such functionality
makes sense within Times Square, but we recommend that it either be
implemented there, or that a capability should be developed elsewhere to
make it straightforward to export a static artifact from the underlying
notebook.
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T153}{LVV-T153}
&
\\
 \hfill Execution & LVV-E3510
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2025\_24 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T153.ipynb."
\medskip
\end{minipage}
&
   \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T88}{LVV-T88}
&
\\
 \hfill Execution & LVV-E3511
& Initial Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed in the RSP at the USDF using pipelines version
w\_2025\_33.
\medskip
\end{minipage}
&
      \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T89}{LVV-T89}
&
\\
 \hfill Execution & LVV-E3512
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Tests performed using ComCam on-sky data at the USDF, using w\_2025\_10
of the science pipelines. See the attached notebook,
"test\_LVV-T89.ipynb", for details.
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T189}{LVV-T189}
&
\\
 \hfill Execution & LVV-E3519
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T197}{LVV-T197}
&
\\
 \hfill Execution & LVV-E3520
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
  \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T48}{LVV-T48}
&
\\
 \hfill Execution & LVV-E3523
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2025\_09 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T48.ipynb."
\medskip
\end{minipage}
&
  \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1862}{LVV-T1862}
&
\\
 \hfill Execution & LVV-E3524
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed using ComCam data as processed by pipelines version
w\_2025\_10. The results are shown in the notebook test\_LVV-T1862.ipynb
attached to this document\textquotesingle s repository.
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T115}{LVV-T115}
&
\\
 \hfill Execution & LVV-E3525
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Executed at the USDF using pipelines version w\_2025\_19, the ci\_cpp
package, and the "testdata\_latiss\_cpp" dataset.
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T98}{LVV-T98}
&
\\
 \hfill Execution & LVV-E3528
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed at the USDF (from both the command line and the RSP) using
pipelines version w\_2025\_33.\\
\strut \\
For this test, we demonstrate that these logical groupings can be
applied in butler queries via the "where" clause. These same query
constraints can be passed to pipetasks to apply the selections for
processing of data.
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T2693}{LVV-T2693}
&
\\
 \hfill Execution & LVV-E3530
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Executed at the USDF using LSSTComCam data processed with pipelines
version `w\_2025\_16`. See the attached notebook,
"test\_LVV-T2693.ipynb", for details.
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T2699}{LVV-T2699}
&
\\
 \hfill Execution & LVV-E3531
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Executed at the USDF using LSSTComCam data processed with pipelines
version `w\_2025\_16`. See the attached notebook,
"test\_LVV-T2699.ipynb", for details.
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1847}{LVV-T1847}
&
\\
 \hfill Execution & LVV-E3537
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2025\_27 in the RSP
Notebook aspect at the USDF. Because this test concerns a threshold
calculated in LVV-T1841, the two tests were executed together.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1841\_1847.ipynb."
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1843}{LVV-T1843}
&
\\
 \hfill Execution & LVV-E3540
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Tests performed using ComCam on-sky data at the USDF, using w\_2025\_10
of the science pipelines. See the attached notebook,
"test\_LVV-T1843.ipynb", for details.
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1757}{LVV-T1757}
&
\\
 \hfill Execution & LVV-E3541
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1757.ipynb."
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1841}{LVV-T1841}
&
\\
 \hfill Execution & LVV-E3543
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2025\_27 in the RSP
Notebook aspect at the USDF. Because this test concerns a threshold for
LVV-T1847, the two tests were executed together.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1841\_1847.ipynb."
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1840}{LVV-T1840}
&
\\
 \hfill Execution & LVV-E3544
& Pass w/ Deviation &
\begin{minipage}[]{9cm}
\smallskip
Executed at the USDF with pipelines version w\_2025\_28, using
LSSTComCam data from DP1. The resulting notebook is attached to the Test
Report repository as "test\_LVV-T1840.ipynb".
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1838}{LVV-T1838}
&
\\
 \hfill Execution & LVV-E3546
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed at the USDF RSP, using w\_2025\_33. The resulting notebook
is attached to this test repository as "test\_LVV-T1838.ipynb".
\medskip
\end{minipage}
&
   \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1836}{LVV-T1836}
&
\\
 \hfill Execution & LVV-E3548
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1836.ipynb."\\
\strut \\
To allow for some flexibility in changing the method of calculating this
metric, it has not yet been implemented within `analysis\_tools`. Before
future large-scale data processing campaigns, this metric will be
incorporated into the `analysis\_tools` tasks and pipelines that are
executed as part of data release processing.
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1746}{LVV-T1746}
&
\\
 \hfill Execution & LVV-E3550
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1746.ipynb."
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1749}{LVV-T1749}
&
\\
 \hfill Execution & LVV-E3551
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1749.ipynb."
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1750}{LVV-T1750}
&
\\
 \hfill Execution & LVV-E3552
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_37 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1750\_1753.ipynb."
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1753}{LVV-T1753}
&
\\
 \hfill Execution & LVV-E3555
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_37 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1750\_1753.ipynb."
\medskip
\end{minipage}
&
     \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T129}{LVV-T129}
&
\\
 \hfill Execution & LVV-E3558
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test performed in the RSP using public Data Preview 1 (DP1) data
products, which are based on on-sky LSSTComCam data. The notebook is
attached to this test repository as "test\_LVV-T129.ipynb".
\medskip
\end{minipage}
&
      \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T30}{LVV-T30}
&
\\
 \hfill Execution & LVV-E3559
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
   \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T29}{LVV-T29}
&
\\
 \hfill Execution & LVV-E3560
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T29.ipynb."
\medskip
\end{minipage}
&
   \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T2297}{LVV-T2297}
&
\\
 \hfill Execution & LVV-E3561
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1612}{LVV-T1612}
&
\\
 \hfill Execution & LVV-E3647
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
   \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1168}{LVV-T1168}
&
\\
 \hfill Execution & LVV-E3648
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1097}{LVV-T1097}
&
\\
 \hfill Execution & LVV-E3649
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T192}{LVV-T192}
&
\\
 \hfill Execution & LVV-E3651
& Pass &
\begin{minipage}[]{9cm}
\smallskip
None
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1751}{LVV-T1751}
&
\\
 \hfill Execution & LVV-E3734
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1751\_AM1\_AM2.ipynb."
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T1752}{LVV-T1752}
&
\\
 \hfill Execution & LVV-E3735
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1752\_AF1\_AF2.ipynb."
\medskip
\end{minipage}
&
    \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T3073}{LVV-T3073}
&
\\
 \hfill Execution & LVV-E3743
& Pass &
\begin{minipage}[]{9cm}
\smallskip
This test was executed at the USDF with science pipelines version
w\_2024\_43.
\medskip
\end{minipage}
&
   \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T191}{LVV-T191}
&
\\
 \hfill Execution & LVV-E3750
& Pass &
\begin{minipage}[]{9cm}
\smallskip
The cluster was moved to the summit facility from the base and is
currently in use in commissioning. There is no specification on what
should be installed but to provide a useful system, we have ensured that
the science pipelines are in stalled and condor as a batch system is
available. The verification submits a batch job to run step\#1 of
nightly validation on some early ComCam images

The batch submission was successful. Aspects of the processing failed
and were correctly reported by the batch system as failures.

This test does not test the processing, only the batch system on the
commissioning cluster
\medskip
\end{minipage}
&
          \\\hline
  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/v2/testCase/LVV-T3155}{LVV-T3155}
&
\\
 \hfill Execution & LVV-E4013
& Pass &
\begin{minipage}[]{9cm}
\smallskip
Test executed with science pipelines version w\_2025\_24 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T3155.ipynb."
\medskip
\end{minipage}
&
    \\\hline
     \caption{Test Campaign Summary}
\label{table:summary}
\end{longtable}
}

\subsection{Overall Assessment}
\label{sect:overallassessment}

In this test campaign, we have successfully verified 27 unique
requirements from \citeds{LSE-61} via the execution of 41 Test Cases (38 of which
passed, 1 that passed with deviation, and 2 that initially passed). Of
these requirements, 26 are of priority 1a, and 1 is priority 2.\\
\strut \\
The test that was granted a "pass with deviation" will result in a new
metric being added to track sky brightness errors, as it was determined
that the existing metric is not useful in its current form. The two
tests that were "initial passes" were partially verified, but have some
portions that cannot be verified until additional hardware is in place.

\subsection{Recommended Improvements}
\label{sect:recommendations}

None

\newpage
\section{Detailed Test Results}
\label{sect:detailedtestresults}

\subsection{Test Cycle LVV-R275 }

Open test cycle {\it \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/testPlayer/LVV-R275}{LDM-503-19a (All P1a DM requirements verified)}} in Jira.

Test Cycle name: LDM-503-19a (All P1a DM requirements verified)\\
Status: Done

Test campaign supporting milestone LDM-503-19a -\/- all P1a requirements
verified.

\subsubsection{Software Version/Baseline}
Not provided.

\subsubsection{Configuration}
Not provided.

\subsubsection{Test Cases in LVV-R275 Test Cycle}

\paragraph{ LVV-T83 - Verify implementation of Bad Pixel Map }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Defined}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T83}{\textit{ LVV-T83 } }
test case in Jira.

Verify that the DMS can produce a map of detector pixels that suffer
from pathologies, and that these pathologies are encoded in at least
32-bit values.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Initial Pass }\\
Final comment:\\Executed at the USDF using the DP1 butler repository and pipelines
version w\_2025\_27. The notebook containing the test execution is
attached to the Test Report repository as "test\_LVV-T83.ipynb".



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3502-1243142026:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3502-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Interrogate the calibRegistry for the metadata associated with a bad
pixel map, where the validity range contains the date of interest.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A bad pixel map for the requested date has been returned.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The following code was used to query for defect masks (the name for the
bad pixel mask datasets), and select the first result:\\
\strut \\
\# Query for all defects datasets in the collection:\\
defects\_refs =
butler.query\_datasets(\textquotesingle defects\textquotesingle)\\
\strut \\
\# Select the first from the list:\\
defects0 = butler.get(\textquotesingle defects\textquotesingle,
dataId=defects\_refs{[}0{]}.dataId)


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3502-2 & Step Execution Status: \textbf{ Initial Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check that the bad pixel pathologies are encoded as at least 32-bit
values, and that the various pathologies are represented by different
encoding.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Bad pixel values can be decoded to determine their pathologies using
their 32-bit values.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, it was demonstrated that the pixels flagged as
"BAD" can be determined from the `defects` dataset. However, the
encoding is a simple boolean (True/False) for "BAD", rather than the
required 32-bit encoding of different pathologies. We grant this test an
"Initial Pass" status, pending the improvement of the bad pixel masks to
encode more detailed status about each bad pixel.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T85 - Verify implementation of Crosstalk Correction Matrix }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Defined}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T85}{\textit{ LVV-T85 } }
test case in Jira.

Verify that the DMS can generate a cross-talk correction matrix from
appropriate calibration data.\\
Verify that the DMS can measure the effectiveness of the cross-talk
correction matrix.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed using ComCam data as processed by pipelines version
w\_2025\_10. The results are shown in the notebook test\_LVV-T85.ipynb
attached to this document\textquotesingle s repository. Additional
verification of the effectiveness of the crosstalk correction can be
found on the higher-level (OSS and LSR) tests pertaining to the
following Verification Elements:

\begin{itemize}
\tightlist
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1624}{LVV-1624}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1621}{LVV-1621}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1642}{LVV-1642}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1633}{LVV-1633}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-1634}{LVV-1634}
\item
  \href{https://rubinobs.atlassian.net/browse/LVV-9802}{LVV-9802}
\end{itemize}



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3503-1243142027:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3503-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify an appropriate calibration dataset that can be used to derive
the crosstalk correction matrix.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
We use the crosstalk coefficients that were measured by the camera team
in the lab and ingested as a calibration data product into the butler.
The creation and ingestion of the ComCam crosstalk curated calibrations
was done on Jira ticket
\href{https://rubinobs.atlassian.net/browse/DM-45614}{DM-45614}.\\
\strut \\
In the attached notebook, we retrieve a crosstalk dataset from the
butler via the following:\\
\strut \\
INSTRUMENT = "LSSTComCam"\\
COLLECTION = "LSSTComCam/runs/DRP/DP1/w\_2025\_10/DM-49359"\\
butler = Butler("/repo/main")\\
query =
butler.query\_datasets(\textquotesingle postISRCCD\textquotesingle,
collections=COLLECTION)\\
\strut \\
\# Select the first image and its crosstalk object:\\
postisrccd = butler.get(query{[}1{]})\\
crosstalk = butler.get("crosstalk", collections=COLLECTION,
dataId=query{[}1{]}.dataId)


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3503-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the crosstalk correction matrix is produced and persisted.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A correction matrix quantifying what fraction of the signal detected in
any given amplifier on each sensor in the focal plane appears in any
other amplifier.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
As seen in the attached notebook, we retrieved the crosstalk object and
plotted its values.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3503-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Apply the crosstalk correction to images, and confirm that the
correction is performing as expected.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A noticeable difference between images before and after applying the
correction.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The attached notebook demonstrates applying the crosstalk correction to
an image, then comparing the image before and after correction. The
correction has a noticeable effect, and the expected behavior where a
bright star\textquotesingle s correction appears in adjacent amplifiers
is observed.\\
\strut \\
This test has achieved a PASS via demonstration of well-formed crosstalk
calibration objects that achieve their goal when applied to images.\\
\strut \\


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T2303 - Verify Image Archive }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2303}{\textit{ LVV-T2303 } }
test case in Jira.

Verify that all image Data Products produced by the DMS (Processed
Science Exposures, Calibration Exposures, Coadded Exposures) are either
archived, or be capable of being recreated on-demand from inputs and
processing provenance.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Will be verified using DP1 data at /repo/dp1.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3504-1243142028:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3504-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
By listing calibration objects and ancillary files (e.g., reference
catalogs), demonstrate that they have been retained. Examine some
examples from the various types, and confirm that they are well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Demonstration that calibration and ancillary data products have been
retained and are available for use.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
DP1 data are archived at the USDF in repository /repo/dp1, collection
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260. Here we will demonstrate via
queries that the datasets are present in this repo.\\
\strut \\
\textbf{Raw images:}\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$\\
\strut ~butler query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 raw \textbar{} wc\\
\strut ~~16129~~161270 2402925\\
\textbf{Reference catalog (The Monster):}\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$\\
\strut ~butler query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 the\_monster\_20250219
-\/-limit 1000000 \textbar{} wc\\
\strut ~131076~~524296 13500624\\
\textbf{Photon transfer curve (ptc):}\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 ptc -\/-limit 1000000
\textbar{} wc\\
\strut ~ ~ ~22 ~ ~~100~ ~~2682\\
\textbf{Bias:}\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 bias -\/-limit 1000000
\textbar{} wc\\
\strut ~ ~ ~31 ~ ~~145~ ~~3917\\
\textbf{Darks:}\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 dark -\/-limit 1000000
\textbar{} wc\\
31 145 3917\\
\strut \\
Examine some of the files to confirm they\textquotesingle re
well-formed. First open an ipython session in a terminal, then:\\
\strut \\
In {[}1{]}: from lsst.daf.butler import Butler\\
In {[}\textbf{2}{]}: butler =
Butler(\textquotesingle/repo/dp1\textquotesingle,
collections={[}\textquotesingle LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260\textquotesingle{]})\\
In {[}\textbf{3}{]}:~refs =
butler.query\_datasets(\textquotesingle bias\textquotesingle)\\
In {[}\textbf{4}{]}:~bias = butler.get(refs{[}0{]})\\
In {[}\textbf{5}{]}:~bias\\
Out{[}\textbf{5}{]}:~\textless lsst.afw.image.\_exposure.ExposureF at
0x7f9898f98830\textgreater{}\\
In {[}\textbf{6}{]}:~bias.getBBox()\\
Out{[}\textbf{6}{]}:~Box2I(corner=Point2I(0, 0),
dimensions=Extent2I(4072, 4000))\\
In {[}7{]}: import numpy as np\\
In {[}\textbf{8}{]}:~np.nanmedian(bias.image.array)\\
Out{[}\textbf{8}{]}:~np.float32(-0.030564716)\\
In {[}\textbf{9}{]}:~np.nanstd(bias.image.array)\\
Out{[}\textbf{9}{]}: np.float32(51.034676)\\
\strut \\
We see that the bias has an ExposureF object containing a 4072x4000
image, with median pixel value of roughly zero, as expected for a
bias.\\
\strut \\
In {[}\textbf{10}{]}: refs =
butler.query\_datasets(\textquotesingle ptc\textquotesingle)\\
In {[}\textbf{11}{]}: ptc = butler.get(refs{[}0{]})\\
In {[}\textbf{12}{]}:~ptc\\
Out{[}\textbf{12}{]}:~\textless lsst.ip.isr.ptcDataset.PhotonTransferCurveDataset
at 0x7f98835e7b60\textgreater{}\\
In {[}\textbf{16}{]}:~ptc.ampNames\\
Out{[}\textbf{16}{]}:~\\
{[}\textquotesingle C10\textquotesingle,\\
\strut ~\textquotesingle C11\textquotesingle,\\
\strut ~\textquotesingle C12\textquotesingle,\\
\strut ~\textquotesingle C13\textquotesingle,\\
\strut ~\textquotesingle C14\textquotesingle,\\
\strut ~\textquotesingle C15\textquotesingle,\\
\strut ~\textquotesingle C16\textquotesingle,\\
\strut ~\textquotesingle C17\textquotesingle,\\
\strut ~\textquotesingle C07\textquotesingle,\\
\strut ~\textquotesingle C06\textquotesingle,\\
\strut ~\textquotesingle C05\textquotesingle,\\
\strut ~\textquotesingle C04\textquotesingle,\\
\strut ~\textquotesingle C03\textquotesingle,\\
\strut ~\textquotesingle C02\textquotesingle,\\
\strut ~\textquotesingle C01\textquotesingle,\\
\strut ~\textquotesingle C00\textquotesingle{]}\\
In
{[}\textbf{18}{]}:~ptc.rawMeans{[}\textquotesingle C00\textquotesingle{]}\\
Out{[}\textbf{18}{]}:~\\
array({[}~~477.57498519, ~~501.49237042, ~~524.90948954,
~~573.17176074,\\
\strut ~ ~ ~ ~ ~596.76702405, ~~644.59139216, ~~668.02285215,
~~716.23392347,\\
\strut ~ ~ ~ ~ ~763.24476975, ~~811.23738884, ~~859.54939063,
~~906.64399373,\\
\strut ~ ~ ~ ~
~955.51931685,~~1002.10624225,~~1073.70054479,~~1145.25495219,\\
\strut ~ ~ ~
~~1217.23845867,~~1288.23956527,~~1359.81858928,~~1431.82314398,\\
\strut ~ ~ ~
~~1526.58121014,~~1598.74978101,~~1694.24779853,~~1813.49611823,\\
\strut ~ ~ ~
~~1909.33584092,~~2027.05957533,~~2147.44780151,~~2266.2842281 ,\\
\strut ~ ~ ~
~~2410.70133852,~~2552.78638784,~~2719.77980282,~~2864.07477037,\\
\strut ~ ~ ~
~~3055.03274106,~~3220.66074203,~~3409.42372835,~~3627.26838956,\\
\strut ~ ~ ~
~~3843.16076696,~~4054.48361054,~~4317.80036862,~~4557.32071885,\\
\strut ~ ~ ~
~~4841.25384465,~~5126.05976276,~~5440.94992003,~~5748.07510771,\\
\strut ~ ~ ~
~~6103.33323664,~~6460.96708419,~~6841.90397705,~~7252.25422254,\\
\strut ~ ~ ~
~~7678.92116404,~~8134.10338573,~~8632.14541315,~~9135.05460446,\\
\strut ~ ~ ~ ~~9679.13393687, 10260.602575~~, 10875.75470457,
11522.94852991,\\
\strut ~ ~ ~ ~12216.72837329, 12927.88795107, 13719.11391032,
14531.25388077,\\
\strut ~ ~ ~ ~15377.98879657, 16321.97483095, 17287.47766898,
18323.39558752,\\
\strut ~ ~ ~ ~19421.33133832, 20556.0394046 , 21768.06500356,
23100.1279195 ,\\
\strut ~ ~ ~ ~24474.0624525 , 25943.35062 ~~, 27460.23492076,
29080.34980963,\\
\strut ~ ~ ~ ~30847.10709202, 32669.31365131, 34646.53475428,
36684.81383157,\\
\strut ~ ~ ~ ~38878.02287999, 41209.17659742, 43672.70153375,
46254.6859343 ,\\
\strut ~ ~ ~ ~49013.94299117, 51927.32674726, 55029.64463467,
58275.2070528 ,\\
\strut ~ ~ ~ ~61765.78259758, 65461.33012346, 69356.02744116,
73410.62451029,\\
\strut ~ ~ ~ ~77697.41695487, 82098.44878214, 85549.37710251,
87751.70902655,\\
\strut ~ ~ ~ ~88826.46248014, 89393.47497459, 89481.88443297,
89659.39305075,\\
\strut ~ ~ ~ ~89740.31328478, 89770.10853101, 89759.45925516,
89816.45895709{]})\\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3504-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
List `visit\_image` and `deep\_coadd` exposures to demonstrate that they
have been retained. Examine some examples, and confirm that they are
well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
窶汽emonstration that 窶久isit and coadd images are present in the
archive.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\textbf{visit\_images:}\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 visit\_image -\/-limit
1000000 \textbar{} wc\\
15976 143766 2731556\textbf{\hfill\break
deep\_coadds:}\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 deep\_coadd -\/-limit 1000000
\textbar{} wc\\
2648 18522 362504\textbf{\hfill\break
}\\
Open an ipython terminal and inspect sample images:\\
\strut \\
In {[}1{]}:~from lsst.daf.butler import Butler\\
In {[}2{]}: butler = Butler(\textquotesingle/repo/dp1\textquotesingle,
collections={[}\textquotesingle LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260\textquotesingle{]})\\
In {[}\textbf{3}{]}: refs =
butler.query\_datasets(\textquotesingle visit\_image\textquotesingle)\\
In {[}\textbf{5}{]}: vis\_im = butler.get(refs{[}0{]})\\
In {[}\textbf{6}{]}:~vis\_im\\
Out{[}\textbf{6}{]}:~\textless lsst.afw.image.\_exposure.ExposureF at
0x7f2816f392f0\textgreater{}\\
\strut \\
In {[}\textbf{7}{]}:~vis\_im.getBBox()\\
Out{[}\textbf{7}{]}:~Box2I(corner=Point2I(0, 0),
dimensions=Extent2I(4072, 4000))\\
\strut \\
In {[}8{]}: import numpy as np\\
\strut \\
In {[}\textbf{9}{]}:~np.nanmedian(vis\_im.image.array)\\
Out{[}\textbf{9}{]}:~np.float32(3.851969)\\
\strut \\
In {[}\textbf{10}{]}:~np.nanstd(vis\_im.image.array)\\
Out{[}\textbf{10}{]}: np.float32(218.97614)\\
\strut \\
In {[}\textbf{11}{]}: refs =
butler.query\_datasets(\textquotesingle deep\_coadd\textquotesingle)\\
In {[}\textbf{12}{]}: deepcoadd\_im = butler.get(refs{[}0{]})\\
In {[}\textbf{13}{]}:~deepcoadd\_im\\
Out{[}\textbf{13}{]}:~\textless lsst.afw.image.\_exposure.ExposureF at
0x7f27de353830\textgreater{}\\
\strut \\
In {[}\textbf{14}{]}:~deepcoadd\_im.getWcs()\\
Out{[}\textbf{14}{]}:~\\
FITS standard SkyWcs:\\
Sky Origin: (94.0540540541, -24.5454545455)\\
Pixel Origin: (14999, 14999)\\
Pixel Scale: 0.2 arcsec/pixel\\
\strut \\
In {[}\textbf{15}{]}:~deepcoadd\_im.getBBox()\\
Out{[}\textbf{15}{]}:~Box2I(corner=Point2I(-200, 5800),
dimensions=Extent2I(3400, 3400))\\
\strut \\
In {[}\textbf{16}{]}:~np.nanmedian(deepcoadd\_im.image.array)\\
Out{[}\textbf{16}{]}:~np.float32(2.913166)\\
\strut \\
In {[}\textbf{17}{]}:~np.nanstd(deepcoadd\_im.image.array)\\
Out{[}\textbf{17}{]}: np.float32(1393.8081)\\
\strut \\
The sample images seem to be well-formed, with metadata such as a
bounding box and WCS, and have reasonable pixel values.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3504-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
For an intermediate data product that is not retained for data releases
(e.g., `preliminary\_visit\_image`), identify appropriate inputs, and
run pipeline tasks to recreate that data product.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Image data products resulting from the executed processing are present
and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Because the archived DP1 data products are in a read-only butler (at
/repo/dp1), we demonstrate this capability based on the DP1 processing
that is in /repo/main. The initial ISR processing steps to go from raw
images to `preliminary\_visit\_image`s (which are not retained in DP1,
and thus must be reproduced) can be run as follows:\\
\strut \\
pipetask run -j 12 -b /repo/main -i
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 -p
\$DRP\_PIPE\_DIR/pipelines/LSSTComCam/DRP-v2.yaml\#step1a-single-visit-detectors
-o u/jcarlin/dp1\_repro\_pvi -\/-instrument lsst.obs.lsst.LsstComCam
-\/-register-dataset-types -d
"skymap=\textquotesingle lsst\_cells\_v1\textquotesingle{} AND visit IN
(2024121100609, 2024121100610, 2024121100611)" 2\textgreater\&1
\textbar{} tee dp1\_repro\_pvi\_test.log\\
\strut \\
After that pipeline task has successfully executed, one can open
ipython, then execute the following to load the
`preliminary\_visit\_image` and examine it:\\
\strut \\
from lsst.daf.butler import Butler\\
butler = Butler(\textquotesingle/repo/main\textquotesingle,
collections={[}\textquotesingle u/jcarlin/dp1\_repro\_pvi\textquotesingle{]})\\
\strut \\
\% load dataset references from the output collection containing the
data that was just processed:\\
In {[}\textbf{12}{]}:~refs =
butler.query\_datasets(\textquotesingle preliminary\_visit\_image\textquotesingle,
collections={[}\textquotesingle u/jcarlin/dp1\_repro\_pvi/20250715T193639Z\textquotesingle{]})\\
\strut \\
In {[}\textbf{13}{]}:~len(refs)\\
Out{[}\textbf{13}{]}: 27\\
\strut \\
\% There are 27 datasets because we processed 3 visits, each of which
contains 9 detectors.\\
\strut \\
In {[}\textbf{14}{]}:~pvi = butler.get(refs{[}13{]})\\
\strut \\
In {[}\textbf{15}{]}:~pvi\\
Out{[}\textbf{15}{]}: \textless lsst.afw.image.\_exposure.ExposureF at
0x7f58baa81930\textgreater{}\\
\strut \\
In {[}\textbf{18}{]}:~pvi.getBBox()\\
Out{[}\textbf{18}{]}: Box2I(corner=Point2I(0, 0),
dimensions=Extent2I(4072, 4000))\\
\strut \\
We see that the image is an ExposureF object with the expected extent,
and thus conclude that the processing recreated the expected
intermediate data products.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T33 - Verify implementation of Raw Science Image Metadata }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T33}{\textit{ LVV-T33 } }
test case in Jira.

Verify successful ingestion of raw data and that image metadata is
present and queryable.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\The python script to execute this test is attached to the Test Report
github repository in scripts/test\_LVV-T33.py.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3505-1243142029:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3505-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify (or gather) a dataset of raw science images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test, we use weekly Science Pipelines version `w\_2025\_33` at
the USDF, examining recently gathered LSSTCam imaging data.\\
\strut \\
In particular, these data are at `/repo/embargo`, in collection
`LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202`.\\
\strut \\
In the attached script, we instantiate a butler pointing to that
repo/collection:\\
\strut \\
from lsst.daf.butler import Butler\\
\strut \\
repo = \textquotesingle/repo/embargo\textquotesingle{}\\
collection =
\textquotesingle LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202\textquotesingle{}\\
butler = Butler(repo, collections=collection)\\
\strut \\
The attached script queries the butler for datasetRefs of raw images:\\
query = butler.query\_datasets(\textquotesingle raw\textquotesingle,
collections=COLLECTION, with\_dimension\_records=True)\\
\strut \\
It then retrieves a selected raw image via the following:\\
\strut \\
raw\_img = butler.get(query{[}0{]})


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3505-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that time of exposure start/end, site metadata, telescope
metadata, and camera metadata are stored in DMS system.\\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Raw image data contain the required metadata.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The attached script also extracts the metadata attached to the image.
The following code extracts the metadata and prints each entry to the
screen:\\
\strut \\
md\_dict = md.toDict()\\
for item in md\_dict.items():\\
\strut ~ ~ print(item)\\
\strut \\

\begin{verbatim}
('SIMPLE', True)
('EXTEND', True)
('BINX', 1)
('BINY', 1)
('CCDGAIN', 1.0)
('CCDNOISE', 10.0)
('DETSIZE', '[1:4096,1:4004]')
('DATE', '2025-07-05T05:19:01.890')
('MJD', 60861.22154965252)
('IMGTYPE', 'OBJECT')
('DATE-OBS', '2025-07-05T05:18:30.962')
('MJD-OBS', 60861.221191691235)
('DATE-TRG', '2025-07-05T05:19:01.883')
('MJD-TRG', 60861.221549576614)
('OBSID', 'MC_O_20250704_000488')
('DATE-BEG', '2025-07-05T05:18:30.962')
('MJD-BEG', 60861.221191691235)
('DATE-END', '2025-07-05T05:19:01.892')
('MJD-END', 60861.22154967161)
('BUNIT', 'adu')
('TIMESYS', 'TAI')
('GROUPID', '2025-07-05T05:15:40.802')
('INSTRUME', 'lsstCam')
('TELESCOP', 'Simonyi Survey Telescope')
('OBS-LONG', -70.749417)
('OBS-LAT', -30.244639)
('OBS-ELEV', 2663.0)
('OBSGEO-X', 1818938.94)
('OBSGEO-Y', -5208470.95)
('OBSGEO-Z', -3195172.08)
('RA', 318.40614409975007)
('DEC', -14.460390741638887)
('RASTART', 318.40704480633815)
('DECSTART', -14.460507389707633)
('RAEND', 318.4070442159996)
('DECEND', -14.460504916972123)
('ROTPA', 77.99440026788089)
('ROTCOORD', 'sky')
('HASTART', -1.7716292227853014)
('ELSTART', 60.8718332734214)
('AZSTART', 62.8679456532809)
('AMSTART', 1.1444389967944493)
('HAEND', -1.7629832636372795)
('ELEND', 60.9712437867589)
('AZEND', 62.7105607584743)
('AMEND', 1.143336566822946)
('TRACKSYS', 'RADEC')
('RADESYS', 'ICRS')
('FOCUSZ', -3.202469781193729)
('OBJECT', 'lowdust')
('VIGNETTE', 'NO')
('VIGN_MIN', 'NO')
('TESTTYPE', 'OBJECT')
('CAMCODE', 'MC')
('CONTRLLR', 'O')
('DAYOBS', '20250704')
('SEQNUM', 488)
('PROGRAM', 'BLOCK-365')
('REASON', 'pairs_zy_33.0')
('CURINDEX', 1)
('MAXINDEX', 1)
('TSTAND', 'TMAMCv1_SUM')
('IMAGETAG', 'd4cb3a7a4bce57ea')
('OBSANNOT', 'pair_33, zy, b')
('CCD_MANU', 'E2V')
('CCD_TYPE', 'CCD250')
('CCDSLOT', 'S21')
('RAFTBAY', 'R12')
('FIRMWARE', '3139500e')
('PLATFORM', 'lsstcam')
('CONTNUM', '18edfb51')
('DAQVERS', 'R5-V13.4 2025-03-20T16:46:35Z (811f588b)')
('DAQPART', 'camera')
('DAQFOLD', 'raw')
('SEQFILE', 'FP_E2V_3s_cp_v1.seq')
('SEQNAME', 'FP_E2V_3s_cp_v1.seq')
('SEQCKSUM', '810001961')
('LSST_NUM', 'E2V-CCD250-287')
('CCD_SERN', '15483-17-04')
('REBNAME', 'LCA-13574-068')
('RAFTNAME', 'LCA-11021_RTM-009')
('FPVERS', '1.3.1-SNAPSHOT')
('IHVERS', '1.1.11')
('FILTBAND', 'z')
('FILTER', 'z_20')
('FILTPOS', 194.0)
('FILTSLOT', 4)
('EXPTIME', 30.0)
('DARKTIME', 30.9295)
('SHUTTIME', 30.000145196914673)
('AIRTEMP', 11.699999809265137)
('PRESSURE', 74405.0)
('HUMIDITY', 11.975000381469727)
('WINDSPD', 9.257399559020996)
('WINDDIR', 18.144826889038086)
('SEEING', 0.97889244556427)
('HEADVER', 2)
('FILENAME', 'MC_O_20250704_000488_R12_S21.fits')
('STUTTER ROWS', 0)
('STUTTER DELAY', 0.0)
('STUTTER NSHIFTS', 0)
('XTENSION', 'BINTABLE')
('BITPIX', 8)
('NAXIS', 2)
('NAXIS1', 0)
('NAXIS2', 0)
('PCOUNT', 0)
('GCOUNT', 1)
('TFIELDS', 0)
('COMMENT', '---- Checksums ----')
('CHECKSUM', 'iGXHjDVGiDVGiDVG')
('EXTNAME', 'REB_COND')
('TEMP1', 3.0625)
('TEMP2', 3.4375)
('TEMP3', -10.9375)
('TEMP4', -7.125)
('TEMP5', -8.3125)
('TEMP6', -7.0)
('TEMP7', -9.875)
('TEMP8', -7.125)
('TEMP9', -8.4375)
('TEMP10', -6.9375)
('ATEMPU', -20.8918)
('ATEMPL', -18.276)
('CCDTEMP', -100.862)
('RTDTEMP', -106.682)
('TEMPAVG', -6.94886)
('DIGPS_V', 5.55)
('DIGPS_I', 713.75)
('ANAPS_V', 7.975)
('ANAPS_I', 554.5)
('CLKHPS_V', 15.4)
('CLKHPS_I', 103.167)
('CLKLPS_V', 13.725)
('CLKLPS_I', 54.5)
('ODPS_V', 38.925)
('ODPS_I', 72.5833)
('HTRPS_V', 2.47346)
('HTRPS_W', 0.405001)
('PCKU_V', 2.04396)
('PCKL_V', -6.0)
('SCKU_V', 3.55311)
('SCKL_V', -5.75092)
('RGU_V', 4.99634)
('RGL_V', -4.98168)
('ODV', 22.2686)
('OGV', -3.67033)
('RDV', 10.5031)
('GDV', 26.0024)
('GDP', 26.0)
('RDP', 10.5)
('OGP', -3.75)
('ODP', 22.3)
('CSGATEP', 1.0)
('SCK_LOWP', -5.75)
('SCK_HIP', 3.55)
('PCK_LOWP', -6.0)
('PCK_HIP', 2.0)
('RG_LOWP', -4.99)
('RG_HIP', 5.01)
('AP0_RC', 2)
('AP1_RC', 2)
('AP0_GAIN', 0)
('AP1_GAIN', 0)
('AP0_CLMP', 0)
('AP1_CLMP', 0)
('AP0_AF1', 0)
('AP1_AF1', 0)
('AP0_TM', 0)
('AP1_TM', 0)
('HVBIAS', 'ON')
('POWER', 15.5266)
('DIGVB', 6.35)
('DIGIB', 738.92)
('DIGVA', 6.07904)
('DIGIA', 737.273)
('DIGVS', 6.04205)
('ANAVB', 9.025)
('ANAIB', 543.79)
('ANAVA', 8.27552)
('ANAIA', 559.116)
('ANAIS', 8.4363)
('ODVB', 40.5)
('ODIB', 77.8466)
('ODVA', 39.1194)
('ODVA2', 39.025)
('ODIA', 75.1178)
('ODVS', 38.9134)
('CKHVB', 16.225)
('CKHIB', 96.854)
('CKHVA', 15.386)
('CKHIA', 41.82)
('CKHVS', 15.492)
('CKLVB', 14.35)
('CKLIB', 40.25)
('CKLVA', 0.60192)
('CKLV2', 13.7481)
('CKLIA', 39.75)
('CKLVS', 13.9615)
('HTRVB', 12.325)
('HTRIB', 122.924)
('HTRVA', 11.7851)
('HTRIA', 105.549)
('HTRVAS', 11.778)
('BSSVBS', 50.1)
('BSSIBS', 0.077559)
('DATASUM', '0')
('HIERARCH ASTRO METADATA FIX MODIFIED', False)
('HIERARCH ASTRO METADATA FIX DATE', '2025-08-19T00:19:32.967981')
\end{verbatim}

\hfill\break
By examination of this metadata, we determine that the correct
information has been included. This includes the start/end times of the
exposure (referenced to TAI), site information including observatory
location, seeing, etc., telescope metadata regarding its pointing,
sensor readings, and camera and program metadata.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3505-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that images from the wavefront sensors and guiders are available,
and that the shutter motion profiles can be retrieved.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, it is demonstrated that both guider and
wavefront sensor images can be retrieved, as well as the shutter motion
profile.\\
\strut \\
Guider image:\\
\textbf{Image Download Error}\\
Wavefront sensor image:\\
\textbf{Image Download Error}\\
Finally, we extract the shutter motion profile. The following shows the
position of the shutter with time for one exposure:\\
\textbf{Image Download Error}


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T38 - Verify implementation of Processed Visit Images }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T38}{\textit{ LVV-T38 } }
test case in Jira.

Verify that the DMS\\
1. Successfully produces Processed Visit Images, where the instrument
signature has been removed.\\
2. Successfully combines images obtained during a standard visit.\\
\strut \\
The verification should include confirming that the images have been
trimmed of the overscan, and that correction of the instrumental
signature (including crosstalk) has been applied properly.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Executed at the USDF with pipelines version w\_2025\_29, using
LSSTComCam data from DP1. The resulting notebook is attached to the Test
Report repository as "test\_LVV-T38.ipynb".



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3506-1243142030:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3506-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify suitable precursor datasets containing unprocessed raw images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Use the LSSTComCam data that became Data Preview 1 (DP1), as processed
with v29 Science Pipelines.\\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3506-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
\textquotesingle DATA/path\textquotesingle, then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
from lsst.daf.butler import Butler\\
collection = "LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260"\\
repo = "/repo/dp1"\\
butler = Butler.from\_config(repo, collections=collection)


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3506-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Run the initial steps (including instrument signature removal and
calibration) of Data Release (or Prompt) Processing on these data.
Verify that Processed Visit Images are generated at the correct size and
with significant instrumental artifacts removed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Raw precursor dataset images have been processed into Processed Visit
Images, with instrumental artifacts corrected.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we examine a `visit\_image`, comparing it to
the `raw` frame of the same observation to confirm that it has been
transformed via instrument signature removal. We further explore the
image to show that it contains a WCS, PSF, and mask and variance planes.
The image is well-formed and contains all expected data.\\
\strut \\
We have thus confirmed that the PVIs are being created as expected in
the Science Pipelines. We note that the requirement mentions a "standard
visit", which was originally expected to contain 2x15s "snaps" that
would be combined. Commissioning data from LSSTComCam showed that this
is likely unnecessary, and the standard visit is likely to be redefined
as a single 30s exposure. If instead the 2x15s snaps are retained, this
test should be re-executed demonstrating the combination of snaps.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T45 - Verify implementation of Prompt Processing Data Quality Report
Definition }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T45}{\textit{ LVV-T45 } }
test case in Jira.

Verify that the DMS produces a Prompt Processing Data Quality Report.
~Specifically check absolute value and temporal variation of\\
1. Photometric zeropoint\\
2. Sky brightness\\
3. Seeing\\
4. PSF\\
5. Detection efficiency

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\It was noted during this testing that a mechanism for exporting the
report to PDF would be useful. It is unclear whether such functionality
makes sense within Times Square, but we recommend that it either be
implemented there, or that a capability should be developed elsewhere to
make it straightforward to export a static artifact from the underlying
notebook.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3508-1243142032:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3508-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset that has been processed with the Alert Production
pipeline. To generate the report, you will need the observation date and
instrument.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
By default, the report will display data from LATISS for 2024-09-04.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3508-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Visit the url for the "AP Data Quality Report" on Times Square, update
the date and instrument, then click "Update" to (re-)generate the
report. (A default report will likely appear when you first reach the
site.)

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A data quality report showing plots that summarize the data taken on the
requested observing night.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The url for the AP Data Quality Report is
\url{https://usdf-rsp-dev.slac.stanford.edu/times-square/github/lsst-dm/ap-times-square-notebooks/AP_Data_Quality_Report}.
Below we display the report for LATISS data from 2024-09-04, obtained by
entering the date and instrument into the boxes at the left. The
following screenshot shows the top of the report, as well as the
interface (on the left side) for changing the configuration of the
report:\\
\textbf{Image Download Error}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3508-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Observe that a dynamically updated Data Quality Report has become
available at the relevant UI.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A Prompt Processing QC report is available via a UI, and contains
information about the photometric zeropoint, sky brightness, seeing,
PSF, and detection efficiency, and possibly other relevant quantities.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The report is available, and displays the following (sets of) plots:

\begin{itemize}
\tightlist
\item
  Photometric Zeropoint vs. Time, by Filter
\item
  Sky Brightness vs. Time, by Filter
\item
  Seeing vs. Time, by Filter
\item
  PSF Parameters vs. Time, by Filter
\end{itemize}

\hfill\break
The detection efficiency for point sources, as requested in the
requirement, is not currently available. To generate this would require
injecting synthetic sources into the data, which may be beyond the scope
of Prompt Processing. In the future, we may instead include the limiting
magnitude for each image as a proxy for the detection efficiency, as
these two quantities are intimately related.\\
\strut \\
Because the definition exists within the Times Square framework, we deem
this test a "\textbf{Pass".~}However, this test should be repeated at a
later date to confirm that (a) the detection efficiency (or a proxy for
it) is reported, and (b) any additional necessary explanatory text or
figures is included. We expect the included information to evolve as the
survey proceeds.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T153 - Verify implementation of Engineering and Facility Database Archive }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T153}{\textit{ LVV-T153 } }
test case in Jira.

Demonstrate Engineering and Facilities Data (images, associated
metadata, and observatory environment and control data) are archived.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2025\_24 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T153.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3510-1243142034:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3510-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Access the EFD archive at the US Data Facility (USDF).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Active connection with the EFD client at the USDF.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The USDF archive of the EFD was accessed from a notebook in the USDF RSP
via the following lines;\\
\strut \\
from lsst\_efd\_client import EfdClient\\
client = EfdClient(\textquotesingle usdf\_efd\textquotesingle)\\
\strut \\
This instantiates the service for queries.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3510-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Query some EFD telemetry topics for a night at least 1 month ago during
which on-sky observing took place. Query topics that are typically
populated during on-sky observing, and confirm that they return results.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Populated EFD telemetry for topics related to the various aspects of the
telescope, camera, and facility.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we have demonstrated that telemetry from a
wide variety (over 3000) topics is available in the archived EFD. The
EFD contains topics pertaining to AuxTel (AT*), the Simonyi Telescope
("MainTel" -\/- denoted MT*), including the telescope mount (MTMount),
the dome (MTDome), the AOS system (MTAOS), the HVAC system, and LSSTCam
(MTCamera), among others. We also note that topics include commands,
logevents, and telemetry from sensors.\\
\strut \\
We extracted data from the EFD for a half-hour period of LSSTCam
observing on May 5, 2025 and printed some columns to the screen. The
following is a subset of the outputs:\\
\strut \\

\begin{verbatim}
*** Retrieving lsst.sal.MTMount.azimuth ***

             index                actualPosition  actualPositionTimestamp
-------------------------------- ---------------- -----------------------
2025-05-05 03:00:00.017759+00:00 16.6336992840165        1746414036.88586
2025-05-05 03:00:00.118609+00:00 16.6328785412205        1746414036.98565
2025-05-05 03:00:00.183883+00:00 16.6324684927823        1746414037.03552 

*** Retrieving lsst.sal.MTMount.elevation ***

             index                actualPosition  actualPositionTimestamp
-------------------------------- ---------------- -----------------------
2025-05-05 03:00:00.018120+00:00 60.4935636867039        1746414036.91525
2025-05-05 03:00:00.119741+00:00 60.4936641347571        1746414037.01558
2025-05-05 03:00:00.184244+00:00  60.493717586413        1746414037.06586 

*** Retrieving lsst.sal.ESS.temperature ***

             index                     sensorName        temperatureItem0
-------------------------------- ---------------------- -----------------
2025-05-05 03:00:00.265538+00:00 MTCameraAssembly-ESS01 9.816399574279785
2025-05-05 03:00:00.423640+00:00           AuxTel-ESS01                --
2025-05-05 03:00:00.476175+00:00           Camera-ESS01             11.75 

*** Retrieving lsst.sal.MTAOS.logevent_wavefrontError ***

             index                 nollZernikeValues7   ... sensorId
-------------------------------- ---------------------- ... --------
2025-05-05 03:08:29.520446+00:00     0.1901925802230835 ...      191
2025-05-05 03:08:29.626493+00:00   0.056604646146297455 ...      195
2025-05-05 03:16:40.393737+00:00 -0.0055709718726575375 ...      191 

*** Retrieving lsst.sal.MTM1M3.accelerometerData ***

             index                  accelerometer0   ...     timestamp     
-------------------------------- ------------------- ... ------------------
2025-05-05 03:00:00.008773+00:00 0.03544413298368454 ... 1746414037.0084796
2025-05-05 03:00:00.029285+00:00 0.03568815067410469 ... 1746414037.0284805
2025-05-05 03:00:00.049199+00:00 0.03679560497403145 ... 1746414037.0484805 


*** Retrieving lsst.sal.MTRotator.logevent_lowFrequencyVibration ***

             index               frequency
-------------------------------- ---------
2025-05-05 03:29:15.264806+00:00      0.33 

*** Retrieving lsst.sal.MTCamera.command_takeImages ***

             index               expTime numImages shutter
-------------------------------- ------- --------- -------
2025-05-05 03:07:24.192381+00:00      30         1    True
2025-05-05 03:08:01.361480+00:00      30         1    True
2025-05-05 03:11:13.485308+00:00      15         1    True 

*** Retrieving lsst.sal.MTCamera.logevent_startIntegration ***

             index               exposureTime ... imageNumber
-------------------------------- ------------ ... -----------
2025-05-05 03:07:24.311131+00:00           30 ...         336
2025-05-05 03:08:01.462359+00:00           30 ...         337
2025-05-05 03:11:13.607377+00:00           15 ...         338 
\end{verbatim}

\hfill\break
We have thus demonstrated that the EFD is archived at the USDF, and that
the data it contains are intact, accessible, and well-formed.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T88 - Verify implementation of Calibration Data Products }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T88}{\textit{ LVV-T88 } }
test case in Jira.

Verify that the DMS can produce and archive the required Calibration
Data Products: cross talk correction, bias, dark, monochromatic dome
flats, broad-band flats, fringe correction, and illumination
corrections.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Initial Pass }\\
Final comment:\\Test executed in the RSP at the USDF using pipelines version
w\_2025\_33.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3511-1243142035:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3511-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a suitable set of calibration frames, including biases, dark
frames, and flat-field frames.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test, we use the most recent LSSTCam on-sky data processing.
The butler initialization is as follows:\\
\strut \\
butler = Butler(\textquotesingle/repo/embargo\textquotesingle,
collections="LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202")\\
\strut \\
Note that this chains in the
\textquotesingle LSSTCam/calib\textquotesingle{} collection, which
contains all the approved calibrations for LSSTCam.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3511-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The creation of the most recent set of calibrations is documented on
the~\href{https://rubinobs.atlassian.net/browse/TAXICAB-43}{TAXICAB-43}
Jira ticket.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3511-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The following steps (executed in the attached notebook
test\_LVV-T88.ipynb) demonstrate that these calibration products are
present and queryable in the database.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3511-4 & Step Execution Status: \textbf{ Initial Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected data products are created, and that they have
the expected properties.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A full set of calibration data products has been created, and they are
well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The attached notebook retrieves brighter-fatter kernel (bfk), defects
mask, photon transfer curve (ptc), crosstalk object, bias, dark, and
flat-field datasets, and demonstrates that they are well-formed and
contain the expected information. We have demonstrated that the
processing produces these calibration data products, and confirmed that
they are well-formed.\\
\strut \\
However, we are not yet capable (mostly due to hardware limitations) of
creating the monochromatic flats, synthetic broad-band flats, or fringe
and illumination corrections, and thus deem the results of this test an
"initial pass". This test will be executed again once the additional
capabilities have been finalized.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3511-5 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test that the calibration products are archived, and can readily be
applied to science data to produce the desired corrections.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Confirmation that application of the calibration products to processed
data has the desired effects.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
This has been demonstrated in test case executions focused on each of
the different calibration datasets separately. For example,
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#!/v2/testCase/190696387}{LVV-T84}
verified the biases,
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#!/v2/testCase/LVV-T85}{LVV-T85}
and
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#!/v2/testCase/LVV-T1843}{LVV-T1843}
confirmed the effectiveness of the crosstalk corrections, and
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#!/v2/testCase/LVV-T90}{LVV-T90}
verified the dark current corrections.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T89 - Verify implementation of Calibration Image Provenance }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T89}{\textit{ LVV-T89 } }
test case in Jira.

Verify that the DMS records the required provenance information for the
Calibration Data Products.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Tests performed using ComCam on-sky data at the USDF, using w\_2025\_10
of the science pipelines. See the attached notebook,
"test\_LVV-T89.ipynb", for details.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3512-1243142036:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3512-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest an appropriate precursor calibration dataset into a Butler repo.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
This test uses calibration frames from the ComCam on-sky campaign in
late 2024. The images were obtained during daily observing, and
transferred to the USDF and ingested into the main shared Butler as part
of routine observing practice.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3512-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
We use the calibrations that were produced as described in the TAXICAB
ticket
\href{https://rubinobs.atlassian.net/browse/TAXICAB-23}{TAXICAB-23}.\\
\strut \\
In the attached notebook, we retrieve calibration datasets from the
butler via the following:\\
\strut \\
INSTRUMENT = "LSSTComCam"\\
COLLECTION = "LSSTComCam/runs/DRP/DP1/w\_2025\_10/DM-49359"\\
butler = Butler("/repo/main")\\
\strut \\
\# Select the first bias image and its metadata:\\
query = butler.query\_datasets(\textquotesingle bias\textquotesingle,
collections=COLLECTION)\\
bias = butler.get(query{[}0{]})\\
bias\_metadata = bias.getMetadata()


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3512-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The images were retrieved successfully, and the following steps serve as
a demonstration that they were well-formed, and contain all the required
metadata and provenance information.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3512-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Load the relevant database/Butler data product, and observe that all
provenance information has been retained.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset consisting of calibration images, with provenance information
recorded and properly associated with the calibration images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook ("test\_LVV-T89.ipynb") we have demonstrated
the retrieval of complete provenance information associated with
calibration images (and their associated Butler RUN collections),
including (among other things) the list of input exposures and the range
of dates over which they were obtained; the processing parameters; the
calibration products used to derive the images; and a set of metadata
attributes including the date of creation; the calibration image type
(e.g. dome flat, superflat, bias, etc); the provenance of the processing
software; and the instrument configuration including the filter in use,
where applicable. We thus deem the status of this test a PASS.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T189 - Verify implementation of Summit Facility Infrastructure }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Draft}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T189}{\textit{ LVV-T189 } }
test case in Jira.

Verify that the Summit Facility ~provides sufficient computing, storage,
and network infrastructure to support buffering and forwarding of all
raw image data to the Archive Facility, and compute facilities to
support Commissioning activities.~

\textbf{ Preconditions}:\\ Summit facility in place


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3519-1243142038:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3519-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Inspect the Computing Infrastructure document ~https://ittn-014.ls for
details of the deployed infrastructure at the summit, section 1.2 Cerro
Pachon. Ensure they are sufficient to support planned activities

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Compute for the Summit cluster sufficient to support operations

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\href{https://ittn-014.io}{ITTN-014} describes the compute
infrastructure on Cerro Pachon (summit).\\
\strut \\
Logging on to one of the summit nodes (azar)\\
\$ kubectl exec -it rook-ceph-tools-5887567898-4p7qj -n rook-ceph -\/-
/bin/bash\\
bash-5.1\$ ceph df\\
-\/-\/- RAW STORAGE -\/-\/-\\
CLASS SIZE AVAIL USED RAW USED \%RAW USED\\
nvme 4.5 PiB 4.5 PiB 16 TiB 16 TiB 0.34\\
TOTAL 4.5 PiB 4.5 PiB 16 TiB 16 TiB 0.34\\
\strut \\
There is a total of 4.5 PB of storage available. Nightly (24hr cycle)
data volume is expected to be \textasciitilde20TB. 20 nights of storage
on the summit is \textasciitilde{} 0.5PB.An internal buffer of about 3
nights data is planned of the camera. This shows there is more than
enough storage at the summit buffering and forwarding of data to the
Archive during commissioning and operations.\\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3519-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Inspect services running on summit systems that support commissioning
and ~operations

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Services running and supporting commissioning~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The compute infrastructure includes the commissioning cluster at the
summit. This supports pipelines and runs bps jobs as shown in test
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#!/v2/testCase/LVV-T191}{LVV-T191
(1.0)~}/
\href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#!/testPlayer/testExecution/LVV-E3750}{LVV-E3750}.
~Additionally, the \href{https://summit-lsp.lsst.codes/}{Rubin Science
Platform} runs at the summit, the Telescope control system, LOVE
(love01/02.cp.lsst.org),
\href{https://summit-lsp.lsst.codes/rubintv/summit}{RubinTV}\\
\strut \\
Connect to the summit RSP from a laptop at the base runimg openVPN\\
\textgreater{} \% curl -sL summit-lsp.lsst.codes \textbar{} sed -n
\textquotesingle s/.*\textless meta property="og:title"
content="\textbackslash({[}\^{}"{]}*\textbackslash)".*/\textbackslash1/p\textquotesingle{}\\
Rubin Science Platform @ Summit\\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3519-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Inspect network bandwidth from Summit to USDF

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Network bandwidth sufficient for predicted data volumes and rates

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Network summit to base is 600Gb/s. The base to USDF has 2 links.
~1x100Gb/s exclusively for Rubin use and another 1x100Gb/s shared with
other regional programs, with a guarantee of 40Gbit/sec minimum for
Rubin.~


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3519-4 & Step Execution Status: \textbf{ Not Executed } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Measure transfer rates for some test datasets

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
ComCam data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T197 - Verify implementation of Archive Center }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Draft}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T197}{\textit{ LVV-T197 } }
test case in Jira.

Verify that the Archive Center is sufficiently provisioned to support
prompt processing, DRP, and data access needs.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3520-1243142039:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3520-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Analyze design and sizing model

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The archive center is set up to execute numerous processing streams
nearly continuously. These include (1) nightly (Prompt) processing,
including Solar System association, on reserved nodes, and (2)
ongoing/regular DRP processing.\\
\strut \\
\textbf{Nightly/prompt processing:}\\
This is executed in Kubernetes environments, configured via the\\
\href{https://github.com/lsst-sqre/phalanx/blob/main/applications/prompt-keda-lsstcam/values-usdfprod-prompt-processing.yaml}{prompt
processing config} that is managed by
\href{https://phalanx.lsst.io/}{Phalanx}.\\
\strut \\
The following portion of the prompt processing configuration in Phalanx
demonstrates the setup of pipelines to be executed, among other
things.\\
\textbf{Image Download Error}This is followed by execution of the AP
pipelines, including:\\

\begin{itemize}
\tightlist
\item
  \texttt{\$\{PROMPT\_PROCESSING\_DIR\}/pipelines/LSSTCam/ApPipe-noForced.yaml}
\item
  \texttt{\$PROMPT\_PROCESSING\_DIR/pipelines/LSSTCam/ApPipe.yaml}
\item
  \texttt{\$AP\_PIPE\_DIR/pipelines/LSSTCam/ApPipe.yaml}
\item
  \texttt{\$AP\_PIPE\_DIR/pipelines/\_ingredients/ApPipeWithIsrTaskLSST.yaml}
\item
  \texttt{\$AP\_PIPE\_DIR/pipelines/\_ingredients/ApPipe.yaml}
\end{itemize}

\hfill\break
There is also consistently a DRP processing run being executed. The
configuration, logs, and submission scripts are archived on the Jira
ticket for each processing run. An example is
\href{https://rubinobs.atlassian.net/browse/DM-50260}{DM-50260} (from
the DP1 processing), which includes a summary that looks like the
following:\\
\textbf{Image Download Error}\\
The storage and archiving provisions have been demonstrated on the Test
Case for DMS-REQ-0003. The sizing model
(\url{https://dmtn-135.lsst.io/}) details plans to accommodate future
processing and storage needs.\\
\strut \\
These simultaneous and ongoing processing streams, plus additional
processing, analysis, and data access activities by Pipelines and other
teams, demonstrate a functioning Archive Center.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T48 - Verify implementation of Exposure Catalog }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T48}{\textit{ LVV-T48 } }
test case in Jira.

Verify that the DMS creates an Exposure Catalog that includes\\
1. Observation datetime, exposure time\\
2. Filter\\
3. Dome, telescope orientation and status\\
4. Calibration status\\
5. Airmass and zenith\\
6. Environmental information\\
7. Per-sensor information

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2025\_09 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T48.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3523-1243142042:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3523-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that Exposure Catalogs contain the required elements. At present,
the form of the exposure catalog is not defined. This information can be
found for a given Butler repo from the metadata, but will ultimately be
aggregated into a database/table summarizing available exposures.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A list of the required metadata for a set of exposures is returned and
both human- and machine-readable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we have demonstrated that an exposure log of
ComCam on-sky data is accessible via the consolidated database
(ConsDB).\\
We show that the ConsDB contains information taken directly from image
headers, transformed data from the Engineering Facilities Database
(EFD), and derived data based on image processing.\\
As required, these data include information about each exposure, include
the telescope and instrument configuration, telemetry from the
telescope, environmental and pointing information, and details about the
camera.\\
\strut \\
In some examples shown, columns that exist in the database are not yet
populated. Nonetheless, this test is deemed to \emph{PASS} because we
have demonstrated the existence of a database (ConsDB) keyed on
day\_obs, which can take inputs from a variety of sources, all of which
can be configured (see the code for configuring and populating ConsDB at
\href{https://github.com/lsst-dm/consdb}{this github link}).


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1862 - Verify determining effectiveness of dark current frame }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1862}{\textit{ LVV-T1862 } }
test case in Jira.

Verify that the DMS can determine the effectiveness of a dark correction
and determine how often it should be updated.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed using ComCam data as processed by pipelines version
w\_2025\_10. The results are shown in the notebook test\_LVV-T1862.ipynb
attached to this document\textquotesingle s repository.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3524-1243142043:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3524-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to a dataset containing dark frames (i.e., exposures
taken with the shutter closed).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
We use the dark correction images for LSSTCam on-sky data that were
created and ingested as part of
\href{https://rubinobs.atlassian.net/browse/TAXICAB-43}{TAXICAB-43}.\\
\strut \\
In the attached notebook, we retrieve a `post\_isr\_image` dataset from
the butler via the following:\\
\strut \\
INSTRUMENT = "LSSTCam"\\
COLLECTION =
"LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202"\\
butler = Butler("/repo/embargo")\\
query =
butler.query\_datasets(\textquotesingle post\_isr\_image\textquotesingle,
collections=COLLECTION)\\
\strut \\
\# Select an image and its dark object:\\
postisrccd = butler.get(query{[}1{]})\\
crosstalk = butler.get("dark", collections=COLLECTION,
dataId=query{[}1{]}.dataId)


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3524-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
As noted in the previous step, we used the calibrations created for the
"intermittent cumulative DRP" processing of LSSTCam data with
`w\_2025\_33`. The processing used the "cpDark.yaml" pipeline to create
the combined dark frames, and the "verifyDark.yaml" pipeline to create
the verification data that is reported to the TAXICAB for formal
approval of calibration products.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3524-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, the dark image was displayed, and its metadata
examined. All looks well-formed.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3524-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Determining whether the dark correction is being done properly will
require on-sky science data. The dark correction can be applied to these
frames and the results inspected to ensure that the correction was
correctly measured and applied.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Applying the dark correction to a dataset produces noticeable
differences between the original frame(s) and the corrected outputs.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we applied the dark correction to an input
`post\_isr\_image` image, and confirmed that the resulting image was as
expected.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T115 - Verify implementation of Calibration Production Processing }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T115}{\textit{ LVV-T115 } }
test case in Jira.

Execute CPP on a variety of representative cadences, and verify that the
calibration pipeline correctly produces necessary calibration products.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Executed at the USDF using pipelines version w\_2025\_19, the ci\_cpp
package, and the "testdata\_latiss\_cpp" dataset.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3525-1243142044:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3525-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a suitable set of calibration frames, including biases, dark
frames, and flat-field frames.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
This test uses the testdata\_latiss\_cpp dataset, a curated dataset used
for regular testing of calibration products production.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3525-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
After setting up the `ci\_cpp\_gen3` package, we executed the command
"scons -j 8" (from the ci\_cpp\_gen3 package root directory), which runs
a scons script that executes a full CPP payload. The full script that is
executed can be seen at
\href{https://github.com/lsst/ci_cpp_gen3/blob/main/DATA/SConscript}{this
link}.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3525-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook ("test\_LVV-T115.ipynb"), we demonstrate
querying the butler repository and confirming that the calibrations
collections and datasets have been created.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3525-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected data products are created, and that they have
the expected properties.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Repos containing valid calibration products that are well-formed and
ready to be applied to processed datasets.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The attached notebook retrieves brighter-fatter kernel (bfk), photon
transfer curve (ptc), bias, dark, and flat-field datasets, and
~demonstrates that they are well-formed and contain the expected
information. We have demonstrated that the processing script produces
the calibration data products, and confirmed that they are well-formed,
and thus deem the results of this test a pass.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T98 - Verify implementation of Selection of Datasets }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Defined}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T98}{\textit{ LVV-T98 } }
test case in Jira.

Verify that the DMS can identify and retrieve datasets consisting of
logical groupings of Exposures, metadata, provenance, etc., or other
groupings that are processed or produced as a logical unit.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed at the USDF (from both the command line and the RSP) using
pipelines version w\_2025\_33.\\
\strut \\
For this test, we demonstrate that these logical groupings can be
applied in butler queries via the "where" clause. These same query
constraints can be passed to pipetasks to apply the selections for
processing of data.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3528-1243142047:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3528-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute a Butler query with constraints on observation time.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
List of datasets observed within the requested time period (and meeting
any additional constraints that were applied).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
From the command line, we issue a butler query to identify
`visit\_image` datasets from LSSTCam observing that were observed after
a time of "2025-06-01 12:20:33". To demonstrate additional constraints
that can be specified, we further limit it to g-band observations, and
only detectors in raft R10.\\
\strut \\
butler query-datasets /repo/main visit\_image -\/-collections
"LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933" -\/-where
"instrument=\textquotesingle LSSTCam\textquotesingle{} AND
skymap=\textquotesingle lsst\_cells\_v1\textquotesingle{} AND
band=\textquotesingle g\textquotesingle{} AND visit.timespan.begin
\textgreater{} T\textquotesingle2025-06-01 12:20:33\textquotesingle{}
AND detector.raft=\textquotesingle R10\textquotesingle"\\
\strut \\
type run id instrument detector visit band day\_obs physical\_filter\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
visit\_image
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250810T233354Z
28e36348-8b46-4449-8aa2-7632ee096bb5 LSSTCam 28 2025060100605 g 20250601
g\_6\\
visit\_image
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250810T233354Z
58bddcc6-42b8-42ee-b6e5-f1189330e464 LSSTCam 29 2025060100605 g 20250601
g\_6\\
visit\_image
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250810T233354Z
6fc1a870-759d-4dcc-a99f-17991c315291 LSSTCam 30 2025060100605 g 20250601
g\_6\\
visit\_image
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250810T233354Z
5d0baa86-f992-4b55-9ace-0c8aa3eaff32 LSSTCam 31 2025060100605 g 20250601
g\_6\\
visit\_image
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250810T233354Z
367391ed-3e38-4908-8842-a2f8f2826c1b LSSTCam 32 2025060100605 g 20250601
g\_6\\
visit\_image
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250810T233354Z
9bc34df8-0d3e-4e39-a708-819ca91109cb LSSTCam 33 2025060100605 g 20250601
g\_6\\
visit\_image
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250810T233354Z
bb94ad6b-20d1-413e-97b3-2126d644017a LSSTCam 35 2025060100605 g 20250601
g\_6\\
visit\_image\\
\strut \\
The results above (truncated) show that the query successfully
identified a set of images meeting the constraint.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3528-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute a Butler query that uses mathematical expressions to sub-select
among the results (e.g., to select even-numbered patches).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
List of datasets satisfying the requested constraints.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
From the command line, we issue a butler query to identify `deep\_coadd`
datasets from LSSTCam observing. The queries below demonstrate applying
mathematical constraints to (1) select even-numbered patches (by
applying a "patch \% 2 = 0" constraint), and (2) select patches with ids
less than 43 (i.e., "patch \textless{} 43"). In each case, the input
query only requests patches 41-44, so the results should return only 2
patches.\\
\strut \\
\$ butler query-datasets /repo/main deep\_coadd -\/-collections
"LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933" -\/-where
"instrument=\textquotesingle LSSTCam\textquotesingle{} AND
skymap=\textquotesingle lsst\_cells\_v1\textquotesingle{} AND tract=3725
AND band=\textquotesingle g\textquotesingle{} AND patch in (41, 42, 43,
44) AND patch \% 2 = 0"\\
\strut \\
type run id band skymap tract patch\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-
-\/-\/-\/-\/-\\
deep\_coadd
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250806T010818Z
d91731aa-e9b4-4101-a6bf-3df72ad677ca g lsst\_cells\_v1 3725 42\\
deep\_coadd
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250806T010818Z
0cc4af67-e488-435a-b50c-cd860b8931ee g lsst\_cells\_v1 3725 44\\
\strut \\
\$ butler query-datasets /repo/main deep\_coadd -\/-collections
"LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933" -\/-where
"instrument=\textquotesingle LSSTCam\textquotesingle{} AND
skymap=\textquotesingle lsst\_cells\_v1\textquotesingle{} AND tract=3725
AND band=\textquotesingle g\textquotesingle{} AND patch in (41, 42, 43,
44) AND patch \textless{} 43"\\
\strut \\
type run id band skymap tract patch\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-
-\/-\/-\/-\/-\\
deep\_coadd
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250806T010818Z
30f19e04-e625-487b-b45e-7515b25cefa5 g lsst\_cells\_v1 3725 41\\
deep\_coadd
LSSTCam/runs/DRP/20250501\_20250609/w\_2025\_30/DM-51933/20250806T010818Z
d91731aa-e9b4-4101-a6bf-3df72ad677ca g lsst\_cells\_v1 3725 42\\
\strut \\
We see that the constraints were successfully applied in each case,
demonstrating that mathematical/numerical groupings can be applied.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3528-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Query the Consolidated Database (ConsDB) to identify visits meeting some
constraints on environmental conditions (e.g., seeing, wind speed or
direction, temperature). Then use the returned list of visits to
constrain a Butler query.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
List of datasets taken in the requested conditions.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In a Jupyter notebook on the USDF RSP, we execute the following code,
which queries the ConsDB for visits taken between 20250721-20250730,
when the dimm seeing was between 1.3-1.5 arcsec, and the air temperature
was \textless{} 7 C.\\
\strut \\
import~os\\
import~numpy~as~np\\
import~pandas~as~pd\\
import~requests\\
from~lsst.summit.utils~import~ConsDbClient\\
\strut \\
\# Parameters ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\\
day\_obs~=~"2025-07-30"\\
instrument~=~"lsstcam"\\
\strut \\
URL~=~"http://consdb-pq.consdb:8080/consdb"~ ~~\\
os.environ{[}"no\_proxy"{]} +=~",.consdb"\\
access\_token~= os.getenv("ACCESS\_TOKEN")\\
headers~= \{"Authorization": f"Bearer \{access\_token\}"\}\\
\strut \\
client~= ConsDbClient(URL)\\
print(client)\\
\strut \\
day\_obs\_int~=~int(day\_obs.replace("-",~""))\\
print(f\textquotesingle Date: \{day\_obs\_int\}\textquotesingle)\\
\strut \\
visit\_query1~= f"""~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\\
\strut ~ ~~SELECT * FROM cdb\_\{instrument\}.visit1~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\\
\strut ~ ~~where day\_obs \textless= \{day\_obs\_int\} AND day\_obs
\textgreater{} \{day\_obs\_int-9\} ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\\
\strut ~ ~~AND
science\_program=\textquotesingle BLOCK-365\textquotesingle{} AND
dimm\_seeing \textless{} 1.5 AND dimm\_seeing \textgreater{} 1.3~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\\
\strut ~ ~~AND air\_temp \textless{} 7.0 ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~\\
"""\\
\strut \\
visits~= client.query(visit\_query1).to\_pandas()\\
\strut \\
print(visits{[}\textquotesingle visit\_id\textquotesingle{]}.to\_list())\\
\strut \\
The query prints the following list of 7 visits to the screen:\\

\begin{verbatim}
[2025072300523,
 2025072300533,
 2025072300534,
 2025072300540,
 2025072300550,
 2025072300551,
 2025072300576]
\end{verbatim}

\hfill\break
This list of visits can be passed to the butler query interface to
retrieve their dataset references as follows:\\
\strut \\
\$ butler query-datasets /repo/embargo preliminary\_visit\_image
-\/-collections
"LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202" -\/-where
"instrument=\textquotesingle LSSTCam\textquotesingle{} AND
skymap=\textquotesingle lsst\_cells\_v1\textquotesingle{} AND visit IN
(2025072300523, 2025072300533, 2025072300534, 2025072300540,
2025072300550, 2025072300551, 2025072300576) AND detector=34"\\
\strut \\
type run id instrument detector visit band day\_obs physical\_filter\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
preliminary\_visit\_image
LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202/20250816T023854Z
e980c8a9-6eb1-451d-b6d6-071156293cc6 LSSTCam 34 2025072300523 g 20250723
g\_6\\
preliminary\_visit\_image
LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202/20250816T023854Z
875130bd-ae7b-4835-8bae-103f0618e33f LSSTCam 34 2025072300533 g 20250723
g\_6\\
preliminary\_visit\_image
LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202/20250816T023854Z
d1ae421f-ae03-4431-8b64-9e358dc4647e LSSTCam 34 2025072300534 g 20250723
g\_6\\
preliminary\_visit\_image
LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202/20250816T023854Z
6330df8d-0c53-4eca-a840-1e145933a23c LSSTCam 34 2025072300540 g 20250723
g\_6\\
preliminary\_visit\_image
LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202/20250816T023854Z
e378692f-10a9-4d97-a7ca-e5550c04ff20 LSSTCam 34 2025072300550 r 20250723
r\_57\\
preliminary\_visit\_image
LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202/20250816T023854Z
cb6ab6c1-d102-443c-9df2-fdf997cedcc5 LSSTCam 34 2025072300551 r 20250723
r\_57\\
preliminary\_visit\_image
LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202/20250816T023854Z
ea0420f3-8cb9-4235-bc01-b188b3806e33 LSSTCam 34 2025072300576 r 20250723
r\_57\\
\strut \\
We have thus demonstrated that constraints on observing conditions can
be applied to select groupings of datasets for processing.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T2693 - Verify implementation of Image Provenance Access }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2693}{\textit{ LVV-T2693 } }
test case in Jira.

Verify that available image data products\textquotesingle{} provenance
information can be listed and retrieved.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Executed at the USDF using LSSTComCam data processed with pipelines
version `w\_2025\_16`. See the attached notebook,
"test\_LVV-T2693.ipynb", for details.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3530-1243142049:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3530-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
\textquotesingle DATA/path\textquotesingle, then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Working in a notebook entitled "test\_LVV-T2693.ipynb" on the U.S. Data
Facility:\\
\strut \\
from lsst.daf.butler import Butler\\
\strut \\
collection = "LSSTComCam/runs/DRP/DP1/w\_2025\_16/DM-50344"\\
butler = Butler("/repo/main", collections={[}collection{]})


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3530-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Using `Butler.get()`, retrieve a `visit\_image` using a known dataId.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\# Define the data dimensions for dataId creation:\\
tract = 5063\\
patch = 24\\
visit = 2024110800246\\
detector = 4\\
\strut \\
\# Retrieve an image:\\
vis\_im = butler.get(\textquotesingle visit\_image\textquotesingle,
dataId=\{\textquotesingle visit\textquotesingle:visit,
\textquotesingle detector\textquotesingle: detector\})


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3530-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Use the `DatasetProvenance` class from `lsst.daf.butler` to extract the
provenance of the image, and display the provenance information to the
screen.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
\hspace{0pt}A `DatasetProvenance` object \hspace{0pt}containing
information about \hspace{0pt}the input datasets to the inspected image
is displayed to the screen.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\# Extract the provenance and print to the screen:\\
vis\_im\_prov = DatasetProvenance.from\_flat\_dict(vis\_im.metadata,
butler)\\
vis\_im\_prov{[}0{]}\\
\strut \\
OUTPUT:\\

\begin{verbatim}
DatasetProvenance(inputs=[SerializedDatasetRef(id=UUID('b97a5838-24a4-4d83-9e14-c2c7fdd17afd'), datasetType=SerializedDatasetType(name='visit_summary', storageClass='ExposureCatalog', dimensions=['instrument', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('31b3f43c-a874-4489-b432-d4b3e30ceb97'), datasetType=SerializedDatasetType(name='refit_psf_star', storageClass='ArrowAstropy', dimensions=['instrument', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('2d130454-72f3-4515-a5ab-8bca272d982c'), datasetType=SerializedDatasetType(name='preliminary_visit_image_background', storageClass='Background', dimensions=['instrument', 'detector', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'detector': 4, 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('d97092fb-27db-4121-85f3-d0ae3029d138'), datasetType=SerializedDatasetType(name='post_isr_image', storageClass='Exposure', dimensions=['instrument', 'detector', 'exposure'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'detector': 4, 'exposure': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('58225fb7-8819-4a3d-b3d7-7032d37d3b2a'), datasetType=SerializedDatasetType(name='background_to_photometric_ratio', storageClass='Image', dimensions=['instrument', 'detector', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'detector': 4, 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None)], quantum_id=UUID('98b2a9c0-a1ef-416d-96f0-ccf508d1dba4'), extras={})
\end{verbatim}

\hfill\break


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3530-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Repeat steps 2 and 3 for difference images and coadd images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
See the attached notebook, wherein we repeated the above steps for many
different image datasets.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T2699 - Verify implementation of Catalog Provenance Access }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2699}{\textit{ LVV-T2699 } }
test case in Jira.

Verify that available catalog data products\textquotesingle{} provenance
can be listed and retrieved.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Executed at the USDF using LSSTComCam data processed with pipelines
version `w\_2025\_16`. See the attached notebook,
"test\_LVV-T2699.ipynb", for details.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3531-1243142050:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3531-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
\textquotesingle DATA/path\textquotesingle, then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Working in a notebook entitled "test\_LVV-T2699.ipynb" on the U.S. Data
Facility:\\
\strut \\
from lsst.daf.butler import Butler\\
\strut \\
collection = "LSSTComCam/runs/DRP/DP1/w\_2025\_16/DM-50344"\\
butler = Butler("/repo/main", collections={[}collection{]})


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3531-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Using `Butler.get()`, retrieve a `source` catalog using a known dataId.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\# Define the data dimensions for dataId creation:\\
tract = 5063\\
patch = 24\\
visit = 2024110800246\\
detector = 4\\
\strut \\
\# Retrieve a catalog:\\
src\_unstd =
butler.get(\textquotesingle source\_unstandardized\textquotesingle,
dataId=\{\textquotesingle visit\textquotesingle:visit,
\textquotesingle detector\textquotesingle: detector\})


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3531-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Use the `DatasetProvenance` class from `lsst.daf.butler` to extract the
provenance of the catalog, and display the provenance information to the
screen.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\# Extract the provenance and print to the screen:\\
src\_unstd\_prov = DatasetProvenance.from\_flat\_dict(src\_unstd.meta,
butler)\\
src\_unstd\_prov{[}0{]}\\
\strut \\
OUTPUT:\\

\begin{verbatim}
DatasetProvenance(inputs=[SerializedDatasetRef(id=UUID('b97a5838-24a4-4d83-9e14-c2c7fdd17afd'), datasetType=SerializedDatasetType(name='visit_summary', storageClass='ExposureCatalog', dimensions=['instrument', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('31b3f43c-a874-4489-b432-d4b3e30ceb97'), datasetType=SerializedDatasetType(name='refit_psf_star', storageClass='ArrowAstropy', dimensions=['instrument', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('2d130454-72f3-4515-a5ab-8bca272d982c'), datasetType=SerializedDatasetType(name='preliminary_visit_image_background', storageClass='Background', dimensions=['instrument', 'detector', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'detector': 4, 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('d97092fb-27db-4121-85f3-d0ae3029d138'), datasetType=SerializedDatasetType(name='post_isr_image', storageClass='Exposure', dimensions=['instrument', 'detector', 'exposure'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'detector': 4, 'exposure': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None), SerializedDatasetRef(id=UUID('58225fb7-8819-4a3d-b3d7-7032d37d3b2a'), datasetType=SerializedDatasetType(name='background_to_photometric_ratio', storageClass='Image', dimensions=['instrument', 'detector', 'visit'], parentStorageClass=None, isCalibration=False), dataId=SerializedDataCoordinate(dataId={'instrument': 'LSSTComCam', 'detector': 4, 'visit': 2024110800246}, records=None), run='LSSTComCam/runs/DRP/DP1/w_2025_16/DM-50344/20250419T134626Z', component=None)], quantum_id=UUID('98b2a9c0-a1ef-416d-96f0-ccf508d1dba4'), extras={})
\end{verbatim}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3531-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Repeat steps 2 and 3 for catalogs from coadd images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
See the attached notebook, wherein we repeated the above steps for many
different catalog datasets.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1847 - Verify calculation of sensor fraction with unusable pixels }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Draft}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1847}{\textit{ LVV-T1847 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum allowable fraction of sensors with \textbf{PixFrac
\textgreater{} 1} percent scientifically unusable pixels is less
than~\textbf{SensorFraction = 15 percent.}

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2025\_27 in the RSP
Notebook aspect at the USDF. Because this test concerns a threshold
calculated in LVV-T1841, the two tests were executed together.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1841\_1847.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3537-1243142055:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3537-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
\protect\phantomsection\label{isPasted}
{Identify the path to a dataset containing LSSTCam images.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\# PARAMETERS:\\
\# Instrument to consider for analysis:\\
INSTRUMENT = "LSSTCam"\\
\# Repository containing our data.\\
REPO = "/repo/main"\\
\# Collection containing processed exposures to use for metadata scan.\\
collection = "LSSTCam/calib"


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3537-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Retrieve the `camera` object associated with the images. This will be
used to extract datasets corresponding to each detector.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A `camera` datasetType, with information about the
camera\textquotesingle s detectors.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Using the parameters defined in Step 1, the butler was initialized and
the camera object retrieved as follows:\\
\strut \\
butler = Butler(REPO)\\
camera = butler.get("camera", instrument=INSTRUMENT,\\
collections=f"\{INSTRUMENT\}/calib")


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3537-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
For each detector, load the `defects` dataset, and calculate the
percentage of pixels that are labeled as defective.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A table containing the percentage of pixels known to be defective for
each detector.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we loop over all the detectors in the camera
object. For each detector, we retrieve the `defects` dataset, and
calculate the percentage of pixels that are flagged as defective.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3537-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Calculate the percentage of detectors that do not meet the
\textbf{PixFrac} threshold, \textbf{SensorFraction}.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Confirm that less than~\textbf{SensorFraction=15\%~}of detectors have
\textbf{PixFrac\textgreater1\%~}of defective pixels.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Using the tabulated \textbf{PixFrac} values from the previous step, we
show (in the attached notebook) that 4\% of the sensors exceed the
\textbf{PixFrac=1\%~}threshold. This is well below the required value
of~\textbf{SensorFraction\textless15\%;~}thus, the\textbf{~}requirement
is met, and this test has a result of \textbf{PASS}.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1843 - Verify calculation of significance of imperfect crosstalk corrections }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1843}{\textit{ LVV-T1843 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum local significance integrated over the PSF of imperfect
crosstalk corrections is less than \textbf{Xtalk = 3 sigma}.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Tests performed using ComCam on-sky data at the USDF, using w\_2025\_10
of the science pipelines. See the attached notebook,
"test\_LVV-T1843.ipynb", for details.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3540-1243142058:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3540-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify datasets containing observations of bright stars.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
One or more dataIds of `calexp` images with stars brighter than
\textasciitilde8th magnitude.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The areas overlapped by four fields (ECDFS, EDFS, Rubin\_SV\_95\_-25,
and Rubin\_SV\_38\_7) from the w\_2025\_10 processing of the ComCam
on-sky data were queried to find sources from Gaia DR3 brighter than 8th
magnitude (in Gaia G-band). This resulted in 5 bright stars with ComCam
observations.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3540-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Make lists of the (x, y) positions of the bright star observations in
the `calexp` images, then identify the corresponding positions in other
amplifiers on each detector where crosstalk artifacts are expected to
appear.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A list of expected crosstalk image positions in all 16 amplifiers of
each detector containing a bright star observation.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The butler was queried to identify `calexp` images overlapping these
bright stars, then their datasetRefs were looped over to extract the
actual (x, y) positions of the bright stars in the images.\\
\strut \\
A function to calculate the corresponding expected crosstalk positions
was applied to each observation, and a list was made of all expected
crosstalk artifact positions.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3540-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Measure forced photometry at the expected positions of crosstalk
artifacts, and confirm that their signal-to-noise is less than 3.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
An ensemble of forced photometry measurements, with none of them
exceeding 3-sigma excess.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Forced photometry was performed at the positions of expected crosstalk,
and the following plot of signal-to-noise vs. amplifier (indexed as
amplifier number relative to the midline of the detector) was generated.
(See details in the attached notebook.)\\
\strut \\
\textbf{Image Download Error}\\
The vast majority of points lie beneath the required Xtalk \textless{} 3
sigma line, but a handful of points exceed this value. We spot-checked
the images at many of these positions, and determined that in all cases
there were stars at the expected crosstalk artifact positions, which
resulted in large flux measurements unrelated to crosstalk.\\
\strut \\
The residual flux significance at the positions of all crosstalk
corrections (excluding those that overlap obvious stars/galaxies) is
less than the required Xtalk = 3 sigma limit. We thus deem this test a
Pass.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1757 - Verify calculation of photometric repeatability in gri filters }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1757}{\textit{ LVV-T1757 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the RMS
photometric repeatability of bright non-saturated unresolved point
sources in the g, r, and i filters, and assess whether it meets the
requirement that it shall be less than \textbf{PA1gri = 5.0
millimagnitudes}.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1757.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3541-1243142059:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3541-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field in each of the g, r,
and i filters with multiple overlapping visits.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use the most recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3541-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `analysis\_tools` on a repository containing processed data.
Identify the path to the data, which we will call
\textquotesingle DATA/path\textquotesingle, then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, "u/username/atools\_metrics")
containing metric measurements and any associated extras and metadata is
available via the butler.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\begin{verbatim}
The processed RC2 data products are accessed via the Butler using the following commands:

from lsst.daf.butler import Butler
\end{verbatim}

\begin{verbatim}
# Initialize the butler repo pointing to the DM-45857 (w_2024_34) collection
repo = '/repo/main'
collection = 'HSC/runs/RC2/w_2024_34/DM-45857'

butler = Butler(repo, collections=collection)
\end{verbatim}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3541-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric PA1gri has been calculated, and that its values
are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that PA1gri has been calculated.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, the metrics were retrieved and printed to the
screen, resulting in the following output:\\
\strut \\

\begin{verbatim}
Tract 9615:

g_stellarPhotRepeatStdev = 7.36 mmag
r_stellarPhotRepeatStdev = 7.31 mmag
i_stellarPhotRepeatStdev = 7.68 mmag

Tract 9697:

g_stellarPhotRepeatStdev = 7.57 mmag
r_stellarPhotRepeatStdev = 7.31 mmag
i_stellarPhotRepeatStdev = 8.46 mmag

Tract 9813:

g_stellarPhotRepeatStdev = 8.24 mmag
r_stellarPhotRepeatStdev = 8.99 mmag
i_stellarPhotRepeatStdev = 8.03 mmag
\end{verbatim}

\hfill\break
The quantities "\{band\}\_stellarPhotRepeatStdev" correspond to the
photometric repeatability metric \textbf{PA1}.\\
\strut \\
In the attached notebook, we also demonstrated the retrieval of plots
generated by `analysis\_tools` showing the distribution of repeatability
values from which PA1 was calculated.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1757.ipynb."


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1841 - Verify calculation of scientifically unusable pixel fraction }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1841}{\textit{ LVV-T1841 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum fraction of pixels scientifically unusable per sensor out of the
total allowable fraction of sensors meeting this performance is less
than~\textbf{PixFrac = 1 percent}.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2025\_27 in the RSP
Notebook aspect at the USDF. Because this test concerns a threshold for
LVV-T1847, the two tests were executed together.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1841\_1847.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3543-1243142061:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3543-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
\protect\phantomsection\label{isPasted}
{Identify the path to a dataset containing LSSTCam images.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\# PARAMETERS:\\
\# Instrument to consider for analysis:\\
INSTRUMENT = "LSSTCam"\\
\# Repository containing our data.\\
REPO = "/repo/main"\\
\# Collection containing processed exposures to use for metadata scan.\\
collection = "LSSTCam/calib"


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3543-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Retrieve the `camera` object associated with the images. This will be
used to extract datasets corresponding to each detector.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A `camera` datasetType, with information about the
camera\textquotesingle s detectors.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Using the parameters defined in Step 1, the butler was initialized and
the camera object retrieved as follows:\\
\strut \\
butler = Butler(REPO)\\
camera = butler.get("camera", instrument=INSTRUMENT,\\
collections=f"\{INSTRUMENT\}/calib")


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3543-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
For each detector, load the `defects` dataset, and calculate the
percentage of pixels that are labeled as defective.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A table containing the percentage of pixels known to be defective for
each detector. Most should be less than PixFrac=1\%.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook (test\_LVV-T1841\_1847.ipynb), we loop over all
the detectors in the camera object. For each detector, we retrieve the
`defects` dataset, and calculate the percentage of pixels that are
flagged as defective.\\
\strut \\
The related Test Case, LVV-T1847, uses these tabulated~\textbf{PixFrac}
values to assess whether the~\textbf{SensorFraction~}requirement is met.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1840 - Verify calculation of sky brightness precision }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1840}{\textit{ LVV-T1840 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum error in the precision of the sky brightness determination is
less than \textbf{SBPrec = 1 percent.}

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass w/ Deviation }\\
Final comment:\\Executed at the USDF with pipelines version w\_2025\_28, using
LSSTComCam data from DP1. The resulting notebook is attached to the Test
Report repository as "test\_LVV-T1840.ipynb".



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3544-1243142062:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3544-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify an appropriate processed precursor dataset containing process
visit images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Use the LSSTComCam data that became Data Preview 1 (DP1), as processed
with v29 Science Pipelines:\\
\strut \\
collection = "LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260"\\
repo = "/repo/dp1"\\
butler = Butler.from\_config(repo, collections=collection)


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3544-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
For each visit-level image, calculate the 1-sigma standard deviation of
the flux level measured via "sky sources" (9-pixel aperture fluxes, well
separated from detected sources).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A set of sky standard deviations, one for each visit.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, g-band `visit\_images` are loaded in
succession, calculating the clipped standard deviation of the background
using a defined function called "deriveBgNoise". In addition, the
standard deviation of "sky sources" as measured in the associated
`source` table is calculated via a function called
"deriveSkySourceNoise". These two methods should produce similar
results, but may differ, as the sky sources are 9-pixel apertures placed
in "empty" regions of the image, while the image-based method uses all
pixels that are not part of a detected source.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3544-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Compare the standard deviation of sky fluxes from the previous step to
the sky pedestal value that has been subtracted from the image to
estimate the fractional error in the determination of the sky background
for each visit.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Estimation of the precision of the sky background measurement for a set
of visits.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The std deviation measurements from the previous step are compared to
the background level that has been subtracted from each image, producing
the following figure for the fractional error in the determination of
the sky background:\\
\textbf{Image Download Error}\\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3544-4 & Step Execution Status: \textbf{ Pass w/ Deviation } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
窶祈ind the maximum value of the fractional errors estimated in the
previous step, and compare it to the SBPrec threshold.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Comparison of the maximum sky background precision to the threshold
\textbf{SBPrec}.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
None of the examined visits meet the SBPrec threshold of 0.01 (1\%), so
this test should technically \textbf{Fail.} However, as detailed in the
notebook, this is unsurprising, as the measurement essentially captures
a signal-to-noise ratio, and its floor is set by the Poisson statistics
of the initial sky brightness. We thus do not expect to be able to reach
SBPrec \textless{} 1\% consistently, and propose an alternate metric for
tracking surface brightness limits.\\
\strut \\
The proposed metric is the limiting surface brightness, as defined by\\
Roman et al. (2020, A\&A, 644, 42), using sky sources for a given visit
and detector. This is defined as 3x the standard deviation of the
background flux distribution, averaged over 10" x 10" scales. A version
of this metric is being implemented in `analysis\_tools` on
\href{https://rubinobs.atlassian.net/browse/DM-51537}{DM-51537}, and
will be regularly monitored in future processing. For the sample of
images used in this test, the limiting surface brightness is measured to
be typically around 27.5-28 mag per square arcsecond, as seen in the
following figure:\\
\textbf{Image Download Error}


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1838 - Verify calculation of image fraction affected by ghosts }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1838}{\textit{ LVV-T1838 } }
test case in Jira.

Verify that the DM system provides code to assess whether the percentage
of image area that has ghosts with surface brightness gradient amplitude
of more than 1/3 of the sky noise over 1 arcsec is less than
\textbf{GhostAF = 1 percent}.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed at the USDF RSP, using w\_2025\_33. The resulting notebook
is attached to this test repository as "test\_LVV-T1838.ipynb".



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3546-1243142064:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3546-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
\textquotesingle DATA/path\textquotesingle, then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we used LSSTCam on-sky data processed with pipelines
version w\_2025\_33. The butler was initialized as follows:\\
\strut \\
butler = Butler(\textquotesingle/repo/embargo\textquotesingle,
collections="LSSTCam/runs/DRP/20250604\_20250814/w\_2025\_33/DM-52202")


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3546-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Examine a large number of warped visit images, confirming that less than
1\% of their pixels have been masked due to ghosts.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A table or histogram of percentages of pixels flagged as ghosts in a
large number of images (to constitute a representative sample).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we looped over 5000
`compare\_warp\_artifact\_mask` datasets, extracting for each one the
percentage of pixels that were flagged as CLIPPED during the masking.
The resulting histogram, shown below, demonstrates that we are meeting
the requirement that less than 1\% of pixels are affected by ghosts.\\
\strut \\
We note that the artifact rejection code identifies all anomalous
pixels, and not just those that are due to ghosts. Thus the statistics
we have measured represent an upper limit on the fraction of pixels
affected by ghosts, as other features such as asteroids contribute to
the CLIPPED mask plane as well.\\
\strut \\
\textbf{Image Download Error}


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1836 - Verify calculation of resolved-to-unresolved flux ratio errors }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Defined}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1836}{\textit{ LVV-T1836 } }
test case in Jira.

Verify that the DM system has provided code to assess whether the
maximum RMS of the ratio of the error in integrated flux measurement
between bright, isolated, resolved sources less than 10 arcsec in
diameter and bright, isolated unresolved point sources is less than
\textbf{ResSource = 2}.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1836.ipynb."\\
\strut \\
To allow for some flexibility in changing the method of calculating this
metric, it has not yet been implemented within `analysis\_tools`. Before
future large-scale data processing campaigns, this metric will be
incorporated into the `analysis\_tools` tasks and pipelines that are
executed as part of data release processing.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3548-1243142066:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3548-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
\protect\phantomsection\label{isPasted}{Identify a dataset containing at
least one tract that has been processed through coaddition to create an
objectTable.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use a recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3548-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\
\strut \\

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster ("lsst-dev"): /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

\hfill\break
From the command line, execute the commands below in the example code:\\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, \textquotesingle obs\textquotesingle{} packages
such as `obs\_subaru`), then additional `setup` commands will be
necessary.\\
\strut \\
To check versions in use, type:\\
eups list -s

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The pipelines were set up with w\_2024\_34.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3548-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
\textquotesingle DATA/path\textquotesingle, then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\begin{verbatim}
The processed RC2 data products are accessed via the Butler using the following commands:

from lsst.daf.butler import Butler
\end{verbatim}

\begin{verbatim}
# Initialize the butler repo pointing to the DM-45857 (w_2024_34) collection
repo = '/repo/main'
collection = 'HSC/runs/RC2/w_2024_34/DM-45857'

butler = Butler(repo, collections=collection)
\end{verbatim}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3548-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
On an `objectTable\_tract` table, execute the following steps:\\
\strut \\

\begin{itemize}
\tightlist
\item
  Apply a signal-to-noise (SNR) cut to select only bright sources.
  (Default: SNR \textgreater{} 100)
\item
  Select isolated objects based on the "detect\_isIsolated" flag.
\item
  Select galaxies and stars based on their "refSizeExtendedness" values.
\item
  Select only galaxies with diameters less than 10 arcsec (based on
  their moments-based trace sizes).
\item
  Bin the flux error values for (separately) selected bright, isolated
  stars and galaxies into magnitude bins.
\item
  Calculate the ratio of the median flux errors in each bin for resolved
  sources (galaxies) vs. unresolved (stars).
\item
  Report summary statistics aggregating the magnitude-binned ratios, and
  return these statistics (mean, median, stdev, etc. over all magnitude
  bins for the patch).
\end{itemize}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Summary values of the median ratio of resolved to unresolved flux errors
for bright, isolated sources in the objectTable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, this calculation is demonstrated for the three
tracts of data contained in RC2. The values of~\textbf{ResSource} are
represented by the "mean values" in the following output:\\
\strut \\

\begin{verbatim}
Mean values, stdev for each RC2 tract
-------------------------------------

tract 9615: mean=1.386, std=0.020
tract 9697: mean=1.438, std=0.071
tract 9813: mean=1.261, std=0.086
\end{verbatim}

The attached notebook also includes some plots illustrating how the
metric was calculated in detail.\\
\strut \\
We see that the values are well below the threshold (\textbf{ResSource
\textless{} 2}) defined in the requirement, and thus this test passes.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1746 - Verify calculation of fraction of relative astrometric measurement error
on 5 arcminute scales exceeding outlier limit }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1746}{\textit{ LVV-T1746 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the maximum
fraction of relative astrometric measurements on 5 arcminute scales that
exceed the 5 arcminute outlier limit \textbf{AD1 = 20 milliarcseconds},
and assess whether it meets the requirement that it shall be less than
\textbf{AF1 = 10 percent.}

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1746.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3550-1243142068:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3550-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use the most recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3550-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\
\strut \\

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster ("lsst-dev"): /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

\hfill\break
From the command line, execute the commands below in the example code:\\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, \textquotesingle obs\textquotesingle{} packages
such as `obs\_subaru`), then additional `setup` commands will be
necessary.\\
\strut \\
To check versions in use, type:\\
eups list -s

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The pipelines were set up with w\_2024\_34.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3550-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `analysis\_tools` on a repository containing processed data.
Identify the path to the data, which we will call
\textquotesingle DATA/path\textquotesingle, then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, "u/username/atools\_metrics")
containing metric measurements and any associated extras and metadata is
available via the butler.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\begin{verbatim}
The processed RC2 data products are accessed via the Butler using the following commands:

from lsst.daf.butler import Butler
\end{verbatim}

\begin{verbatim}
# Initialize the butler repo pointing to the DM-45857 (w_2024_34) collection
repo = '/repo/main'
collection = 'HSC/runs/RC2/w_2024_34/DM-45857'

butler = Butler(repo, collections=collection)
\end{verbatim}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3550-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AF1 has been calculated using the outlier limit
AD1, and that its values are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AF1 has been calculated (and used the limit AD1).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, the metrics were retrieved and printed to the
screen, resulting in the following output:\\

\begin{verbatim}
Tract 9615:

g_AF1 = 0.07 %
r_AF1 = 0.07 %
i_AF1 = 0.52 %

Tract 9697:

g_AF1 = 1.97 %
r_AF1 = 1.09 %
i_AF1 = 0.07 %

Tract 9813:

g_AF1 = 0.59 %
r_AF1 = 1.42 %
i_AF1 = 1.25 %
\end{verbatim}

\hfill\break
In the attached notebook, we also demonstrated the retrieval of plots
generated by `analysis\_tools` showing the distribution of source
separations from which \textbf{AF1} was calculated.\\
\strut \\
Finally, we confirmed via inspection of the relevant code that the AD1
threshold is set to 20 mas by default, as required.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1746.ipynb."


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1749 - Verify calculation of fraction of relative astrometric measurement error
on 20 arcminute scales exceeding outlier limit }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1749}{\textit{ LVV-T1749 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the maximum
fraction of relative astrometric measurements on 20 arcminute scales
that exceed the 20 arcminute outlier limit \textbf{AD2 = 20
milliarcseconds}, and assess whether it meets the requirement that it
shall be less than \textbf{AF2 = 10 percent.}

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1749.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3551-1243142069:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3551-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use the most recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3551-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\
\strut \\

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster ("lsst-dev"): /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

\hfill\break
From the command line, execute the commands below in the example code:\\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, \textquotesingle obs\textquotesingle{} packages
such as `obs\_subaru`), then additional `setup` commands will be
necessary.\\
\strut \\
To check versions in use, type:\\
eups list -s

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The pipelines were set up with w\_2024\_34.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3551-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `analysis\_tools` on a repository containing processed data.
Identify the path to the data, which we will call
\textquotesingle DATA/path\textquotesingle, then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, "u/username/atools\_metrics")
containing metric measurements and any associated extras and metadata is
available via the butler.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\begin{verbatim}
The processed RC2 data products are accessed via the Butler using the following commands:

from lsst.daf.butler import Butler
\end{verbatim}

\begin{verbatim}
# Initialize the butler repo pointing to the DM-45857 (w_2024_34) collection
repo = '/repo/main'
collection = 'HSC/runs/RC2/w_2024_34/DM-45857'

butler = Butler(repo, collections=collection)
\end{verbatim}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3551-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AF2 has been calculated using the outlier limit
AD2, and that its values are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AF2 has been calculated (and used the limit AD2).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, the metrics were retrieved and printed to the
screen, resulting in the following output:\\
\strut \\

\begin{verbatim}
Tract 9615:

g_AF2 = 0.06 %
r_AF2 = 0.05 %
i_AF2 = 0.45 %

Tract 9697:

g_AF2 = 2.01 %
r_AF2 = 1.08 %
i_AF2 = 0.06 %

Tract 9813:

g_AF2 = 0.70 %
r_AF2 = 1.35 %
i_AF2 = 1.33 %
\end{verbatim}

\hfill\break
In the attached notebook, we also demonstrated the retrieval of plots
generated by `analysis\_tools` showing the distribution of source
separations from which \textbf{AF2} was calculated.\\
\strut \\
Finally, we confirmed via inspection of the relevant code that the AD2
threshold is set to 20 mas by default, as required.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1749.ipynb."


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1750 - Verify calculation of separations relative to r-band exceeding color
difference outlier limit }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1750}{\textit{ LVV-T1750 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the
separations measured relative to the r-band that exceed the color
difference outlier limit \textbf{AB2 = 20 milliarcseconds}, and assess
whether it meets the requirement that it shall be less than \textbf{ABF1
= 10 percent.~}

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_37 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1750\_1753.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3552-1243142070:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3552-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and including at least one visit in r-band.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use the most recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3552-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\
\strut \\

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster ("lsst-dev"): /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

\hfill\break
From the command line, execute the commands below in the example code:\\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, \textquotesingle obs\textquotesingle{} packages
such as `obs\_subaru`), then additional `setup` commands will be
necessary.\\
\strut \\
To check versions in use, type:\\
eups list -s

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The pipelines were set up with w\_2024\_37.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3552-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `analysis\_tools` on a repository containing processed data.
Identify the path to the data, which we will call
\textquotesingle DATA/path\textquotesingle, then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, "u/username/atools\_metrics")
containing metric measurements and any associated extras and metadata is
available via the butler.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Because the relevant `analysis\_tools` tasks are not executed in the
default pipeline, we executed them manually by entering the following on
the command line:\\
\strut \\
pipetask run -b /repo/main -i HSC/runs/RC2/w\_2024\_34/DM-45857 -p
./visitQualityCore.yaml -o u/jcarlin/atools\_visitQualityCore\_AB1
-\/-instrument lsst.obs.subaru.HyperSuprimeCam
-\/-register-dataset-types -d
"skymap=\textquotesingle hsc\_rings\_v1\textquotesingle{} AND
instrument=\textquotesingle HSC\textquotesingle{} AND visit IN
(26044,26046,26048,26050,26058,23884,23886,23888,23890,23898,1302,1306,1308,1310,1314,23250,23256,23258,27090,27094)"
-j 6 2\textgreater\&1 \textbar{} tee
atools\_visitQualityCore\_AB1\_gri\_test.log\\
\strut \\
The list of visits contains 5 visits in each of the griz bands.\\
\strut \\
A butler with results from the processing is initialized using the
following commands:\\

\begin{verbatim}
repo = '/repo/main'
collection = 'u/jcarlin/atools_visitQualityCore_AB1'

butler = Butler(repo, collections=collection)
\end{verbatim}

\hfill\break


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3552-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric ABF1 has been calculated using the outlier limit
AB2, and that its values are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that ABF1 has been calculated (and used the limit AB2).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, the metrics were retrieved and printed to the
screen, resulting in the following output for the mean values of ABF1:\\

\begin{verbatim}
g
abf1_ra = 0.02 %
abf1_dec = 0.08 %
abf1_tot = 0.12 %

i
abf1_ra = 2.72 %
abf1_dec = 3.67 %
abf1_tot = 5.78 %

z
abf1_ra = 0.38 %
abf1_dec = 0.67 %
abf1_tot = 1.47 %
\end{verbatim}

\hfill\break
In the attached notebook, we also demonstrated the retrieval of plots
generated by `analysis\_tools` showing the distribution of source
separations from which \textbf{ABF1} was calculated.\\
\strut \\
Finally, we confirmed via inspection of the relevant code that the AB2
threshold is set to 20 mas by default, as required.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1750\_1753.ipynb."


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1753 - Verify calculation of RMS difference of separations relative to r-band }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1753}{\textit{ LVV-T1753 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the
separations measured relative to the r-band, and assess whether it meets
the requirement that it shall be less than \textbf{AB1 =
10~milliarcseconds.}

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_37 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1750\_1753.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3555-1243142073:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3555-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and including at least one visit in r-band.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use the most recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3555-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\
\strut \\

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster ("lsst-dev"): /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

\hfill\break
From the command line, execute the commands below in the example code:\\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, \textquotesingle obs\textquotesingle{} packages
such as `obs\_subaru`), then additional `setup` commands will be
necessary.\\
\strut \\
To check versions in use, type:\\
eups list -s

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The pipelines were set up with w\_2024\_37.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3555-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `analysis\_tools` on a repository containing processed data.
Identify the path to the data, which we will call
\textquotesingle DATA/path\textquotesingle, then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, "u/username/atools\_metrics")
containing metric measurements and any associated extras and metadata is
available via the butler.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Because the relevant `analysis\_tools` tasks are not executed in the
default pipeline, we executed them manually by entering the following on
the command line:\\
\strut \\
pipetask run -b /repo/main -i HSC/runs/RC2/w\_2024\_34/DM-45857 -p
./visitQualityCore.yaml -o u/jcarlin/atools\_visitQualityCore\_AB1
-\/-instrument lsst.obs.subaru.HyperSuprimeCam
-\/-register-dataset-types -d
"skymap=\textquotesingle hsc\_rings\_v1\textquotesingle{} AND
instrument=\textquotesingle HSC\textquotesingle{} AND visit IN
(26044,26046,26048,26050,26058,23884,23886,23888,23890,23898,1302,1306,1308,1310,1314,23250,23256,23258,27090,27094)"
-j 6 2\textgreater\&1 \textbar{} tee
atools\_visitQualityCore\_AB1\_gri\_test.log\\
\strut \\
The list of visits contains 5 visits in each of the griz bands.\\
\strut \\
A butler with results from the processing is initialized using the
following commands:\\

\begin{verbatim}
repo = '/repo/main'
collection = 'u/jcarlin/atools_visitQualityCore_AB1'

butler = Butler(repo, collections=collection)
\end{verbatim}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3555-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AB1 has been calculated, and that its values are
reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AB1 has been calculated.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, the metrics were retrieved and printed to the
screen, resulting in the following output for the mean values of AB1:\\

\begin{verbatim}
g
ab1_ra = 3.67 mas
ab1_dec = 4.40 mas
ab1_tot = 5.78 mas

i
ab1_ra = 8.62 mas
ab1_dec = 10.73 mas
ab1_tot = 11.62 mas

z
ab1_ra = 12.32 mas
ab1_dec = 11.27 mas
ab1_tot = 17.60 mas
\end{verbatim}

In the attached notebook, we also demonstrated the retrieval of plots
generated by `analysis\_tools` showing the distribution of source
separations from which \textbf{AB1} was calculated.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1750\_1753.ipynb."


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T129 - Verify implementation of Provide Calibrated Photometry }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T129}{\textit{ LVV-T129 } }
test case in Jira.

Verify that the DMS provides photometry calibrated in AB mags and fluxes
(in nJy) for all measured objects and sources. Must be tested for both
DRP and AP products.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test performed in the RSP using public Data Preview 1 (DP1) data
products, which are based on on-sky LSSTComCam data. The notebook is
attached to this test repository as "test\_LVV-T129.ipynb".



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3558-1243142076:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3558-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
\textquotesingle DATA/path\textquotesingle, then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Rather than the Butler, we used the public Qserv tables served via TAP
with DP1. In this way we ensure that we are verifying against
public-facing data products.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3558-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest the data products from an appropriate DRP-processed dataset.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we check each of the Object, Source,
DiaObject, DiaSource, ForcedSource, and ForcedSourceOnDiaObject tables,
by executing a spatial query of the DP1 dataset over a small area. Here
is an example query:\\
\strut \\
results = service.search("SELECT coord\_ra, coord\_dec, g\_psfFlux,
r\_cModelFlux FROM dp1.Object as obj WHERE
CONTAINS(POINT(\textquotesingle ICRS\textquotesingle, coord\_ra,
coord\_dec), CIRCLE(\textquotesingle ICRS\textquotesingle, 53.13,
-28.10, 0.05)) = 1").to\_table()


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3558-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that AB-calibrated magnitudes and fluxes are available for all
measured Sources and Objects. {[}An enhanced verification could include
matching the sources to an external source catalog and comparing the
magnitudes to show that they are well-calibrated.{]}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Calibrated fluxes and magnitudes are available for all sources, as well
as tools to convert measured fluxes to magnitudes (and vice-versa).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, each table is checked to confirm that its
units are calibrated to (and specified as) nJy. The units are reported
as being in nJy for all columns containing flux measurements.\\
\strut \\
We further checked that the fluxes converted to magnitudes produce
reasonable outputs. The following plot illustrates this for two flux/mag
measurements from the Object table:\\
\textbf{Image Download Error}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3558-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest the data products from an appropriate AP processing dataset.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
See step 2, where this was already performed.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3558-5 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that AB-calibrated magnitudes and fluxes are available for all
measured Sources, DIASources, and Objects. {[}An enhanced verification
could include matching the sources to an external source catalog and
comparing the magnitudes to show that they are well-calibrated.{]}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Calibrated fluxes and magnitudes are available for all Sources,
DIASources, and Objects, as well as tools to convert measured fluxes to
magnitudes (and vice-versa).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, each table is checked to confirm that its
units are calibrated to (and specified as) nJy. The units are reported
as being in nJy for all columns containing flux measurements, with the
exception of the `dipoleMeanFlux` column from the DiaSource table.\\
\strut \\
We confirmed that the units on the `dipoleMeanFlux` column are simply
listed incorrectly in the table schema.~A ticket has been filed to fix
this:~\href{https://rubinobs.atlassian.net/browse/DM-51812}{DM-51812:
"DP1 dipole flux description inconsistencies"}. The error is simply a
mistake in moving the schema from its location in the Science Pipelines
codebase to the DP1 repository.\\
\strut \\
We further checked that the `dipoleMeanFluxes` converted to magnitudes
produce reasonable outputs. The following plot illustrates this for the
dipole fluxes with and without their errors added:\\
\textbf{Image Download Error}\\
We have thus confirmed that all fluxes are provided as calibrated values
in nJy, with the single exception of one column in the DiaSource table,
which is being fixed. The result of this test is thus a Pass.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T30 - Verify implementation of Wavefront Sensor Data Acquisition }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T30}{\textit{ LVV-T30 } }
test case in Jira.

Verify successful ingestion of wavefront sensor data from LSSTCam

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3559-1243142077:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3559-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the test script DMTR-412/notebooks/test\_LVV-T30.ipynb in
https://github.com/lsst-dm/DMTR-412/tree/main

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Notebook ran successfully on all LSSTCam commissioning data taken from
the date of first photon until mid August.~


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3559-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Look at the statistics reported, check that we have acquired the data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Well-formed wavefront sensor image data with appropriate associated
metadata.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\begin{verbatim}
From 2025-04-15 through 2025-08-16  172728 wavefront sensor (ccd) images have been recorded  in a total of 21591 unique science exposures with LSSTCam. 
The exposures are stored in files at the USDF. The files were read in and the images inspected
All exposures have the full 8 wavefront sensor images, as expected. None are missing ccd images.

For a random selection of 3 exposures, thhe wavefront sensor images are inspected and show well formed images with donuts.
This notebook that the DMS can acquire raw, full-frame exposures from the camera wavefront sensors.
\end{verbatim}


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T29 - Verify implementation of Raw Science Image Data Acquisition }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T29}{\textit{ LVV-T29 } }
test case in Jira.

Verify acquisition of raw data from an LSST camera in all modes.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T29.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3560-1243142078:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3560-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
{Obtain images from a camera (either real or simulated) in each
observing mode.\\
}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
CCD images ingested into the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use images from a recent Auxtel imaging night. To
access these images in the USDF RSP, we execute the following:\\
\strut \\
from lsst.daf.butler import Butler\\
\strut \\
\# Initialize the butler repo pointing to the LATISS/raw/all
collection\\
repo = \textquotesingle/repo/embargo\_new\textquotesingle{}\\
collection = \textquotesingle LATISS/raw/all\textquotesingle{}\\
\strut \\
butler = Butler(repo, collections={[}collection{]})


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3560-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
O{bserve that the images and their metadata are present and queryable in
the Data Backbone.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Well-formed image data with appropriate associated metadata.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we demonstrate that the raw LATISS images can
be queried as follows:\\
\strut \\
flats = butler.query\_datasets(\textquotesingle raw\textquotesingle,
where="day\_obs=20240807 AND
instrument=\textquotesingle LATISS\textquotesingle{} AND band in
(\textquotesingle g\textquotesingle,\textquotesingle r\textquotesingle,\textquotesingle i\textquotesingle,\textquotesingle z\textquotesingle,\textquotesingle y\textquotesingle)
AND exposure.observation\_type=\textquotesingle flat\textquotesingle")\\
\strut \\
Example images are then examined, including confirming that metadata and
objects made up of translated versions of those metadata are available.
We also displayed the images, confirming that they are well-formed and
look as expected for raw images.\\
\strut \\
Finally, the attached notebook looks at the LSST Science Pipelines "obs"
packages in some detail. For more information about these, see
\href{https://github.com/lsst/obs_base}{lsst.obs\_base} for the base
class, \href{https://github.com/lsst/obs_lsst}{lsst.obs\_lsst} for
implementations of various LSST cameras, and
\href{https://pipelines.lsst.io/modules/lsst.obs.base/creating-an-obs-package.html}{this
guidance} about how to set up an obs package.\\
\strut \\
We have demonstrated that raw images can be obtained with an LSST
camera, and that the interfaces exist to transform them as needed and
ingest them into the Butler. The result of this test is a \textbf{Pass}.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T2297 - Verify implementation of Science Data Archive }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T2297}{\textit{ LVV-T2297 } }
test case in Jira.

Verify that a Science Data Archive has been created ~and that all LSST
public data products have been archived together with the raw data
necessary to reproduce them. ~Verify that the archive is scalable to the
data from the full survey and all Data Releases.\\
\strut \\
This requirement will be verified by analysis. Verification must
demonstrate that we have a written plan for how data will be archived
and that the storage systems needed exist. The plan should include
details on recovery. ~This is needed before commissioning to support
commissioning data taking.~

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3561-1243142079:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3561-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check that all LSST public data products have been archived at the
Science Data Archive

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
DP1 data are archived at the USDF in repository /repo/dp1, collection
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260. Here we will demonstrate via
queries that the datasets are present in this repo.\\
\strut \\
butler query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 raw \textbar{} wc\\
16129 161270 2402925\\
\strut \\
butler query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 visit\_image \textbar{} wc\\
15976 143766 2731556\\
\strut \\
butler query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 difference\_image \textbar{}
wc\\
15976 143766 2811426\\
\strut \\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 dia\_source \textbar{} wc\\
29 135 3404\\
\strut \\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 deep\_coadd \textbar{} wc\\
2648 18522 362504\\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ butler
query-datasets /repo/dp1 -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0/DM-50260 object \textbar{} wc\\
33 155 3784\\
\strut \\
Now confirm that the same numbers of each dataset type are present in
the repository at /repo/main:\\
\strut \\
butler query-datasets /repo/main -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 object \textbar{} wc\\
33 155 3908\\
butler query-datasets /repo/main -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 deep\_coadd \textbar{}
wc 2648 18522 373088\\
butler query-datasets /repo/main -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 difference\_image
\textbar{} wc\\
15976 143766 2875322\\
butler query-datasets /repo/main -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 dia\_source \textbar{}
wc\\
29 135 3512\\
butler query-datasets /repo/main -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 visit\_image \textbar{}
wc\\
15976 143766 2795452\\
butler query-datasets /repo/main -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098
preliminary\_visit\_image \textbar{} wc\\
16129 145143 3015751\\
butler query-datasets /repo/main -\/-collections
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 raw \textbar{} wc\\
16129 161270 2402925\\
\strut \\
We see that the number of datasets agrees, suggesting that the full DP1
dataset has indeed been archived at /repo/dp1.\\
\strut \\
Furthermore, the raw images that contributed to DP1 are archived
separately. Examine the file tree to confirm that the files are there.\\
\strut \\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ ls
/sdf/data/rubin/lsstdata/offline/instrument/LSSTComCam/\\
20240801/ 20241024/ 20241031/ 20241107/ 20241114/ 20241121/ 20241128/
20241205/ gen2repo/ log/ reingest\_log\_20201111.txt\\
20240806/ 20241025/ 20241101/ 20241108/ 20241115/ 20241122/ 20241129/
20241206/ gen2repo\_20200716/ \textbf{reingest\_day.sh}*
reingest\_log\_20201130.txt\\
20240807/ 20241026/ 20241102/ 20241109/ 20241116/ 20241123/ 20241130/
20241207/ gen2repo\_20200721/ reingest\_log\_20200716.txt
\textbf{remake\_gen2repo.sh}*\\
20240808/ 20241027/ 20241103/ 20241110/ 20241117/ 20241124/ 20241201/
20241208/ gen2repo\_20200727/ reingest\_log\_20200721.txt
\textbf{remake\_gen3repo.sh}*\\
20241021/ 20241028/ 20241104/ 20241111/ 20241118/ 20241125/ 20241202/
20241209/ gen3repo/ reingest\_log\_20200727.txt storage/\\
20241022/ 20241029/ 20241105/ 20241112/ 20241119/ 20241126/ 20241203/
20241210/ gen3repo\_20201111/ reingest\_log\_20201022.txt
tempfilelist\_single\\
20241023/ 20241030/ 20241106/ 20241113/ 20241120/ 20241127/ 20241204/
20241211/ gen3repo\_20201130/ reingest\_log\_20201109.txt\\
\strut \\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ ls
/sdf/data/rubin/lsstdata/offline/instrument/LSSTComCam/20241024/\\
CC\_O\_20241024\_000001/ CC\_O\_20241024\_000033/
CC\_O\_20241024\_000065/ CC\_O\_20241024\_000097/
CC\_O\_20241024\_000129/ CC\_O\_20241024\_000161/
CC\_O\_20241024\_000193/\\
CC\_O\_20241024\_000002/ CC\_O\_20241024\_000034/
CC\_O\_20241024\_000066/ CC\_O\_20241024\_000098/
CC\_O\_20241024\_000130/ CC\_O\_20241024\_000162/
CC\_O\_20241024\_000194/\\
CC\_O\_20241024\_000003/ CC\_O\_20241024\_000035/
CC\_O\_20241024\_000067/ CC\_O\_20241024\_000099/
CC\_O\_20241024\_000131/ CC\_O\_20241024\_000163/
CC\_O\_20241024\_000195/\\
CC\_O\_20241024\_000004/ CC\_O\_20241024\_000036/
CC\_O\_20241024\_000068/ CC\_O\_20241024\_000100/
CC\_O\_20241024\_000132/ CC\_O\_20241024\_000164/
CC\_O\_20241024\_000196/\\
CC\_O\_20241024\_000005/ CC\_O\_20241024\_000037/
CC\_O\_20241024\_000069/ CC\_O\_20241024\_000101/
CC\_O\_20241024\_000133/ CC\_O\_20241024\_000165/
CC\_O\_20241024\_000197/\\
CC\_O\_20241024\_000006/ CC\_O\_20241024\_000038/
CC\_O\_20241024\_000070/ CC\_O\_20241024\_000102/
CC\_O\_20241024\_000134/ CC\_O\_20241024\_000166/
CC\_O\_20241024\_000198/\\
CC\_O\_20241024\_000007/ CC\_O\_20241024\_000039/
CC\_O\_20241024\_000071/ CC\_O\_20241024\_000103/
CC\_O\_20241024\_000135/ CC\_O\_20241024\_000167/
CC\_O\_20241024\_000199/\\
CC\_O\_20241024\_000008/ CC\_O\_20241024\_000040/
CC\_O\_20241024\_000072/ CC\_O\_20241024\_000104/
CC\_O\_20241024\_000136/ CC\_O\_20241024\_000168/
CC\_O\_20241024\_000200/\\
CC\_O\_20241024\_000009/ CC\_O\_20241024\_000041/
CC\_O\_20241024\_000073/ CC\_O\_20241024\_000105/
CC\_O\_20241024\_000137/ CC\_O\_20241024\_000169/
CC\_O\_20241024\_000201/\\
CC\_O\_20241024\_000010/ CC\_O\_20241024\_000042/
CC\_O\_20241024\_000074/ CC\_O\_20241024\_000106/
CC\_O\_20241024\_000138/ CC\_O\_20241024\_000170/
CC\_O\_20241024\_000202/\\
CC\_O\_20241024\_000011/ CC\_O\_20241024\_000043/
CC\_O\_20241024\_000075/ CC\_O\_20241024\_000107/
CC\_O\_20241024\_000139/ CC\_O\_20241024\_000171/
CC\_O\_20241024\_000203/\\
CC\_O\_20241024\_000012/ CC\_O\_20241024\_000044/
CC\_O\_20241024\_000076/ CC\_O\_20241024\_000108/
CC\_O\_20241024\_000140/ CC\_O\_20241024\_000172/
CC\_O\_20241024\_000204/\\
CC\_O\_20241024\_000013/ CC\_O\_20241024\_000045/
CC\_O\_20241024\_000077/ CC\_O\_20241024\_000109/
CC\_O\_20241024\_000141/ CC\_O\_20241024\_000173/
CC\_O\_20241024\_000205/\\
CC\_O\_20241024\_000014/ CC\_O\_20241024\_000046/
CC\_O\_20241024\_000078/ CC\_O\_20241024\_000110/
CC\_O\_20241024\_000142/ CC\_O\_20241024\_000174/
CC\_O\_20241024\_000206/\\
CC\_O\_20241024\_000015/ CC\_O\_20241024\_000047/
CC\_O\_20241024\_000079/ CC\_O\_20241024\_000111/
CC\_O\_20241024\_000143/ CC\_O\_20241024\_000175/
CC\_O\_20241024\_000207/\\
CC\_O\_20241024\_000016/ CC\_O\_20241024\_000048/
CC\_O\_20241024\_000080/ CC\_O\_20241024\_000112/
CC\_O\_20241024\_000144/ CC\_O\_20241024\_000176/
CC\_O\_20241024\_000208/\\
CC\_O\_20241024\_000017/ CC\_O\_20241024\_000049/
CC\_O\_20241024\_000081/ CC\_O\_20241024\_000113/
CC\_O\_20241024\_000145/ CC\_O\_20241024\_000177/
CC\_O\_20241024\_000209/\\
CC\_O\_20241024\_000018/ CC\_O\_20241024\_000050/
CC\_O\_20241024\_000082/ CC\_O\_20241024\_000114/
CC\_O\_20241024\_000146/ CC\_O\_20241024\_000178/
CC\_O\_20241024\_000210/\\
CC\_O\_20241024\_000019/ CC\_O\_20241024\_000051/
CC\_O\_20241024\_000083/ CC\_O\_20241024\_000115/
CC\_O\_20241024\_000147/ CC\_O\_20241024\_000179/
CC\_O\_20241024\_000211/\\
CC\_O\_20241024\_000020/ CC\_O\_20241024\_000052/
CC\_O\_20241024\_000084/ CC\_O\_20241024\_000116/
CC\_O\_20241024\_000148/ CC\_O\_20241024\_000180/
CC\_O\_20241024\_000212/\\
CC\_O\_20241024\_000021/ CC\_O\_20241024\_000053/
CC\_O\_20241024\_000085/ CC\_O\_20241024\_000117/
CC\_O\_20241024\_000149/ CC\_O\_20241024\_000181/
CC\_O\_20241024\_000213/\\
CC\_O\_20241024\_000022/ CC\_O\_20241024\_000054/
CC\_O\_20241024\_000086/ CC\_O\_20241024\_000118/
CC\_O\_20241024\_000150/ CC\_O\_20241024\_000182/
CC\_O\_20241024\_000214/\\
CC\_O\_20241024\_000023/ CC\_O\_20241024\_000055/
CC\_O\_20241024\_000087/ CC\_O\_20241024\_000119/
CC\_O\_20241024\_000151/ CC\_O\_20241024\_000183/
CC\_O\_20241024\_000215/\\
CC\_O\_20241024\_000024/ CC\_O\_20241024\_000056/
CC\_O\_20241024\_000088/ CC\_O\_20241024\_000120/
CC\_O\_20241024\_000152/ CC\_O\_20241024\_000184/
CC\_O\_20241024\_000216/\\
CC\_O\_20241024\_000025/ CC\_O\_20241024\_000057/
CC\_O\_20241024\_000089/ CC\_O\_20241024\_000121/
CC\_O\_20241024\_000153/ CC\_O\_20241024\_000185/
CC\_O\_20241024\_000217/\\
CC\_O\_20241024\_000026/ CC\_O\_20241024\_000058/
CC\_O\_20241024\_000090/ CC\_O\_20241024\_000122/
CC\_O\_20241024\_000154/ CC\_O\_20241024\_000186/
CC\_O\_20241024\_000218/\\
CC\_O\_20241024\_000027/ CC\_O\_20241024\_000059/
CC\_O\_20241024\_000091/ CC\_O\_20241024\_000123/
CC\_O\_20241024\_000155/ CC\_O\_20241024\_000187/
CC\_O\_20241024\_000219/\\
CC\_O\_20241024\_000028/ CC\_O\_20241024\_000060/
CC\_O\_20241024\_000092/ CC\_O\_20241024\_000124/
CC\_O\_20241024\_000156/ CC\_O\_20241024\_000188/\\
CC\_O\_20241024\_000029/ CC\_O\_20241024\_000061/
CC\_O\_20241024\_000093/ CC\_O\_20241024\_000125/
CC\_O\_20241024\_000157/ CC\_O\_20241024\_000189/\\
CC\_O\_20241024\_000030/ CC\_O\_20241024\_000062/
CC\_O\_20241024\_000094/ CC\_O\_20241024\_000126/
CC\_O\_20241024\_000158/ CC\_O\_20241024\_000190/\\
CC\_O\_20241024\_000031/ CC\_O\_20241024\_000063/
CC\_O\_20241024\_000095/ CC\_O\_20241024\_000127/
CC\_O\_20241024\_000159/ CC\_O\_20241024\_000191/\\
CC\_O\_20241024\_000032/ CC\_O\_20241024\_000064/
CC\_O\_20241024\_000096/ CC\_O\_20241024\_000128/
CC\_O\_20241024\_000160/ CC\_O\_20241024\_000192/\\
\strut \\
(lsst-scipipe-10.0.0) {[}jcarlin@sdfiana032 archive\_tests{]}\$ ls
/sdf/data/rubin/lsstdata/offline/instrument/LSSTComCam/20241024/CC\_O\_20241024\_000125/\\
CC\_O\_20241024\_000125\_R22\_S00.fits~~CC\_O\_20241024\_000125\_R22\_S02.json~~CC\_O\_20241024\_000125\_R22\_S12.fits~~CC\_O\_20241024\_000125\_R22\_S21.json\\
CC\_O\_20241024\_000125\_R22\_S00.json~~CC\_O\_20241024\_000125\_R22\_S10.fits~~CC\_O\_20241024\_000125\_R22\_S12.json~~CC\_O\_20241024\_000125\_R22\_S22.fits\\
CC\_O\_20241024\_000125\_R22\_S01.fits~~CC\_O\_20241024\_000125\_R22\_S10.json~~CC\_O\_20241024\_000125\_R22\_S20.fits~~CC\_O\_20241024\_000125\_R22\_S22.json\\
CC\_O\_20241024\_000125\_R22\_S01.json~~CC\_O\_20241024\_000125\_R22\_S11.fits~~CC\_O\_20241024\_000125\_R22\_S20.json\\
CC\_O\_20241024\_000125\_R22\_S02.fits
CC\_O\_20241024\_000125\_R22\_S11.json
CC\_O\_20241024\_000125\_R22\_S21.fits\\
\strut \\
We note also that Prompt data products will be in
/sdf/data/rubin/repo/prompt/.\\
\strut \\
We have demonstrated that the DP1 data products are archived.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3561-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test that the public data products can be reproduced from the raw data
stored at the archive.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Because the archived DP1 data products are in a read-only butler (at
/repo/dp1), we demonstrate this capability based on the DP1 processing
that is in /repo/main. The initial ISR processing steps to go from raw
images to `preliminary\_visit\_image`s (which are not retained in DP1,
and thus must be reproduced) can be run as follows:\\
\strut \\
pipetask run -j 12 -b /repo/main -i
LSSTComCam/runs/DRP/DP1/v29\_0\_0\_rc6/DM-50098 -p
\$DRP\_PIPE\_DIR/pipelines/LSSTComCam/DRP-v2.yaml\#step1a-single-visit-detectors
-o u/jcarlin/dp1\_repro\_pvi -\/-instrument lsst.obs.lsst.LsstComCam
-\/-register-dataset-types -d
"skymap=\textquotesingle lsst\_cells\_v1\textquotesingle{} AND visit IN
(2024121100609, 2024121100610, 2024121100611)" 2\textgreater\&1
\textbar{} tee dp1\_repro\_pvi\_test.log\\
\strut \\
After that pipeline task has successfully executed, one can open
ipython, then execute the following to load the
`preliminary\_visit\_image` and examine it:\\
\strut \\
from lsst.daf.butler import Butler\\
butler = Butler(\textquotesingle/repo/main\textquotesingle,
collections={[}\textquotesingle u/jcarlin/dp1\_repro\_pvi\textquotesingle{]})\\
\strut \\
\% load dataset references from the output collection containing the
data that was just processed:\\
In {[}\textbf{12}{]}:~refs =
butler.query\_datasets(\textquotesingle preliminary\_visit\_image\textquotesingle,
collections={[}\textquotesingle u/jcarlin/dp1\_repro\_pvi/20250715T193639Z\textquotesingle{]})\\
\strut \\
In {[}\textbf{13}{]}:~len(refs)\\
Out{[}\textbf{13}{]}: 27\\
\strut \\
\% There are 27 datasets because we processed 3 visits, each of which
contains 9 detectors.\\
\strut \\
In {[}\textbf{14}{]}:~pvi = butler.get(refs{[}13{]})\\
\strut \\
In {[}\textbf{15}{]}:~pvi\\
Out{[}\textbf{15}{]}: \textless lsst.afw.image.\_exposure.ExposureF at
0x7f58baa81930\textgreater{}\\
\strut \\
In {[}\textbf{18}{]}:~pvi.getBBox()\\
Out{[}\textbf{18}{]}: Box2I(corner=Point2I(0, 0),
dimensions=Extent2I(4072, 4000))\\
\strut \\
We see that the image is an ExposureF object with the expected extent,
and thus conclude that the processing recreated the expected
intermediate data products.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3561-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test that the archive is scalable to the full survey data volume.~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
All raws, data releases, and prompt data products will be accessible via
Weka S3 object store (as they are currently at the SDF). Weka is
scalable storage, so the archive is easily scalable to the full survey
data volume.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1612 - Verify Summit - Base Network Integration (System Level) }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1612}{\textit{ LVV-T1612 } }
test case in Jira.

Verify ISO Layer 3 full (22 x 10 Gbps ethernet ports on DAQ side with
test data from DAQ test stand, AURA, Camera DAQ team do test).
Demonstrate transfer of data at or exceeding rates specified in \citeds{LDM-142}.

\textbf{ Preconditions}:\\ \begin{enumerate}
\tightlist
\item
  PMCS DMTC-7400-2400 COMPLETE
\item
  \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/1401}{LVV-T1168}
  Passed
\item
  EITHER: Full Camera DAQ installed on summit and loaded with data OR:
  high-quality DAQ application-level simulators that match the form,
  volume, file paths, compressibility, and cadence of the expected
  instrument data, running on end node computers that are the production
  hardware or equivalent to it. Scientific validity of the data content
  is not essential.
\item
  Archiver/forwarders installed at Base running on end node computers
  that are the production hardware or equivalent to it.
\item
  As-built documentation for all of the above is available.
\end{enumerate}

NOTE: This test will be repeated at increasing data volumes as
additional observatory capabilities (e.g. ComCAM, FullCam) become
available. Final verification will be tested at full operational
volume.After the initial test, the corresponding verification elements
will be flagged as ``Requires Monitoring'' such that those requirements
will be closed out as having been verified but will continue to be
monitored throughout commissioning to ensure they do not drop out of
compliance. This will also be monitored for end to end Summit - Data
Facility transfers during Commissioning.


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3647-1243142145:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3647-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify Pre-conditions are satisfied.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
NA

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Pre-conditions are satisfied.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Pre-conditions are met, T1168 is passed


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3647-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Transfer data between summit and base over uninterrupted 1 day period.
~Monitor transfer of data at or exceeding rates specified in LDM-142.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
DAQ pre-loaded data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Data transfers at or exceeding rates specified in LDM-142.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Summit - Base links are operational. It has been used many times during
night runs. The link is 6x100 and 2x100\\
\textbf{Image Download Error}


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1168 - Verify Summit - Base Network Integration }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1168}{\textit{ LVV-T1168 } }
test case in Jira.

Verify the integration of the summit to base network by demonstrating a
sustained and uninterrupted transfer of data between summit and base
over 1 day period at or exceeding rates specified in \citeds{LDM-142}. Done in 3
phases in collaboration with equipment/installation vendors (see test
procedure).

\textbf{ Preconditions}:\\ PMCS DMTC-7400-2330 COMPLETE\\
By phase:

\begin{enumerate}
\tightlist
\item
  Posts from Cerro Pachon to AURA Gatehouse repaired/improved. ~Fiber
  installed on posts from Cerro Pachon to AURA Gatehouse. ~Fiber
  installed from AURA Gatehouse to AURA compound in La Serena. OTDR
  purchased.
\item
  AURA DWDM installed in caseta on Cerro Pachon and in existing computer
  room in La Serena. ~DTN installed in La Serena. ~DTN loaded with
  software and test data staged.
\item
  Base Data Center (BDC) ready for installation of LSST DWDM. ~Fiber
  connecting existing computer room to BDC. ~LSST DWDM equipment
  installed in Summit Computer Room and BDC.
\end{enumerate}


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3648-1243142146:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3648-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test optical fiber with OTDR:\\
Installation of fiber optic cables and Optical Time Domain Reflector
(OTDR) fiber testing (completed 20170602
\href{https://docushare.lsstcorp.org/docushare/dsweb/Get/Document-26270/RD10\%20Report\%20of\%20delivery\%20of\%20LS\%20-\%20AG\%20fiber\%20from\%20Telefonica\%20to\%20REUNA.pdf}{REUNA
deliverable RD10})

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
OTDR generated optical data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Fiber tested to within acceptable Db.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Completed ad per document indicated and in section "Annex1: OTDR
Measures"


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3648-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test AURA DWDM:\\
Installation of AURA DWDM and Data Transfer Node (DTN) (completed
20171218
\href{https://docushare.lsst.org/docushare/dsweb/Get/DMTR-82/DMTR-82.pdf}{DMTR-82})

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
DTN perfSonar generated data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Summit - Base bandwidth and latency within specifications

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Completed and DTN reachable at dnt01.ls.lsst.org


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3648-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test LSST DWDM:\\
Installation of LSST DWDM and Bit Error Rate Tester (BERT) data
(completed 20190505
\href{https://docushare.lsstcorp.org/docushare/dsweb/View/Collection-7743}{collection-7743},
20191108
\href{https://docushare.lsstcorp.org/docushare/dsweb/Get/Document-35302/DAQ\%20DWDM\%20connection\%20tests\%2020191109.pptx}{DAQ
DWDM Connection Tests})

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
BERT generated data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Summit - Base bandwidth, latency, bit error rate within specifications

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Completed as per documents


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1097 - Verify Summit Facility Network Implementation }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1097}{\textit{ LVV-T1097 } }
test case in Jira.

Verify that data acquired by a AuxTel DAQ can be transferred to Summit
DWDM and loaded in the EFD without problems.

\textbf{ Preconditions}:\\ \begin{enumerate}
\tightlist
\item
  Summit Control Network and Camera Data Backbone installed and
  operating properly.
\item
  Summit - Base Network installed and operating properly.
\item
  EITHER: AuxTel hardware and control systems are functional with
  LATISS. AuxTel TCS, AuxTel EFD, AuxTel CCS, AuxTel DAQ are connected
  via Control Network on Summit to Rubin Observatory DWDM (with at least
  2 x 10 Gbps ethernet port client cards) OR: high-quality DAQ
  application-level simulators that match the form, volume, file paths,
  compressibility, and cadence of the expected instrument data, running
  on end node computers that are the production hardware or equivalent
  to it. Scientific validity of the data content is not essential.
\item
  AuxTel Archiver/forwarders installed in Summit and operating properly
  running on end node computers that are the production hardware or
  equivalent to it.
\item
  As-built documentation for all of the above is available.
\end{enumerate}

NOTE: This test will be repeated at increasing data volumes as
additional observatory capabilities (e.g. ComCAM, LSSTCam) become
available. ~Final verification will be tested at full operational
volume. After the initial test, the corresponding verification elements
will be flagged as ``Requires Monitoring'' such that those requirements
will be closed out as having been verified but will continue to be
monitored throughout commissioning to ensure they do not drop out of
compliance. ~This will also be monitored for end to end Summit - Data
Facility transfers during Commissioning.


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3649-1243142147:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3649-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify the pre-conditions have been satisfied

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
NA

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Pre-conditions are satisfied.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Pre-conditions are met. ComCam was on sky, we used it instead of Auxtel


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3649-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Control the AuxTel through a night of Observing. ~While observing, read
out LATISS data and transfer to Rubin Observatory Summit DWDM while
monitoring latency.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
LATISS images and metadata

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Data is fed to DWDM without delays or errors.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
From Nightlog, ComCam didnt have any problems observing during the
night, data was transfer to USDF, the following link is a plot the night
transfer\\
https://usdf-rsp-dev.slac.stanford.edu/times-square/github/lsst-dm/image-transfers-info/ImageLatency-Summit-USDF?day=20241202\&instrument=LSSTComCam\&ts\_hide\_code=1


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3649-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that data acquired by a AuxTel DAQ can be transferred ~and loaded
in EFD without problems.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
LATISS images and metadata

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Examine the EFD to ensure that the data has been loaded properly.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
ComCam data was feed into EFD and visible by Chronograf\\
https://summit-lsp.lsst.codes/chronograf/sources/1/dashboards/53?refresh=Paused\&lower=2024-12-02T17\%3A49\%3A00.000Z\&upper=2024-12-03T17\%3A49\%3A00.000Z


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T192 - Verify implementation of Base Wireless LAN (WiFi) }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T192}{\textit{ LVV-T192 } }
test case in Jira.

Verify as-built wireless network at the Base Facility supports
minBaseWiFi bandwidth (1000 Mbs).

\textbf{ Preconditions}:\\ \begin{enumerate}
\tightlist
\item
  Base Wireless LAN is installed/configured and Test Personnel have
  accounts for email, internet access.
\item
  As-built documentation for all of the above is available.
\end{enumerate}


Execution status: {\bf Pass }\\
Final comment:\\None



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3651-1244810980:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3651-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Connect to Rubin Base wireless network RubinObs-Guest by scanning the QR
code

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Connection to network is successful

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Connection successful with full strength showing~\textbf{Image Download
Error}


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3651-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Disconnect from Rubin Base wireless and connect again using the provided
SSID/pasaswd combination

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Connection to Network is successful

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Successful connection


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3651-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute ~script scripts/LVV\_T192.sh that tests connection to external
sites, file download and runs a network speed test

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Verify as-built wireless network at the Base Facility supports regular
work activities. Verify wireless signal strength meets or exceeds
typical, and average and peak bandwidths and that \hspace{0pt}web
browsing, download and connection to external sites is possible

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Successful connection to external sites and download if a file.~ Network
speed reported as\\
Download Speed: 282.29 Mbit/s\\
Upload Speed: 268.29 Mbit/s\\
Ping Time: 14.934 ms


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1751 - Verify calculation of median relative astrometric measurement error on
200 arcminute scales }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1751}{\textit{ LVV-T1751 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the median
relative astrometric measurement error on 200 arcminute scales and
assess whether it meets the requirement that it shall be no more than
AM3 = 15 milliarcseconds.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1751\_AM1\_AM2.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3734-1288390608:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3734-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and that has previously gone through Data Release
Processing, including calculation of data quality metrics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use a recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3734-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Retrieve the AM1 and AM2 metrics calculated for this dataset to
demonstrate that they have been measured and are well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
AM1 and AM2 metrics for the dataset.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we demonstrate the retrieval of these metrics.
The results are as follows:\\
\strut \\

\begin{verbatim}
Tract 9615:

g_AM1 = 3.8231023494070002 mas
r_AM1 = 3.228288002351153 mas
i_AM1 = 3.728593216447628 mas


g_AM2 = 3.7467052200092983 mas
r_AM2 = 3.132794128702427 mas
i_AM2 = 3.6810483122240245 mas

Tract 9697:

g_AM1 = 6.658043997359657 mas
r_AM1 = 6.140262782686699 mas
i_AM1 = 3.5977059787241354 mas


g_AM2 = 6.993080826381683 mas
r_AM2 = 6.28257099305163 mas
i_AM2 = 3.497105717983318 mas

Tract 9813:

g_AM1 = 4.994415732783283 mas
r_AM1 = 4.472256088715839 mas
i_AM1 = 4.839994490987725 mas


g_AM2 = 5.155219088191533 mas
r_AM2 = 4.512034918398069 mas
i_AM2 = 4.957150406798739 mas
\end{verbatim}

\hfill\break


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3734-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The same pipelines tasks that produce AM1 and AM2 can be reconfigured to
calculate the metric at any spatial scale. Demonstrate via inspection of
the relevant code that this is the case.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Code snippets that show the configurability of the size scale for AMx
metrics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The
\href{https://github.com/lsst/analysis_tools/blob/2b45b7d01314f84ce12d05144fb9ae7110de62b8/python/lsst/analysis/tools/atools/astrometricRepeatability.py\#L209-L215}{task}
to calculate the AMx (i.e., AM1, AM2, AM3) metrics begins with the
following configuration options:\\
\strut \\
class AstrometricRelativeRepeatability(AnalysisTool):\\
"""Calculate the AMx, ADx, AFx metrics and make histograms showing the
data\\
used to compute the metrics.\\
"""\\
\strut \\
fluxType = Field{[}str{]}(doc="Flux type to calculate repeatability
with", default="psfFlux")\\
xValue = Field{[}int{]}(doc="Metric suffix corresponding to annulus size
(1, 2, or 3)", default=1)\\
\strut \\
The
\href{https://github.com/lsst/analysis_tools/blob/w.2024.34/pipelines/matchedVisitQualityCore.yaml}{pipeline}
that calls this task is where the annulus size for calculation is
specified. Here are the relevant lines from the pipeline YAML
configuration for AM1, AM2, and AM3:\\
\strut \\
\strut ~ ~ ~ atools.stellarAstrometricRepeatability1:
AstrometricRelativeRepeatability\\
atools.stellarAstrometricRepeatability1.xValue: 1\\
atools.stellarAstrometricRepeatability1.process.calculateActions.rms.annulus:
5\\
atools.stellarAstrometricRepeatability2:
AstrometricRelativeRepeatability\\
atools.stellarAstrometricRepeatability2.xValue: 2\\
atools.stellarAstrometricRepeatability2.process.calculateActions.rms.annulus:
20\\
atools.stellarAstrometricRepeatability3:
AstrometricRelativeRepeatability\\
atools.stellarAstrometricRepeatability3.xValue: 3\\
atools.stellarAstrometricRepeatability3.process.calculateActions.rms.annulus:
200\\
\strut \\
We have thus demonstrated that the pipelines contain the code to
calculate AM3 once we have datasets that are sufficient for the purpose.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T1752 - Verify calculation of fraction of relative astrometric measurement error
on 200 arcminute scales exceeding outlier limit }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T1752}{\textit{ LVV-T1752 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the maximum
fraction of relative astrometric measurements on 200 arcminute scales
that exceed the 200 arcminute outlier limit \textbf{AD3 = 30
milliarcseconds}, and assess whether it meets the requirement that it
shall be less than \textbf{AF3 = 10 percent.}

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2024\_34 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T1752\_AF1\_AF2.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3735-1288458853:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3735-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and that has previously gone through Data Release
Processing, including calculation of data quality metrics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
For this test we use a recent reprocessing of the Subaru+HSC RC2
dataset. The data were processed with the w\_2024\_34 pipelines.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3735-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Retrieve the AF1 and AF2 metrics calculated for this dataset to
demonstrate that they have been measured and are well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
AF1 and AF2 metrics for the dataset.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we demonstrate the retrieval of these metrics.
The results are as follows:\\

\begin{verbatim}
Tract 9615:

g_AF1 = 0.06679791871747996 %
r_AF1 = 0.06546091100993683 %
i_AF1 = 0.519371635336687 %

g_AF2 = 0.056792018419033 %
r_AF2 = 0.04708780063749638 %
i_AF2 = 0.44838105038773934 %

Tract 9697:

g_AF1 = 1.9712959844317206 %
r_AF1 = 1.0932507987220448 %
i_AF1 = 0.07248196921310417 %

g_AF2 = 2.0060957760060614 %
r_AF2 = 1.081161689594751 %
i_AF2 = 0.05548913674036633 %

Tract 9813:

g_AF1 = 0.5892173229892959 %
r_AF1 = 1.425046176579239 %
i_AF1 = 1.2487806237632042 %

g_AF2 = 0.7005543674105357 %
r_AF2 = 1.3457338124427536 %
i_AF2 = 1.3252626295841194 %
\end{verbatim}

\hfill\break


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3735-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The same pipelines tasks that produce AF1 and AF2 can be reconfigured to
calculate the metric at any spatial scale. Demonstrate via inspection of
the relevant code that this is the case.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Code snippets that show the configurability of the size scale for AFx
metrics and the associated threshold ADx.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The
\href{https://github.com/lsst/analysis_tools/blob/2b45b7d01314f84ce12d05144fb9ae7110de62b8/python/lsst/analysis/tools/atools/astrometricRepeatability.py\#L209-L215}{task}
to calculate the AMx (i.e., AM1, AM2, AM3) metrics begins with the
following configuration options:\\
\strut \\
class AstrometricRelativeRepeatability(AnalysisTool):\\
"""Calculate the AMx, ADx, AFx metrics and make histograms showing the
data\\
used to compute the metrics.\\
"""\\
\strut \\
fluxType = Field{[}str{]}(doc="Flux type to calculate repeatability
with", default="psfFlux")\\
xValue = Field{[}int{]}(doc="Metric suffix corresponding to annulus size
(1, 2, or 3)", default=1)\\
\strut \\
The
\href{https://github.com/lsst/analysis_tools/blob/w.2024.34/pipelines/matchedVisitQualityCore.yaml}{pipeline}
that calls this task is where the annulus size for calculation is
specified. Here are the relevant lines from the pipeline YAML
configuration for AM1, AM2, and AM3:\\
\strut \\
atools.stellarAstrometricRepeatability1:
AstrometricRelativeRepeatability\\
atools.stellarAstrometricRepeatability1.xValue: 1\\
atools.stellarAstrometricRepeatability1.process.calculateActions.rms.annulus:
5\\
atools.stellarAstrometricRepeatability2:
AstrometricRelativeRepeatability\\
atools.stellarAstrometricRepeatability2.xValue: 2\\
atools.stellarAstrometricRepeatability2.process.calculateActions.rms.annulus:
20\\
atools.stellarAstrometricRepeatability3:
AstrometricRelativeRepeatability\\
atools.stellarAstrometricRepeatability3.xValue: 3\\
atools.stellarAstrometricRepeatability3.process.calculateActions.rms.annulus:
200\\
atools.stellarAstrometricRepeatability3.process.calculateActions.rms.threshAD:
30\\
\strut \\
Note the final line, which sets the "AD3" threshold to 30 mas for the
AF3 calculation. This configuration is by default set to 20 mas, the
required value for AD1 and AD2.\\
\strut \\
We have thus demonstrated that the pipelines contain the code to
calculate AF3, and apply its threshold AD3, once we have datasets that
are sufficient for the purpose.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T3073 - Verify implementation of L1 Data Product pixel embargo }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T3073}{\textit{ LVV-T3073 } }
test case in Jira.

Verify that Rubin Observatory pixel data is held in a secure location
and not released prior to~\textbf{L1CommissioningEmbargoT=30 days} after
data acquisition during the Commissioning phase.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\This test was executed at the USDF with science pipelines version
w\_2024\_43.



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3743-1290916404:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3743-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a butler repository in the "embargo rack (e.g., /repo/embargo)"
containing on-sky datasets that have been obtained within the past week.
Then execute a butler query similar the example code to identify
datasets.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A long list of datasets.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
We will query for "raw" exposures from recent ComCam on-sky imaging
(using "day\_obs \textgreater{} 20241022" to select images observed on
or after 22 Oct 2024).\\
\strut \\
butler query-datasets /repo/embargo raw -\/-where "detector IN (0..9)
AND instrument=\textquotesingle LSSTComCam\textquotesingle{} AND
day\_obs \textgreater{} 20241022" -\/-collections "*\textquotesingle{}
\textbar{} less\\
\strut \\
The first few lines of output look like the following:\\
type~ ~ ~ ~~run~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~id~ ~ ~ ~ ~ ~ ~ ~ ~~instrument
detector~ ~~exposure ~ ~~band~~day\_obs~ ~ ~ ~ ~ ~~group ~ ~ ~ ~
~~physical\_filter\\
-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
\strut ~raw LSSTComCam/raw/all 21a65a59-447c-51e2-8568-382e64b060a8
LSSTComCam~ ~ ~ ~~0 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all 27edf641-28f4-5fce-b631-103cf87a94b1
LSSTComCam~ ~ ~ ~~1 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all 627d5780-83ce-58eb-99d5-da4a5a9ae9e6
LSSTComCam~ ~ ~ ~~2 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all ef7f8d7d-7502-5fe5-affa-6e6b5f291534
LSSTComCam~ ~ ~ ~~3 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all f490fcb1-471b-5134-99db-e5328c26a916
LSSTComCam~ ~ ~ ~~4 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all d96d6efa-be1e-5cd5-91a8-f504ddd60bf2
LSSTComCam~ ~ ~ ~~5 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all ed9842a3-638d-5739-8aee-cd3dd5e979a7
LSSTComCam~ ~ ~ ~~6 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all e0ea2df1-b4d3-5b4f-8561-94bd6c69abaf
LSSTComCam~ ~ ~ ~~7 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all 154d1ba6-af36-5bef-a617-c8a06dba9609
LSSTComCam~ ~ ~ ~~8 2024102300001 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
\strut ~raw LSSTComCam/raw/all 5e2e8cbe-6693-52e6-9492-91474f65ae50
LSSTComCam~ ~ ~ ~~0 2024102300002 ~ ~ ~~r 20241023
~~BT220\_O\_20241023\_000001~ ~ ~ ~ ~ ~~r\_03\\
raw LSSTComCam/raw/all 9da0d4be-49ed-5f43-a074-bdc895235753 LSSTComCam 1
2024102300002 r 20241023 BT220\_O\_20241023\_000001 r\_03\\
\strut \\
To count the number of results, change the command to:\\
butler query-datasets /repo/embargo raw -\/-where "detector IN (0..9)
AND instrument=\textquotesingle LSSTComCam\textquotesingle{} AND
day\_obs \textgreater{} 20241022" -\/-collections "*" \textgreater{}
embargo\_query\_results.txt\\
\strut \\
Executing "wc embargo\_query\_results.txt" yields:\\
10498 104960 1616386 embargo\_query\_results.txt\\
\strut \\
Not counting the first two lines, which are header rows, the query has
returned 10496 raw images.\\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3743-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the same query against "/repo/main", which should only contain
data that are no longer under embargo. Observe that the query returns no
results.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
An empty query result, confirming that the datasets are not in the
public repository.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Execute the following query, which is identical to the one in the
previous step, but with "/repo/embargo" replaced with "/repo/main":\\
\strut \\
butler query-datasets /repo/main raw -\/-where "detector IN (0..9) AND
instrument=\textquotesingle LSSTComCam\textquotesingle{} AND day\_obs
\textgreater{} 20241022" -\/-collections "*" \textgreater{}
main\_query\_results.txt\\
\strut \\
wc main\_query\_results.txt\\
1 0 1 main\_query\_results.txt\\
\strut \\
The query returned no results, confirming that the images have not been
copied to the "public" repository "/repo/main." We have thus verified
that a system is in place to hold images until the embargo period has
passed.


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T191 - Verify implementation of Commissioning Cluster }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T191}{\textit{ LVV-T191 } }
test case in Jira.

Verify that the Commissioning Cluster has sufficient Compute/Storage/LAN
at the Base Facility to support Commissioning.

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\The cluster was moved to the summit facility from the base and is
currently in use in commissioning. There is no specification on what
should be installed but to provide a useful system, we have ensured that
the science pipelines are in stalled and condor as a batch system is
available. The verification submits a batch job to run step\#1 of
nightly validation on some early ComCam images

The batch submission was successful. Aspects of the processing failed
and were correctly reported by the batch system as failures.

This test does not test the processing, only the batch system on the
commissioning cluster



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E3750-1306416784:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The Rubin commissioning cluster is described in the "Computing
Infrastructure" technote at ittn-014.lsst.io under the section
\textquotesingle"Cerro Pachon". Yagan is the commissioning cluster, it
contains 20 nodes, 2200 cores + \textasciitilde7TB RAM

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Technote exists

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
ittn-014.lsst.io describes the ~commissioning cluster on Cerro Pachon


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Connect to openvpn~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Successful connection to openvpn

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Connect to commissioning cluster head node htcondor.cp.lsst.org

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Sucessfully connected


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-4 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Set up the LSST stack\\
\strut \\
source /project/stack/loadLSST.sh\\
setup lsst\_distrib\\
eups list -s \textbar{} grep lsst\_distrib

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Stack set up and a valid result returned, e.g.~\\
\textbf{\textgreater{} lsst\_distrib}~ ~ ~ ~ ~~gc7ba34d93f+b61867af9c ~
~ current w\_2024\_43 setup

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
(Weekly 43 set up\\
\strut \\
lsst-scipipe-9.0.0) {[}lguy@htcondor test\_LVV-T191{]}\$ eups list -s
\textbar{} grep lsst\_distrib\\
\textbf{lsst\_distrib}~ ~ ~ ~ ~~gc7ba34d93f+b61867af9c ~ ~ current
w\_2024\_43 setup\\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-5 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check condor is alive and well~\\
\textgreater{} condor\_status\\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Status returned

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
(lsst-scipipe-9.0.0) {[}lguy@htcondor test\_LVV-T191{]}\$
condor\_status\\
Name ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~OpSys~ ~ ~~Arch ~~State ~
~~Activity LoadAv Mem ~ ~~ActvtyTime\\
\strut \\
slot1@htcondor-worker-5b7cf78857-h5fwn LINUX~ ~ ~~X86\_64 Unclaimed
Idle~ ~ ~~0.000 515101~~8+21:44:52\\
slot1@htcondor-worker-5b7cf78857-wwblw LINUX~ ~ ~~X86\_64 Unclaimed
Idle~ ~ ~~0.000 515101~~8+21:44:51\\
slot1@htcondor-worker-5b7cf78857-zdfw4 LINUX~ ~ ~~X86\_64 Unclaimed
Idle~ ~ ~~0.000 515101~~8+21:45:08\\
\strut \\
\strut ~ ~ ~ ~ ~ ~ ~ ~Total Owner Claimed Unclaimed Matched
Preempting~~Drain Backfill BkIdle\\
\strut \\
\strut ~~X86\_64/LINUX ~ ~~3 ~ ~~0 ~ ~ ~~0 ~ ~ ~ ~~3 ~ ~ ~~0~ ~ ~ ~ ~~0~
~ ~~0~ ~ ~ ~~0~ ~ ~~0\\
\strut \\
Total 3 0 0 3 0 0 0 0 0


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-6 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Submit the bps batch job defined in
./scripts/test\_LVV-T191/LVV-T191.yaml~\\
with~\\
\strut \\
\textgreater{} bps submit LVV-T191.yaml~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
Job submitted and valid RunId and RubName returned\\
\strut \\
(lsst-scipipe-9.0.0) {[}lguy@htcondor test\_LVV-T191{]}\$ bps submit
LVV-T191.yaml\\
lsst.ctrl.bps.drivers INFO: DISCLAIMER: All values regarding memory
consumption reported below are approximate and may not accurately
reflect actual memory usage by the bps process.\\
lsst.ctrl.bps.drivers INFO: The workflow is submitted to the local Data
Facility.\\
lsst.ctrl.bps.drivers INFO: Starting submission process\\
lsst.ctrl.bps.drivers INFO: Initializing execution environment\\
Submit dir:
/home/lguy/repos/dmtr-412/scripts/test\_LVV-T191/submit/u/lguy/LVV-T191/20241029T010847Z\\
lsst.ctrl.bps.drivers INFO: Initializing execution environment
completed: Took 6.7785 seconds; current memory usage: 0.199 Gibyte,
delta: 0.012 Gibyte, peak delta: 0.017 Gibyte\\
lsst.ctrl.bps.drivers INFO: Peak memory usage for bps process 0.204
Gibyte (main), 0.000 Gibyte (largest child process)\\
lsst.ctrl.bps.drivers INFO: Starting acquire stage (generating and/or
reading quantum graph)\\
lsst.ctrl.bps.pre\_transform INFO: Creating quantum graph\\
lsst.ctrl.bps.pre\_transform INFO:
/project/stack/conda/envs/lsst-scipipe-9.0.0/share/eups/Linux64/ctrl\_mpexec/g3abcffb608+e4b6b84164/bin/pipetask
-\/-long-log -\/-log-level=VERBOSE qgra\\
ph -\/-butler-config /repo/LSSTComCam -i LSSTComCam/defaults -o
u/lguy/LVV-T191 -\/-output-run u/lguy/LVV-T191/20241029T010847Z
-\/-pipeline /project/stack/conda/envs/lsst-scipipe-9.0.0/s\\
hare/eups/Linux64/drp\_pipe/g406d2130e7+9fa41d294b/pipelines/LSSTComCam/nightly-validation.yaml\#step1
-\/-save-qgraph
/home/lguy/repos/dmtr-412/scripts/test\_LVV-T191/submit/u/lguy/LVV-\\
T191/20241029T010847Z/u\_lguy\_LVV-T191\_20241029T010847Z.qgraph
-\/-qgraph-datastore-records -d "exposure.day\_obs=20241027 and
instrument=\textquotesingle LSSTComCam\textquotesingle{} and
exposure.observation\_type IN (\\
\textquotesingle science\textquotesingle,
\textquotesingle acq\textquotesingle)"\\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:03.706+00:00
lsst.pipe.base.quantum\_graph\_builder
()(quantum\_graph\_builder.py:344) - Processing pipeline subgraph 1 of 1
with\\
5 task(s).\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:03.706+00:00
lsst.pipe.base.quantum\_graph\_builder
()(quantum\_graph\_builder.py:350) - Subgraph tasks: {[}isr,
characterizeIma\\
ge, calibrate, writePreSourceTable, transformPreSourceTable{]}\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:03.708+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:495) - Querying for data
IDs\\
with arguments:\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:03.708+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:496) -
dimensions={[}\textquotesingle band\textquotesingle,\\
\textquotesingle instrument\textquotesingle,
\textquotesingle day\_obs\textquotesingle,
\textquotesingle detector\textquotesingle,
\textquotesingle group\textquotesingle,
\textquotesingle physical\_filter\textquotesingle,
\textquotesingle exposure\textquotesingle,
\textquotesingle visit\textquotesingle{]},\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:03.709+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:497) -
dataId=\{\textquotesingle instrument\textquotesingle{}\\
: \textquotesingle LSSTComCam\textquotesingle\},\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:03.709+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:499) -
where="exposure.day\_\\
obs=20241027 and
instrument=\textquotesingle LSSTComCam\textquotesingle{} and
exposure.observation\_type IN (\textquotesingle science\textquotesingle,
\textquotesingle acq\textquotesingle)",\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:03.709+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:501) -
datasets={[}\textquotesingle raw\textquotesingle{]},\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:03.709+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:503) -
collections={[}\textquotesingle LSSTCo\\
mCam/raw/all\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/flat-i.20240926a\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/flat-r.20240926a\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/flat-g.2024\\
0926a\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/dark.20240926a\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/bias.20240926a\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/bfk.20240926a\textquotesingle,
\textquotesingle LSSTC\\
omCam/calib/DM-46360/isrTaskLSST/ptc.20240926a\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/linearizer.20240926a\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-46360/isrTaskLSST/defects.20240926a\textquotesingle,
\textquotesingle LSSTComCam\\
/calib/DM-45877\textquotesingle,
\textquotesingle LSSTComCam/calib/DM-45877/unbounded\textquotesingle,
\textquotesingle refcats\textquotesingle{]},\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:03.935+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:163) - Iterating over
query resu\\
lts to associate quanta with datasets.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:04.008+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:205) - Initial bipartite
graph h\\
as 810 quanta, 3900 dataset nodes, and 4860 edges from 162 query
row(s).\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.048+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:242) - Found 162
overall-inpu\\
t dataset(s) of type \textquotesingle raw\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.100+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type
\textquotesingle defects\textquotesingle{} to task
\textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.143+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type
\textquotesingle crosstalk\textquotesingle{} to task
\textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.185+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type \textquotesingle bias\textquotesingle{}
to task \textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.226+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type \textquotesingle dark\textquotesingle{}
to task \textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.289+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type
\textquotesingle camera\textquotesingle{} to task
\textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.371+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type \textquotesingle bfk\textquotesingle{}
to task \textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.412+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type \textquotesingle ptc\textquotesingle{}
to task \textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.473+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 162
prerequisite\\
input edge(s) from dataset type
\textquotesingle linearizer\textquotesingle{} to task
\textquotesingle isr\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.591+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 454
prerequisite\\
input edge(s) from dataset type
\textquotesingle the\_monster\_20240904\textquotesingle{} to task
\textquotesingle calibrate\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:04.685+00:00
lsst.pipe.base.quantum\_graph\_builder
()(all\_dimensions\_quantum\_graph\_builder.py:367) - Added 454
prerequisite\\
input edge(s) from dataset type
\textquotesingle the\_monster\_20240904\textquotesingle{} to task
\textquotesingle calibrate\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:04.755+00:00
lsst.pipe.base.quantum\_graph\_builder
()(quantum\_graph\_builder.py:572) - Generated 162 quanta for task
isr.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:04.785+00:00
lsst.pipe.base.quantum\_graph\_builder
()(quantum\_graph\_builder.py:572) - Generated 162 quanta for task
characteri\\
zeImage.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:04.837+00:00
lsst.pipe.base.quantum\_graph\_builder
()(quantum\_graph\_builder.py:572) - Generated 162 quanta for task
calibrate.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:04.858+00:00
lsst.pipe.base.quantum\_graph\_builder
()(quantum\_graph\_builder.py:572) - Generated 162 quanta for task
writePreSo\\
urceTable.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:04.879+00:00
lsst.pipe.base.quantum\_graph\_builder
()(quantum\_graph\_builder.py:572) - Generated 162 quanta for task
transformP\\
reSourceTable.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: INFO 2024-10-29T01:09:11.244+00:00
lsst.ctrl.mpexec.cmdLineFwk ()(cmdLineFwk.py:909) - QuantumGraph
contains 810 quanta for 5 tasks, graph ID: \textquotesingle173\\
0164151.1788852-957876\textquotesingle{}\\
Quanta Tasks\\
-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
162 isr\\
162 characterizeImage\\
162 calibrate\\
162 writePreSourceTable\\
162 transformPreSourceTable\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: VERBOSE 2024-10-29T01:09:11.244+00:00
lsst.ctrl.mpexec.cmdLineFwk ()(cmdLineFwk.py:694) - Writing QuantumGraph
to \textquotesingle/home/lguy/repos/dmtr-412/script\\
s/test\_LVV-T191/submit/u/lguy/LVV-T191/20241029T010847Z/u\_lguy\_LVV-T191\_20241029T010847Z.qgraph\textquotesingle.\\
\strut \\
lsst.ctrl.bps.pre\_transform INFO: Completed creating quantum graph:
Took 19.2857 seconds\\
lsst.ctrl.bps.pre\_transform INFO: Reading quantum graph from
\textquotesingle/home/lguy/repos/dmtr-412/scripts/test\_LVV-T191/submit/u/lguy/LVV-T191/20241029T010847Z/u\_lguy\_LVV-T191\_20241029T010847\\
Z.qgraph\textquotesingle{}\\
lsst.ctrl.bps.pre\_transform INFO: Completed reading quantum graph: Took
6.2427 seconds\\
lsst.ctrl.bps.drivers INFO: Acquire stage completed: Took 25.5348
seconds; current memory usage: 0.452 Gibyte, delta: 0.253 Gibyte, peak
delta: 0.247 Gibyte\\
lsst.ctrl.bps.drivers INFO: Peak memory usage for bps process 0.452
Gibyte (main), 0.482 Gibyte (largest child process)\\
lsst.ctrl.bps.drivers INFO: Starting cluster stage (grouping quanta into
jobs)\\
lsst.ctrl.bps.drivers INFO: Cluster stage completed: Took 0.0314
seconds; current memory usage: 0.452 Gibyte, delta: 0.000 Gibyte, peak
delta: 0.000 Gibyte\\
lsst.ctrl.bps.drivers INFO: Peak memory usage for bps process 0.452
Gibyte (main), 0.482 Gibyte (largest child process)\\
lsst.ctrl.bps.drivers INFO: ClusteredQuantumGraph contains 810
cluster(s)\\
lsst.ctrl.bps.drivers INFO: Starting transform stage (creating generic
workflow)\\
lsst.ctrl.bps.drivers INFO: Generic workflow name
\textquotesingle u\_lguy\_LVV-T191\_20241029T010847Z\textquotesingle{}\\
lsst.ctrl.bps.drivers INFO: Transform stage completed: Took 0.1669
seconds; current memory usage: 0.453 Gibyte, delta: 0.001 Gibyte, peak
delta: 0.001 Gibyte\\
lsst.ctrl.bps.drivers INFO: Peak memory usage for bps process 0.453
Gibyte (main), 0.482 Gibyte (largest child process)\\
lsst.ctrl.bps.drivers INFO: GenericWorkflow contains 812 job(s)
(including final)\\
lsst.ctrl.bps.drivers INFO: Starting prepare stage (creating specific
implementation of workflow)\\
lsst.ctrl.bps.htcondor.htcondor\_service INFO: Completed HTCondor
workflow creation: Took 0.0546 seconds\\
lsst.ctrl.bps.htcondor.htcondor\_service INFO: Completed writing out
HTCondor workflow: Took 0.8290 seconds\\
lsst.ctrl.bps.drivers INFO: Prepare stage completed: Took 0.8908
seconds; current memory usage: 0.457 Gibyte, delta: 0.004 Gibyte, peak
delta: 0.004 Gibyte\\
lsst.ctrl.bps.drivers INFO: Peak memory usage for bps process 0.457
Gibyte (main), 0.482 Gibyte (largest child process)\\
lsst.ctrl.bps.drivers INFO: Starting submit stage\\
lsst.ctrl.bps.submit INFO: Submitting run to a workflow management
system for execution\\
lsst.ctrl.bps.htcondor.htcondor\_service INFO: Submitting from
directory:
/home/lguy/repos/dmtr-412/scripts/test\_LVV-T191/submit/u/lguy/LVV-T191/20241029T010847Z\\
lsst.ctrl.bps.submit INFO: Completed submitting to a workflow management
system: Took 0.2570 seconds\\
lsst.ctrl.bps.drivers INFO: Run
\textquotesingle u\_lguy\_LVV-T191\_20241029T010847Z\textquotesingle{}
submitted for execution with id
\textquotesingle1873.0\textquotesingle{}\\
lsst.ctrl.bps.drivers INFO: Completed submit stage: Took 0.2633 seconds;
current memory usage: 0.458 Gibyte, delta: 0.001 Gibyte, peak delta:
0.001 Gibyte\\
lsst.ctrl.bps.drivers INFO: Completed entire submission process: Took
33.7108 seconds; current memory usage: 0.458 Gibyte, delta: 0.271
Gibyte, peak delta: 0.271 Gibyte\\
lsst.ctrl.bps.drivers INFO: Peak memory usage for bps process 0.458
Gibyte (main), 0.482 Gibyte (largest child process)\\
Run Id: 1873.0\\
Run Name: u\_lguy\_LVV-T191\_20241029T010847Z


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-7 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Get a report on the job status\\
\textgreater{} bps report -\/-id \textless id or path\textgreater{}\\
\strut \\
\strut \\

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Valid report returned

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
(lsst-scipipe-9.0.0) {[}lguy@htcondor test\_LVV-T191{]}\$ bps report
-\/-id 1873.0\\
X STATE \%S ID OPERATOR PROJECT CAMPAIGN PAYLOAD RUN\\
-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/- -\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
F RUNNING 4 1873.0 lguy LVV-T191 u\_lguy\_LVV-T191\_20241029T010847Z\\
\strut \\
\strut \\
Path:
/home/lguy/repos/dmtr-412/scripts/test\_LVV-T191/submit/u/lguy/LVV-T191/20241029T010847Z\\
Global job id: htcondor.cp.lsst.org\#1873.0\#1730164161\\
\strut \\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~UNKNOWN MISFIT UNREADY READY PENDING
RUNNING DELETED HELD SUCCEEDED FAILED PRUNED EXPECTED\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-\/-\\
TOTAL ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~0~ ~ ~~0~~ ~~634~~ ~~0~~ ~ ~~0~~ ~~139~~ ~
~~0~ ~~0~ ~ ~ ~~38~ ~ ~~1~ ~ ~~0~ ~ ~~812\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-~-\/-\/-\/-\/-\/-\/-\/-\\
pipetaskInit~ ~ ~ ~ ~ ~ ~ ~ ~~0~ ~ ~~0~~ ~ ~~0~~ ~~0~~ ~ ~~0~~ ~ ~~0~~ ~
~~0~ ~~0~~ ~ ~ ~~1~ ~ ~~0~ ~ ~~0~ ~ ~ ~~1\\
isr ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~0~ ~ ~~0~~ ~ ~~0~~ ~~0~~ ~ ~~0~~ ~~126~~ ~
~~0~ ~~0~ ~ ~ ~~36~ ~ ~~0~ ~ ~~0~ ~ ~~162\\
characterizeImage ~ ~ ~ ~ ~ ~~0~ ~ ~~0~~ ~~148~~ ~~0~~ ~ ~~0~ ~ ~~12~~ ~
~~0~ ~~0~~ ~ ~ ~~1~ ~ ~~1~ ~ ~~0~ ~ ~~162\\
calibrate ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~0~ ~ ~~0~~ ~~161~~ ~~0~~ ~ ~~0~~ ~ ~~1~~ ~
~~0~ ~~0~~ ~ ~ ~~0~ ~ ~~0~ ~ ~~0~ ~ ~~162\\
writePreSourceTable ~ ~ ~ ~ ~~0~ ~ ~~0~~ ~~162~~ ~~0~~ ~ ~~0~~ ~ ~~0~~ ~
~~0~ ~~0~~ ~ ~ ~~0~ ~ ~~0~ ~ ~~0~ ~ ~~162\\
transformPreSourceTable ~ ~ ~~0~ ~ ~~0~~ ~~162~~ ~~0~~ ~ ~~0~~ ~ ~~0~~ ~
~~0~ ~~0~~ ~ ~ ~~0~ ~ ~~0~ ~ ~~0~ ~ ~~162\\
\strut \\
\strut \\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-8 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
When the job is complete, inspect the full job report~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Valid job report accessible listing successes and failures

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
(lsst-scipipe-9.0.0) {[}lguy@htcondor test\_LVV-T191{]}\$ bps report
-\/-id 1873.0\\
X STATE \%S ID OPERATOR PROJECT CAMPAIGN PAYLOAD RUN\\
-\/-\/- -\/-\/-\/-\/-\/- -\/-\/- -\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
FAILED 63 1873.0 lguy LVV-T191 u\_lguy\_LVV-T191\_20241029T010847Z\\
\strut \\
\strut \\
Path:
/home/lguy/repos/dmtr-412/scripts/test\_LVV-T191/submit/u/lguy/LVV-T191/20241029T010847Z\\
Global job id: htcondor.cp.lsst.org\#1873.0\#1730164161\\
\strut \\
\strut \\
UNKNOWN MISFIT UNREADY READY PENDING RUNNING DELETED HELD SUCCEEDED
FAILED PRUNED EXPECTED\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\\
TOTAL 0 0 0 0 0 0 0 0 512 75 225 812\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-\/- -\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/- -\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\\
pipetaskInit 0 0 0 0 0 0 0 0 1 0 0 1\\
isr 0 0 0 0 0 0 0 0 162 0 0 162\\
characterizeImage 0 0 0 0 0 0 0 0 87 75 0 162\\
calibrate 0 0 0 0 0 0 0 0 87 0 75 162\\
writePreSourceTable 0 0 0 0 0 0 0 0 87 0 75 162\\
transformPreSourceTable 0 0 0 0 0 0 0 0 87 0 75 162\\
finalJob 0 0 0 0 0 0 0 0 1 0 0 1\\
\strut \\
\strut \\
This bps job completed successfully. The pipetaskInit and isr tasks were
successful but there were processing failures in characterizeImage and
onwards. This is a failure in processing, not the batch system . The
batch system correctly reported processing failures.\\
\strut \\
Inspect the detailed output in\\
\textgreater{} ls submit/u/lguy/LVV-T191/20241029T010847Z/jobs\\
\strut \\
In this case, the cause was no objects passing cuts for consideration as
psf stars.\\
\strut ~~File
"/project/stack/conda/envs/lsst-scipipe-9.0.0/share/eups/Linux64/meas\_algorithms/ga1f12eb575+e479d44c40/python/lsst/meas/algorithms/objectSizeStarSelector.py",
line 408, in selectSources\\
\strut ~ ~~raise RuntimeError("No objects passed our cuts for
consideration as psf stars")\\
RuntimeError: No objects passed our cuts for consideration as psf
stars\\
\strut \\


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E3750-9 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Inspect the data products and runs via the Butler

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
窶毅utler collections accessible

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
\textgreater{} butler query-collections /repo/LSSTComCam *lguy*\\
\strut \\
(lsst-scipipe-9.0.0) {[}lguy@htcondor jobs{]}\$ butler query-collections
/repo/LSSTComCam *LVV-T191*\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~Name ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~~Type~ ~\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
u/lguy/LVV-T191~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~CHAINED ~
~\\
\strut ~~u/lguy/LVV-T191/20241029T010847Z ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~RUN
~ ~ ~ ~\\
\strut ~~LSSTComCam/raw/all ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~RUN
~ ~ ~ ~\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/flat-i.20240926a ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/flat-r.20240926a ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/flat-g.20240926a ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/dark.20240926a ~ ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/bias.20240926a ~ ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/bfk.20240926a~ ~ ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/ptc.20240926a~ ~ ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/linearizer.20240926a
CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-46360/isrTaskLSST/defects.20240926a~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-45877~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~
~~CALIBRATION\\
\strut ~~LSSTComCam/calib/DM-45877/unbounded~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~RUN
~ ~ ~ ~\\
\strut ~~refcats~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~RUN
~ ~ ~ ~\\
u/lguy/LVV-T191/20241029T010847Z RUN\\
\strut \\
We see that data products clear\\
for the successful ISR task are available\\
\strut \\
\textgreater~(lsst-scipipe-9.0.0) {[}lguy@htcondor jobs{]}\$ butler
query-dataset-types /repo/LSSTComCam -\/-collections *LVV-T191*~\\
\strut ~ ~ ~ ~ ~ ~ ~~name ~ ~ ~ ~ ~ ~ ~\\
-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\\
\strut ~ ~ ~ ~ ~~atlas\_refcat2\_20220201\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~bfk\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~bias\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~calexp\\
\strut ~ ~ ~ ~ ~ ~ ~ ~~calexpBackground\\
\strut ~ ~ ~ ~ ~ ~calexpSummary\_metrics\\
\strut ~ ~ ~ ~ ~ ~ ~ ~~calibrate\_config\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~calibrate\_log\\
\strut ~ ~ ~ ~ ~ ~ ~~calibrate\_metadata\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~camera\\
\strut ~ ~ ~ ~~characterizeImage\_config\\
\strut ~ ~ ~ ~ ~ ~characterizeImage\_log\\
\strut ~ ~ ~~characterizeImage\_metadata\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~crosstalk\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~dark\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~defects\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~flat\\
\strut ~ ~ ~ ~ ~ ~ ~ ~gaia\_dr2\_20200414\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~icExp\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~icExpBackground\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~icSrc\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~icSrc\_schema\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~isrStatistics\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~isr\_config\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~isr\_log\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~isr\_metadata\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~linearizer\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~packages\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~postISRCCD\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~preSource\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~~preSourceTable\\
\strut ~ ~ ~ ~ ~ ~~ps1\_pv3\_3pi\_20170110\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ptc\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~raw\\
\strut ~ ~ ~ ~ ~ ~ ~ ~sdss\_dr9\_fink\_v5b\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~src\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~srcMatch\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~srcMatchFull\\
\strut ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~src\_schema\\
\strut ~ ~ ~ ~ ~ ~~the\_monster\_20240904\\
\strut ~~transformPreSourceTable\_config\\
\strut ~ ~ ~transformPreSourceTable\_log\\
transformPreSourceTable\_metadata\\
\strut ~ ~ ~ ~ ~ ~ ~transmission\_filter\\
\strut ~ ~ ~ ~ ~ ~ ~transmission\_optics\\
\strut ~ ~ ~ ~ ~ ~ ~transmission\_sensor\\
\strut ~ ~ ~~writePreSourceTable\_config\\
\strut ~ ~ ~ ~ ~writePreSourceTable\_log\\
writePreSourceTable\_metadata\\
\strut \\
\strut \\
\textgreater{} ~butler query-datasets /repo/LSSTComCam -\/-collections
*LVV-T191*


}
  % end if not not executed - no steps if not executed
\paragraph{ LVV-T3155 - Verify Engineering and Facility Database Availability }\mbox{}\\

Version \textbf{1.0(d)}.
Status \textbf{Approved}.
Open  \href{https://rubinobs.atlassian.net/projects/LVV?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page\#\!/v2/testCase/LVV-T3155}{\textit{ LVV-T3155 } }
test case in Jira.

Demonstrate Engineering and Facilities Data are available for public
access within~\textbf{L1PublicT (24 hours)}.~

\textbf{ Preconditions}:\\ None


Execution status: {\bf Pass }\\
Final comment:\\Test executed with science pipelines version w\_2025\_24 in the RSP
Notebook aspect at the USDF.\\
\strut \\
The executed notebook was saved in the repository associated with this
campaign's test report as ``notebooks/test\_LVV-T3155.ipynb."



% Note Steps "Not Executed" and with No Result are not shown in this report if the flag is passed
Detailed steps results LVV-R275-LVV-E4013-1650631565:\\
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E4013-1 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
\protect\phantomsection\label{isPasted}{Execute on-sky observing,
ingesting OCS commands, image headers, and transformed EFD quantities
into the Consolidated Database (ConsDB).~}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
The test was executed during observing with LSSTCam at Cerro Pachon.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E4013-2 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
\protect\phantomsection\label{isPasted}
{While observing is ongoing (or at least within \textbf{L1PublicT=24}
hours), access the ConsDB and confirm that the data products are
present.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
In the attached notebook, we have demonstrated that the ConsDB contains
information taken directly from image headers, transformed data from the
Engineering Facilities Database (EFD), and derived data based on image
processing. As required, these data include information about each
exposure, include the telescope and instrument configuration, telemetry
from the telescope, environmental and pointing information, and details
about the camera.\\
\strut \\
We have furthermore demonstrated that the ConsDB records are populated
well before the L1PublicT=24 hours requirement.


}
  {

\begin{tabular}{p{4cm}p{12cm}}
\toprule
Step LVV-E4013-3 & Step Execution Status: \textbf{ Pass } \\ \hline
\end{tabular}
 Description \\
{\footnotesize
\protect\phantomsection\label{isPasted}
{From the public access portal to the EFD (ConsDB), execute a query and
demonstrate that the data are publicly available.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
None

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
\protect\phantomsection\label{isPasted}
{A query at the public interface to the EFD successfully executes and
returns EFD data.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Actual Result \\
{\footnotesize
See the steps above, and the attached notebook. We have demonstrated
that ConsDB is populated in nearly real-time, and that it contains the
required telemetry and derived quantities.\\
\strut \\
While the ConsDB accessed via TAP service is not yet publicly available,
this test was performed with the architecture and access mechanisms that
will be available to users in DP2, and thus demonstrates that the
capability is in place.


}
  % end if not not executed - no steps if not executed
  %end of the if with theo test_items in testcycles_map[cyclie.id]


\input{appendix.tex}
\end{document}
