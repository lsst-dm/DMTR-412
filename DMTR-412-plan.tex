% generated from JIRA project LVV
% using template at /Users/womullan/anaconda3/envs/docsteady-env/lib/python3.7/site-packages/docsteady/templates/tpnoresult.latex.jinja2.
% using docsteady version 2.4
% Please do not edit -- update information in Jira instead
\documentclass[DM,lsstdraft,STR,toc]{lsstdoc}
\usepackage{geometry}
\usepackage{longtable,booktabs}
\usepackage{enumitem}
\usepackage{arydshln}
\usepackage{attachfile}
\usepackage{array}
\usepackage{dashrule}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}

\input meta.tex

\newcommand{\attachmentsUrl}{https://github.com/\gitorg/\lsstDocType-\lsstDocNum/blob/\gitref/attachments}
\providecommand{\tightlist}{
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\setcounter{tocdepth}{4}

\begin{document}

\def\milestoneName{LDM-503-19a (All P1a DM requirements verified)}
\def\milestoneId{}
\def\product{Acceptance}

\setDocCompact{true}

\title{LVV-P117: LDM-503-19a (All P1a DM requirements verified) Test Plan }
\setDocRef{\lsstDocType-\lsstDocNum}
\date{ 2024-08-12 }
\author{ Jeffrey Carlin }

\input{history_and_info.tex}


\setDocAbstract{
This is the test plan for
\textbf{ LDM-503-19a (All P1a DM requirements verified)},
an LSST milestone pertaining to the Data Management Subsystem.\\
This document is based on content automatically extracted from the Jira test database on \docDate.
The most recent change to the document repository was on \vcsDate.
}


\maketitle

\section{Introduction}
\label{sect:intro}


\subsection{Objectives}
\label{sect:objectives}

 This DM acceptance test campaign will verify all DM priority 1a
requirements that have not been verified as part of prior testing and
milestones.



\subsection{System Overview}
\label{sect:systemoverview}

 This test campaign is intended to verify that the DM system satisfies
all of the priority 1a requirements outlined in the Data Management
System Requirements (DMSR; \href{https://lse-61.lsst.io/}{LSE-61} ),
ensuring that we are progressing toward readiness for the installation
and operation of LSSTCam. Additional DMSR requirements (priorities 1b,
2, and 3) will be verified in later Acceptance Test
Campaigns.\\[2\baselineskip]\textbf{Applicable Documents:}\\
\citeds{LSE-61}: Data Management System (DMS) Requirements\\
\citeds{LDM-503} Data Management Test Plan\\
\citeds{LDM-639}: Data Management Acceptance Test
Specification\\[2\baselineskip]Tests in this campaign will use data
products and artifacts from Data Preview 0.2, which consists of DESC
Data Challenge 2 (DC2) simulated data reprocessed using the LSST Science
Pipelines, on-sky data from auxTel imaging campaigns, precursor data
from Subaru+HyperSuprime-Cam (HSC), and camera test-stand data, when
appropriate.


\subsection{Document Overview}
\label{sect:docoverview}

This document was generated from Jira, obtaining the relevant information from the
\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testPlan/LVV-P117}{LVV-P117}
~Jira Test Plan and related Test Cycles (
\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCycle/LVV-C275}{LVV-C275}
).

Section \ref{sect:intro} provides an overview of the test campaign, the system under test (\product{}),
the applicable documentation, and explains how this document is organized.
Section \ref{sect:testplan} provides additional information about the test plan, like for example the configuration
used for this test or related documentation.
Section \ref{sect:personnel} describes the necessary roles and lists the individuals assigned to them.

Section \ref{sect:overview} provides a summary of the test results, including an overview in Table \ref{table:summary},
an overall assessment statement and suggestions for possible improvements.
Section \ref{sect:detailedtestresults} provides detailed results for each step in each test case.

The current status of test plan \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testPlan/LVV-P117}{LVV-P117} in Jira is \textbf{ Draft }.

\subsection{References}
\label{sect:references}
\renewcommand{\refname}{}
\bibliography{lsst,refs,books,refs_ads,local}


\newpage
\section{Test Plan Details}
\label{sect:testplan}


\subsection{Data Collection}

  Observing is not required for this test campaign.

\subsection{Verification Environment}
\label{sect:hwconf}
  Most testing will be performed using the Rubin Science Platform (RSP)
and the development cluster at the USDF. All tests will use the most
recent available version of the Pipelines.




\subsection{Related Documentation}



\subsection{PMCS Activity}

Primavera milestones related to the test campaign:
\begin{itemize}
\item None
\end{itemize}


\newpage
\section{Personnel}
\label{sect:personnel}

The personnel involved in the test campaign is shown in the following table.

{\small
\begin{longtable}{p{3cm}p{3cm}p{3cm}p{6cm}}
\hline
\multicolumn{2}{r}{T. Plan \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testPlan/LVV-P117}{LVV-P117} owner:} &
\multicolumn{2}{l}{\textbf{ Jeffrey Carlin } }\\\hline
\multicolumn{2}{r}{T. Cycle \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCycle/LVV-C275}{LVV-C275} owner:} &
\multicolumn{2}{l}{\textbf{
Jeffrey Carlin }
} \\\hline
\textbf{Test Cases} & \textbf{Assigned to} & \textbf{Executed by} & \textbf{Additional Test Personnel} \\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T83}{LVV-T83}
& {\small Jim Bosch } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T85}{LVV-T85}
& {\small Robert Lupton } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2303}{LVV-T2303}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T33}{LVV-T33}
& {\small Kian-Tat Lim } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T38}{LVV-T38}
& {\small Eric Bellm } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T103}{LVV-T103}
& {\small Kian-Tat Lim } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T45}{LVV-T45}
& {\small Eric Bellm } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T47}{LVV-T47}
& {\small Eric Bellm } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T153}{LVV-T153}
& {\small Robert Gruendl } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T88}{LVV-T88}
& {\small Eli Rykoff } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T89}{LVV-T89}
& {\small Eli Rykoff } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T148}{LVV-T148}
& {\small Colin Slater } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1097}{LVV-T1097}
& {\small Jeff Kantor } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small Ron Lambert (Rubin Observatory), Kian-Tat Lim (Rubin Observatory), Matt
Kollross (NCSA), Tony Johnson (SLAC), Gregg Thayer (SLAC) }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2338}{LVV-T2338}
& {\small Wil O'Mullane } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small William O Mullane }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1168}{LVV-T1168}
& {\small Jeff Kantor } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small Ron Lambert (LSST), Albert Astudillo (REUNA), Mauricio Rojas
(CTIO/CISS), Raylex, Coriant, Telefonica contractors }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1612}{LVV-T1612}
& {\small Jeff Kantor } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small Ron Lambert (LSST), Greg Thayer (SLAC) }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T189}{LVV-T189}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T197}{LVV-T197}
& {\small Robert Gruendl } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T198}{LVV-T198}
& {\small Robert Gruendl } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T34}{LVV-T34}
& {\small Kian-Tat Lim } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T48}{LVV-T48}
& {\small Jim Bosch } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1862}{LVV-T1862}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T115}{LVV-T115}
& {\small Kian-Tat Lim } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1935}{LVV-T1935}
& {\small Robert Gruendl } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1987}{LVV-T1987}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T98}{LVV-T98}
& {\small Kian-Tat Lim } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1986}{LVV-T1986}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2693}{LVV-T2693}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2699}{LVV-T2699}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T154}{LVV-T154}
& {\small Colin Slater } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T287}{LVV-T287}
& {\small Michelle Butler [X] } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T191}{LVV-T191}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1250}{LVV-T1250}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1251}{LVV-T1251}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1847}{LVV-T1847}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T377}{LVV-T377}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1846}{LVV-T1846}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1843}{LVV-T1843}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1757}{LVV-T1757}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1842}{LVV-T1842}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1841}{LVV-T1841}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1840}{LVV-T1840}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1839}{LVV-T1839}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1838}{LVV-T1838}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1837}{LVV-T1837}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1836}{LVV-T1836}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2202}{LVV-T2202}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1746}{LVV-T1746}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1749}{LVV-T1749}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1750}{LVV-T1750}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1751}{LVV-T1751}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1752}{LVV-T1752}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1753}{LVV-T1753}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1831}{LVV-T1831}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2329}{LVV-T2329}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T129}{LVV-T129}
& {\small Jeffrey Carlin } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T30}{LVV-T30}
& {\small Kian-Tat Lim } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T29}{LVV-T29}
& {\small Kian-Tat Lim } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2297}{LVV-T2297}
& {\small Leanne Guy } & {\small  } &
\begin{minipage}[]{6cm}
\smallskip
{\small  }
\medskip
\end{minipage}
\\ \hline
\end{longtable}
}

\newpage

\section{Test Campaign Overview}
\label{sect:overview}

\subsection{Summary}
\label{sect:summarytable}

{\small
\begin{longtable}{p{2cm}cp{2.3cm}p{8.6cm}p{2.3cm}}
\toprule
\multicolumn{2}{r}{ T. Plan \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testPlan/LVV-P117}{LVV-P117}:} &
\multicolumn{2}{p{10.9cm}}{\textbf{ LDM-503-19a (All P1a DM requirements verified) }} & Draft \\\hline
\multicolumn{2}{r}{ T. Cycle \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCycle/LVV-C275}{LVV-C275}:} &
\multicolumn{2}{p{10.9cm}}{\textbf{ LDM-503-19a (All P1a DM requirements verified) }} & Not Executed \\\hline
\textbf{Test Cases} &  \textbf{Ver.}  \\\toprule
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T83}{LVV-T83}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T85}{LVV-T85}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2303}{LVV-T2303}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T33}{LVV-T33}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T38}{LVV-T38}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T103}{LVV-T103}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T45}{LVV-T45}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T47}{LVV-T47}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T153}{LVV-T153}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T88}{LVV-T88}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T89}{LVV-T89}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T148}{LVV-T148}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1097}{LVV-T1097}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2338}{LVV-T2338}
&  2
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1168}{LVV-T1168}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1612}{LVV-T1612}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T189}{LVV-T189}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T197}{LVV-T197}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T198}{LVV-T198}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T34}{LVV-T34}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T48}{LVV-T48}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1862}{LVV-T1862}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T115}{LVV-T115}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1935}{LVV-T1935}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1987}{LVV-T1987}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T98}{LVV-T98}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1986}{LVV-T1986}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2693}{LVV-T2693}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2699}{LVV-T2699}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T154}{LVV-T154}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T287}{LVV-T287}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T191}{LVV-T191}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1250}{LVV-T1250}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1251}{LVV-T1251}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1847}{LVV-T1847}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T377}{LVV-T377}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1846}{LVV-T1846}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1843}{LVV-T1843}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1757}{LVV-T1757}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1842}{LVV-T1842}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1841}{LVV-T1841}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1840}{LVV-T1840}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1839}{LVV-T1839}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1838}{LVV-T1838}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1837}{LVV-T1837}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1836}{LVV-T1836}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2202}{LVV-T2202}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1746}{LVV-T1746}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1749}{LVV-T1749}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1750}{LVV-T1750}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1751}{LVV-T1751}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1752}{LVV-T1752}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1753}{LVV-T1753}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1831}{LVV-T1831}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2329}{LVV-T2329}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T129}{LVV-T129}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T30}{LVV-T30}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T29}{LVV-T29}
&  1
\\
\href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2297}{LVV-T2297}
&  1
\\
\\\hline
\caption{Test Campaign Summary}
\label{table:summary}
\end{longtable}
}

\subsection{Overall Assessment}
\label{sect:overallassessment}

Not yet available.

\subsection{Recommended Improvements}
\label{sect:recommendations}

\newpage
\section{Detailed Tests}
\label{sect:detailedtests}

\subsection{Test Cycle LVV-C275 }

Open test cycle {\it \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testrun/LVV-C275}{LDM-503-19a (All P1a DM requirements verified)}} in Jira.

Test Cycle name: LDM-503-19a (All P1a DM requirements verified)\\
Status: Not Executed

Test campaign supporting milestone LDM-503-19a -- all P1a requirements
verified.

\subsubsection{Software Version/Baseline}
Not provided.

\subsubsection{Configuration}
Not provided.

\subsubsection{Test Cases in LVV-C275 Test Cycle}

\paragraph{ LVV-T83 - Verify implementation of Bad Pixel Map }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T83}{\textit{ LVV-T83 } }
test case in Jira.

Verify that the DMS can produce a map of detector pixels that suffer
from pathologies, and that these pathologies are encoded in at least
32-bit values.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Interrogate the calibRegistry for the metadata associated with a bad
pixel map, where the validity range contains the date of interest.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A bad pixel map for the requested date has been returned.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check that the bad pixel pathologies are encoded as at least 32-bit
values, and that the various pathologies are represented by different
encoding.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Bad pixel values can be decoded to determine their pathologies using
their 32-bit values.

}

\paragraph{ LVV-T85 - Verify implementation of Crosstalk Correction Matrix }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T85}{\textit{ LVV-T85 } }
test case in Jira.

Verify that the DMS can generate a cross-talk correction matrix from
appropriate calibration data.\\
Verify that the DMS can measure the effectiveness of the cross-talk
correction matrix.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify an appropriate calibration dataset that can be used to derive
the crosstalk correction matrix.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the crosstalk correction matrix is produced and persisted.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A correction matrix quantifying what fraction of the signal detected in
any given amplifier on each sensor in the focal plane appears in any
other amplifier.

}

\begin{tabular}{p{2cm}}
\toprule
Step 5  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Apply the crosstalk correction to simulated images, and confirm that the
correction is performing as expected.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A noticeable difference between images before and after applying the
correction.

}

\paragraph{ LVV-T2303 - Verify Image Archive }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2303}{\textit{ LVV-T2303 } }
test case in Jira.

Verify that all image Data Products produced by the DMS (Processed
Science Exposures, Calibration Exposures, Coadded Exposures) are either
archived, or be capable of being recreated on-demand from inputs and
processing provenance.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T33 - Verify implementation of Raw Science Image Metadata }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T33}{\textit{ LVV-T33 } }
test case in Jira.

Verify successful ingestion of raw data and that image metadata is
present and queryable.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify (or gather) a dataset of raw science images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that time of exposure start/end, site metadata, telescope
metadata, and camera metadata are stored in DMS
system.\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Raw image data contain the required metadata.

}

\paragraph{ LVV-T38 - Verify implementation of Processed Visit Images }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T38}{\textit{ LVV-T38 } }
test case in Jira.

Verify that the DMS\\
1. Successfully produces Processed Visit Images, where the instrument
signature has been removed.\\
2. Successfully combines images obtained during a standard
visit.\\[2\baselineskip]The verification should include confirming that
the images have been trimmed of the overscan, and that correction of the
instrumental signature (including crosstalk) has been applied properly.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify suitable precursor datasets containing unprocessed raw images.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
`DATA/path', then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
\begin{verbatim}
from lsst.daf.butler import Butler
repo = 'Data/path'
collection = 'collection'
butler = Butler(repo, collections=collection)
\end{verbatim}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Run the initial steps (including instrument signature removal and
calibration) of Data Release (or Prompt) Processing on these data.
Verify that Processed Visit Images are generated at the correct size and
with significant instrumental artifacts removed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Raw precursor dataset images have been processed into Processed Visit
Images, with instrumental artifacts corrected.

}

\paragraph{ LVV-T103 - Verify implementation of Generate Data Quality Report Within Specified
Time }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T103}{\textit{ LVV-T103 } }
test case in Jira.

Verify that the DMS can generate a nightly L1 Data Quality Report within
\textbf{dqReportComplTime = 4{[}hour{]}}, in both human- and
machine-readable formats.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute single-day operations rehearsal

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
After \textbf{dqReportComplTime = 4{[}hour{]}~}has passed, confirm (via
timestamps) that the data quality report has been generated within
\textbf{dqReportComplTime = 4{[}hour{]},} and that it contains the
correct contents.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Both human- and machine-readable versions of the L1 Data Quality Report
are available with dqReportComplTime.

}

\paragraph{ LVV-T45 - Verify implementation of Prompt Processing Data Quality Report
Definition }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T45}{\textit{ LVV-T45 } }
test case in Jira.

Verify that the DMS produces a Prompt Processing Data Quality Report.
~Specifically check absolute value and temporal variation of\\
1. Photometric zeropoint\\
2. Sky brightness\\
3. Seeing\\
4. PSF\\
5. Detection efficiency

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest raw data from L1 Test Stand DAQ.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Perform the steps of Alert Production (including, but not necessarily
limited to, single frame processing, ISR, source detection/measurement,
PSF estimation, photometric and astrometric calibration, difference
imaging, DIASource detection/measurement, source association). During
Operations, it is presumed that these are automated for a given
dataset.~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
An output dataset including difference images and DIASource and
DIAObject measurements.

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that the expected data products have been produced, and that
catalogs contain reasonable values for measured quantities of interest.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Load the Prompt Processing QC reports, and observe that a dynamically
updated Data Quality Report has become available at the relevant UI.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A Prompt Processing QC report is available via a UI, and contains
information about the photometric zeropoint, sky brightness, seeing,
PSF, and detection efficiency, and possibly other relevant quantities.

}

\begin{tabular}{p{2cm}}
\toprule
Step 5  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check that a static report is created and archived in a
readily-accessible location.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Persistence of a static QC report in an accessible location, containing
the same information as in the report from Step 3.

}

\paragraph{ LVV-T47 - Verify implementation of Prompt Processing Calibration Report Definition }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T47}{\textit{ LVV-T47 } }
test case in Jira.

Verify that the DMS produces a Prompt Processing Calibration Report.
~Specifically check that this report is capable of identifying when
aspects of the telescope or camera are changing with time.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify precursor and simulated calibration datasets on which to run
the L1 calibration pipeline.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Daily Calibration Products Update payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check that a dynamic report is created that triggers alerts if
calibrations go out of range.~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dynamic report is available via UI to users, and if any out-of-spec
changes have occurred, alerts have been issued.

}

\begin{tabular}{p{2cm}}
\toprule
Step 5  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check that a static report is created and archived in a
readily-accessible location.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
An archived version of the calibration report is available and will be
retained in a static file format.

}

\paragraph{ LVV-T153 - Verify implementation of Provide Engineering and Facility Database
Archive }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T153}{\textit{ LVV-T153 } }
test case in Jira.

Demonstrate Engineering and Facilities Data (images, associated
metadata, and observatory environment and control data) are archived and
available for public access within \textbf{L1PublicT (24 hours)}.~

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute a single-day operations rehearsal, ingesting (simulated) OCS
commands into the EFD.~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Wait at least \textbf{L1PublicT=24} hours, then access the archived EFD.
Confirm that the data products are present in the archived EFD
after~\textbf{L1PublicT=24} hours have elapsed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The EFD contains the simulated OCS commands, and they were ingested
within~\textbf{L1PublicT=24} hours of the operations rehearsal.

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
From the public access portal to the EFD, execute a query and
demonstrate that the data are publicly available.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A query at the public interface to the EFD successfully executes and
returns EFD data.

}

\paragraph{ LVV-T88 - Verify implementation of Calibration Data Products }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T88}{\textit{ LVV-T88 } }
test case in Jira.

Verify that the DMS can produce and archive the required Calibration
Data Products: cross talk correction, bias, dark, monochromatic dome
flats, broad-band flats, fringe correction, and illumination
corrections.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a suitable set of calibration frames, including biases, dark
frames, and flat-field frames.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected data products are created, and that they have
the expected properties.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A full set of calibration data products has been created, and they are
well-formed.

}

\begin{tabular}{p{2cm}}
\toprule
Step 5  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test that the calibration products are archived, and can readily be
applied to science data to produce the desired corrections.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Confirmation that application of the calibration products to processed
data has the desired effects.

}

\paragraph{ LVV-T89 - Verify implementation of Calibration Image Provenance }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T89}{\textit{ LVV-T89 } }
test case in Jira.

Verify that the DMS records the required provenance information for the
Calibration Data Products.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest an appropriate precursor calibration dataset into a Butler repo.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Load the relevant database/Butler data product, and observe that all
provenance information has been retained.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset consisting of calibration images, with provenance information
recorded and properly associated with the calibration images.

}

\paragraph{ LVV-T148 - Verify implementation of Unique Processing Coverage }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T148}{\textit{ LVV-T148 } }
test case in Jira.

Verify that a user-specified criterion can be used to process each
record in a table exactly once.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute representative processing, observe lack of duplicates or missing
rows even in the presence of failures

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1097 - Verify Summit Facility Network Implementation }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1097}{\textit{ LVV-T1097 } }
test case in Jira.

Verify that data acquired by a AuxTel DAQ can be transferred to Summit
DWDM and loaded in the EFD without problems.

\textbf{ Preconditions}:\\
\begin{enumerate}
\tightlist
\item
  Summit Control Network and Camera Data Backbone installed and
  operating properly.
\item
  Summit - Base Network installed and operating properly.
\item
  EITHER: AuxTel hardware and control systems are functional with
  LATISS. AuxTel TCS, AuxTel EFD, AuxTel CCS, AuxTel DAQ are connected
  via Control Network on Summit to Rubin Observatory DWDM (with at least
  2 x 10 Gbps ethernet port client cards) OR: high-quality DAQ
  application-level simulators that match the form, volume, file paths,
  compressibility, and cadence of the expected instrument data, running
  on end node computers that are the production hardware or equivalent
  to it. Scientific validity of the data content is not essential.
\item
  AuxTel Archiver/forwarders installed in Summit and operating properly
  running on end node computers that are the production hardware or
  equivalent to it.
\item
  As-built documentation for all of the above is available.
\end{enumerate}

NOTE: This test will be repeated at increasing data volumes as
additional observatory capabilities (e.g. ComCAM, LSSTCam) become
available. ~Final verification will be tested at full operational
volume. After the initial test, the corresponding verification elements
will be flagged as ``Requires Monitoring'' such that those requirements
will be closed out as having been verified but will continue to be
monitored throughout commissioning to ensure they do not drop out of
compliance. ~This will also be monitored for end to end Summit - Data
Facility transfers during Commissioning.

Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify the pre-conditions have been satisfied

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
NA

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Pre-conditions are satisfied.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Control the AuxTel through a night of Observing. ~While observing, read
out LATISS data and transfer to Rubin Observatory Summit DWDM while
monitoring latency.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
LATISS images and metadata

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Data is fed to DWDM without delays or errors.

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that data acquired by a AuxTel DAQ can be transferred ~and loaded
in EFD without problems.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
LATISS images and metadata

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Examine the EFD to ensure that the data has been loaded properly.

}

\paragraph{ LVV-T2338 - Replicated telemetry data agrees with telemetry produced at the summit }\mbox{}\\

Version \textbf{2}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2338}{\textit{ LVV-T2338 } }
test case in Jira.

Show that telemetry data can be accessed from the replicated EFD.
~Further, show that the values in the replicated database agree with the
values in the summit EFD over a specified time range and set of
topics.\\[2\baselineskip]This test case provides partial coverage of the
requirement DMS-REQ-0168, Summit Facility Data Communications: "The DMS
shall provide data communications infrastructure to accept science data
and associated metadata read-outs, and \textbf{the collection of
ancillary and engineering data}, for transfer to the base facility.", as
adapted to the current design for EFD replication (see
\href{https://dmtn-082.lsst.io}{DMTN-082}).

\textbf{ Preconditions}:\\
See prerequisites in the Test Plan LVV-P90

Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T2114}{~LVV-T2114
(2.0)~} Prepare to analyze EFD at USDF\\[2\baselineskip]Using
tunnelblick or your equivalent VPN with summit access log on to
https://summit-lsp.lsst.codes/nb\\[2\baselineskip]Create a new notebook
and connect to the efd at the summit and USDF.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
from lsst\_efd\_client import EfdClient,
resample\\[2\baselineskip]client = EfdClient('summit\_efd')\\
client.output = `dataframe'\\
cl=client.influx\_client\\[3\baselineskip]usdf\_client =
EfdClient('usdf\_efd')\\
usdf\_client.output = `dataframe'\\
usdf\_cl=usdf\_client.influx\_client

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
RSP on summit open with Conneciton to USDF\_efd and summit\_efd

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Choose 5 topics to query and select a 6 day window of data. The window
is arbitrary, but must be explicit (not relative to now()) so that it
can be reproduced. The topics should be chosen to sample the various
topic contexts. I.e. the topics should be chosen to sample both
diagnostic topics like heartbeat monitors as well as both high and low
cadence telemetry topics to get a broad view on how the system behaves
with different kinds of topics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A list of 5 valid SAL topics to be queried and a time window defined as
astropy.Time objects.

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Issue selections at both the summit and the data facility. These
selections should select all fields for the chosen topics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A total of 10 pandas.DataFrame objects, 5 each for the summit and
replicated EFDs. ~Each topic requires a separate query, so each will get
its own DataFrame. ~All fields in each topic should be selected.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
First compare the index for each topic between the summit and replicated
EFD. ~There should be:\\

\begin{enumerate}
\tightlist
\item
  The same number of samples in each topic for each location
\item
  Given 1) each time stamp should represent the same time
\end{enumerate}

Reliability of the replication must be at better than 99\%. If there are
samples missing from the replicated datasets, confirm that the length of
the replicated DataFrame divided by the length of the summit DataFrame
is greater than 0.99 for all topics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A cell in the notebook showing the DataFrames are the same length per
topic between the summit and the replicated EFD. ~A cell showing the
times in the index are the same for each topic. ~This could be done by
converting to seconds and showing the difference is zero for every
sample.\\[2\baselineskip]If there are missing samples, the replication
should be better than 99\%. ~If it is not, the deviation must be traced
to an intervening event or system other than the replication system
itself to explain the discrepancy.

}

\begin{tabular}{p{2cm}}
\toprule
Step 5  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Compare the fields for each topic between the summit and the replicated
EFDs. ~They should be equivalent to double precision. ~This can be done
by looping over the topics and fields and showing numpy.all (or similar)
evaluates to True.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A cell or cells showing that all fields for all topics evaluate as
equivalent given appropriate precision.

}

\begin{tabular}{p{2cm}}
\toprule
Step 6  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Examine the summit messages to confirm that the reliability is better
than 99.9\% for all topics. ~Keep in mind that the private\_seqNum is
intended to be a sequentially increasing index of the messages, but that
it gets reset after every CSC reboot. ~This must be accounted for by
applying an offset when a reset is observed.\\
Show the reliability is better than 99.9\% by showing that the
private\_seqNum is sequential better than 99.9\% of the time (when
correcte for resets).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A histogram or similar showing that the difference
private\_seqNum{[}1:{]} - private\_seqnum{[}:-1{]} is 1 more than 99.9\%
of the time.

}

\begin{tabular}{p{2cm}}
\toprule
Step 7  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Document the procedure including topics chosen, time window, replication
reliability and EFD reliability

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
\begin{itemize}
\tightlist
\item
  A document describing the process including topics and time window.
\item
  The document shall be in the form of a notebook with saved outputs, or
  similar
\end{itemize}

}

\paragraph{ LVV-T1168 - Verify Summit - Base Network Integration }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1168}{\textit{ LVV-T1168 } }
test case in Jira.

Verify the integration of the summit to base network by demonstrating a
sustained and uninterrupted transfer of data between summit and base
over 1 day period at or exceeding rates specified in \citeds{LDM-142}. Done in 3
phases in collaboration with equipment/installation vendors (see test
procedure).

\textbf{ Preconditions}:\\
PMCS DMTC-7400-2330 COMPLETE\\
By phase:

\begin{enumerate}
\tightlist
\item
  Posts from Cerro Pachon to AURA Gatehouse repaired/improved. ~Fiber
  installed on posts from Cerro Pachon to AURA Gatehouse. ~Fiber
  installed from AURA Gatehouse to AURA compound in La Serena. OTDR
  purchased.
\item
  AURA DWDM installed in caseta on Cerro Pachon and in existing computer
  room in La Serena. ~DTN installed in La Serena. ~DTN loaded with
  software and test data staged.
\item
  Base Data Center (BDC) ready for installation of LSST DWDM. ~Fiber
  connecting existing computer room to BDC. ~LSST DWDM equipment
  installed in Summit Computer Room and BDC.
\end{enumerate}

Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test optical fiber with OTDR:\\
Installation of fiber optic cables and Optical Time Domain Reflector
(OTDR) fiber testing (completed 20170602
\href{https://docushare.lsstcorp.org/docushare/dsweb/Get/Document-26270/RD10\%20Report\%20of\%20delivery\%20of\%20LS\%20-\%20AG\%20fiber\%20from\%20Telefonica\%20to\%20REUNA.pdf}{REUNA
deliverable RD10})

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
OTDR generated optical data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Fiber tested to within acceptable Db.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test AURA DWDM:\\
Installation of AURA DWDM and Data Transfer Node (DTN) (completed
20171218
\href{https://docushare.lsst.org/docushare/dsweb/Get/DMTR-82/DMTR-82.pdf}{DMTR-82})

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
DTN perfSonar generated data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Summit - Base bandwidth and latency within specifications

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test LSST DWDM:\\
Installation of LSST DWDM and Bit Error Rate Tester (BERT) data
(completed 20190505
\href{https://docushare.lsstcorp.org/docushare/dsweb/View/Collection-7743}{collection-7743},
20191108
\href{https://docushare.lsstcorp.org/docushare/dsweb/Get/Document-35302/DAQ\%20DWDM\%20connection\%20tests\%2020191109.pptx}{DAQ
DWDM Connection Tests})

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
BERT generated data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Summit - Base bandwidth, latency, bit error rate within specifications

}

\paragraph{ LVV-T1612 - Verify Summit - Base Network Integration (System Level) }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1612}{\textit{ LVV-T1612 } }
test case in Jira.

Verify ISO Layer 3 full (22 x 10 Gbps ethernet ports on DAQ side with
test data from DAQ test stand, AURA, Camera DAQ team do test).
Demonstrate transfer of data at or exceeding rates specified in \citeds{LDM-142}.

\textbf{ Preconditions}:\\
\begin{enumerate}
\tightlist
\item
  PMCS DMTC-7400-2400 COMPLETE
\item
  \href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/1401}{LVV-T1168}
  Passed
\item
  EITHER: Full Camera DAQ installed on summit and loaded with data OR:
  high-quality DAQ application-level simulators that match the form,
  volume, file paths, compressibility, and cadence of the expected
  instrument data, running on end node computers that are the production
  hardware or equivalent to it. Scientific validity of the data content
  is not essential.
\item
  Archiver/forwarders installed at Base running on end node computers
  that are the production hardware or equivalent to it.
\item
  As-built documentation for all of the above is available.
\end{enumerate}

NOTE: This test will be repeated at increasing data volumes as
additional observatory capabilities (e.g. ComCAM, FullCam) become
available. Final verification will be tested at full operational
volume.After the initial test, the corresponding verification elements
will be flagged as ``Requires Monitoring'' such that those requirements
will be closed out as having been verified but will continue to be
monitored throughout commissioning to ensure they do not drop out of
compliance. This will also be monitored for end to end Summit - Data
Facility transfers during Commissioning.

Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify Pre-conditions are satisfied.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
NA

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Pre-conditions are satisfied.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Transfer data between summit and base over uninterrupted 1 day period.
~Monitor transfer of data at or exceeding rates specified in LDM-142.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
DAQ pre-loaded data

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Data transfers at or exceeding rates specified in LDM-142.

}

\paragraph{ LVV-T189 - Verify implementation of Base Facility Infrastructure }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T189}{\textit{ LVV-T189 } }
test case in Jira.

Verify that the (a) planned infrastructure and (b) as-built
infrastructure for the Base Facility satisfies the needs for data
transfer and buffering, a copy of the Archive Facility, and support for
Commissioning.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Analyze design and sizing model

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T197 - Verify implementation of Archive Center }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T197}{\textit{ LVV-T197 } }
test case in Jira.

Verify that the Archive Center is sufficiently provisioned to support
prompt processing, DRP, and data access needs.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Analyze design and sizing model

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T198 - Verify implementation of Archive Center Disaster Recovery }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T198}{\textit{ LVV-T198 } }
test case in Jira.

Verify disaster recovery plan for Archive Center.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Analyze design; simulate storage failure, observe restore from disaster
recovery

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T34 - Verify implementation of Guider Calibration Data Acquisition }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T34}{\textit{ LVV-T34 } }
test case in Jira.

{Verify successful}\\
{~1. Ingestion of calibration frames from L1 Test Stand DAQ}\\
{~2. Execution of CPP payloads}\\
{~3. Availability of observed guider calibration products}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
{Ingest calibration frames for the guider sensors from L1 Test Stand
DAQ}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Observe that guider calibration products have been produced.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Well-formed calibration frames for the guider sensors.

}

\paragraph{ LVV-T48 - Verify implementation of Exposure Catalog }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T48}{\textit{ LVV-T48 } }
test case in Jira.

Verify that the DMS creates an Exposure Catalog that includes\\
1. Observation datetime, exposure time\\
2. Filter\\
3. Dome, telescope orientation and status\\
4. Calibration status\\
5. Airmass and zenith\\
6. Environmental information\\
7. Per-sensor information

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Verify that Exposure Catalogs contain the required elements. At present,
the form of the exposure catalog is not defined. This information can be
found for a given Butler repo from the metadata, but will ultimately be
aggregated into a database/table summarizing available exposures.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A list of the required metadata for a set of exposures is returned and
both human- and machine-readable.

}

\paragraph{ LVV-T1862 - Verify determining effectiveness of dark current frame }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1862}{\textit{ LVV-T1862 } }
test case in Jira.

Verify that the DMS can determine the effectiveness of a dark correction
and determine how often it should be updated.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to a dataset containing dark frames (i.e., exposures
taken with the shutter closed).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Determining whether the dark correction is being done properly will
require on-sky science data. The dark correction can be applied to these
frames and the results inspected to ensure that the correction was
correctly measured and applied.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Applying the dark correction to a dataset produces noticeable
differences between the original frame(s) and the corrected outputs.

}

\paragraph{ LVV-T115 - Verify implementation of Calibration Production Processing }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T115}{\textit{ LVV-T115 } }
test case in Jira.

Execute CPP on a variety of representative cadences, and verify that the
calibration pipeline correctly produces necessary calibration products.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a suitable set of calibration frames, including biases, dark
frames, and flat-field frames.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the Calibration Products Production payload. The payload uses
raw calibration images and information from the Transformed EFD to
generate a subset of Master Calibration Images and Calibration Database
entries in the Data Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected Master Calibration images and Calibration
Database entries are present and well-formed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the expected data products are created, and that they have
the expected properties.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Repos containing valid calibration products that are well-formed and
ready to be applied to processed datasets.

}

\paragraph{ LVV-T1935 - Demonstrate ComCam Data Processing Capability }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1935}{\textit{ LVV-T1935 } }
test case in Jira.

To process raw ComCam data and demonstrate that the results are
available either in the shared DM development environment/repository or
in the RSP.

\textbf{ Preconditions}:\\
ComCam data acquisition and ingest are nominal. ~(LVV-T1934)

Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Obtain BIAS and FLAT sequences (minimum of 3 exposures each)

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
Acquired from ComCam Archiver.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Data acquired, ingested, and available in shared work space.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Process BIAS frames

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
From Step 1

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
\begin{verbatim}
# setup a current LSST stack, currently:
/software/lsstsw/stack3/loadLSST.bash
setup -v lsst_distrib

setenv REPODIR=/project/shared/comCam
setenv VER_DIR={verification_dir}

constructBias.py $REPODIR --rerun $VER_DIR \
    --id expId=2020070800001^2020070800002^2020070800003 --batch-type none -c isr.doCrosstalk=False -j 9

ingestCalibs.py $REPODIR $REPODIR/rerun/$VER_DIR/bias/*/*.fits --validity 9999 --mode=link --calib $REPODIR/CALIB
\end{verbatim}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Successful execution of BIAS reduction software (currently~

\begin{verbatim}
constructBias.py and ingestion)
\end{verbatim}

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Process FLAT frames

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
From Step 1 (and step 2)

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
\begin{verbatim}
# setup a current LSST stack, currently:
/software/lsstsw/stack3/loadLSST.bash
setup -v lsst_distrib

setenv REPODIR=/project/shared/comCam
setenv VER_DIR={verification_dir}
\end{verbatim}

\begin{verbatim}
constructFlat.py $REPODIR --rerun $VER_DIR \
    --id expId=2020070100152..2020070100154 filter=r --batch-type none -j 9 -c isr.doCrosstalk=False
\end{verbatim}

\begin{verbatim}
ingestCalibs.py $REPODIR $REPODIR/rerun/$VER_DIR/flat/*/*.fits \
    --validity 9999 --mode=link --calib $REPODIR/CALIB
\end{verbatim}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Successful execution of FLAT reduction software (currently
constructFlat.py and ingestion)

}

\paragraph{ LVV-T1987 - Run Calibration Products Processing (CPP) }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1987}{\textit{ LVV-T1987 } }
test case in Jira.

Demonstrate that basic calibration processing from Gen2 era has been
enabled within Gen3 environment. ~ This test is not concerned with large
scales but merely demonstrates that Gen3 capability to generate
calibration products (i.e. they are no longer required to be generated
in Gen2 and then migrated to Gen3).

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify an existing or instantiate a new Gen3 repository with raw bias,
dark, and flat observations.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Test Data \\
 {\footnotesize
It is preferred these data be early observatory products (i.e. either
AuxTel/LATISS or ComCam).

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A Gen3 repo with appropriate raw data products.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Create master bias, dark and flat products from the raw products.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A master bias, dark, and flat calibration product.\\[2\baselineskip]

}

\paragraph{ LVV-T98 - Verify implementation of Selection of Datasets }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T98}{\textit{ LVV-T98 } }
test case in Jira.

Verify that the DMS can identify and retrieve datasets consisting of
logical groupings of Exposures, metadata, provenance, etc., or other
groupings that are processed or produced as a logical unit.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
`DATA/path', then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
\begin{verbatim}
from lsst.daf.butler import Butler
repo = 'Data/path'
collection = 'collection'
butler = Butler(repo, collections=collection)
\end{verbatim}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest data from an appropriate processed dataset.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Observe retrieval of single Processed Visit Image (PVI) with metadata.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A PVI and its associated metadata.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Observe retrieval of multiple PVIs with metadata.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A set of PVIs and their associated metadata.

}

\begin{tabular}{p{2cm}}
\toprule
Step 5  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Observe retrieval of coadd patch with metadata and provenance
information.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
An image of coadded data in a patch, along with its metadata and
information describing the provenance of the patch constituents.

}

\begin{tabular}{p{2cm}}
\toprule
Step 6  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Observe retrieval of subset of rows in each of the above catalogs.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1986 - Mini DC2 processing capability }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1986}{\textit{ LVV-T1986 } }
test case in Jira.

Demonstrate that a typical 3-tract DC2 data processing is possible using
the Gen3 system and the nascent Batch Production Service (BPS). ~This
test is meant to
extend~\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T1983}{LVV-T1983}
(Mini RC2 processing capability) by demonstrating Gen3 + BPS systems are
capable of supporting future Data Previews (which have been specified to
use the DC2 image sim data rather than HSC data). ~

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T2693 - Verify implementation of Image Provenance Access }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2693}{\textit{ LVV-T2693 } }
test case in Jira.

Verify that available image data products' provenance information can be
listed and retrieved.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T2699 - Verify implementation of Catalog Provenance Access }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2699}{\textit{ LVV-T2699 } }
test case in Jira.

Verify that available catalog data products' provenance can be listed
and retrieved.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T154 - Verify implementation of Raw Data Archiving Reliability }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T154}{\textit{ LVV-T154 } }
test case in Jira.

Verify that raw images are reliably archived.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Analyze sources of loss or corruption after mitigation to compute
estimated reliability

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T287 - RAS-00-30: Raw Image Archiving Availability, Throughput, Reliability,
and Heterogeneity }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T287}{\textit{ LVV-T287 } }
test case in Jira.

This test will check:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  Raw Image Archiving meets availability requirements;
\item
  Raw Image Archiving meets throughput requirements;
\item
  Raw Image Archiving meets reliability requirements;
\item
  Raw Image Archiving meets heterogeneity requirements;
\end{itemize}

This test case need to be completed when more information is available.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
these will be filled out as the service becomes more known as to what
the availablility, throughput, reliability and heterogeneity are.
~\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The archive system will stay up through thick and thin and perform like
it's suppose to.\\[2\baselineskip]

}

\paragraph{ LVV-T191 - Verify implementation of Commissioning Cluster }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T191}{\textit{ LVV-T191 } }
test case in Jira.

Verify that the Commissioning Cluster has sufficient Compute/Storage/LAN
at the Base Facility to support Commissioning.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Analyze design and budget

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1250 - Verify implementation of minimum number of simultaneous DM EFD query
users }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1250}{\textit{ LVV-T1250 } }
test case in Jira.

Verify that the DM EFD can support \textbf{dmEfdQueryUsers~= 5}
simultaneous queries. The additional requirement that each query must
last no more than \textbf{dmEfdQueryTime = 10 seconds~}will be verified
separately in
\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T1251}{LVV-T1251},
but these must be satisfied together.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Send multiple (at least 5) simultaneous queries to the DM EFD.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that (a) the queries executed successfully, and that (b) they
return reasonable results.~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Repeat the above steps for different queries, and different numbers of
simultaneous queries, to confirm that the expected performance is met
regardless of the query being executed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1251 - Verify implementation of maximum time to retrieve DM EFD query results }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1251}{\textit{ LVV-T1251 } }
test case in Jira.

Verify that the DM EFD can support \textbf{dmEfdQueryUsers~= 5}
simultaneous queries, with each query must executing in no more than
\textbf{dmEfdQueryTime = 10 seconds.~}The requirement on at least 5
simultaneous queries will be verified separately in
\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T1250}{LVV-T1250},\href{https://jira.lsstcorp.org/secure/Tests.jspa\#/testCase/LVV-T1251}{}
but these must be satisfied together.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Send multiple (at least 5) simultaneous queries to the DM EFD.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that (a) the queries executed successfully, and that (b) they
return reasonable results. Check that the time of execution for all
queries was less than 10 seconds.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Repeat the above steps for different queries, and different numbers of
simultaneous queries, to confirm that the expected performance is met
regardless of the query being executed.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1847 - Verify calculation of sensor fraction with unusable pixels }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1847}{\textit{ LVV-T1847 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum allowable fraction of sensors with \textbf{PixFrac
\textgreater{} 1} percent scientifically unusable pixels is less
than~\textbf{SensorFraction = 15 percent.}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T377 - Verify Calculation of Photometric Performance Metrics }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T377}{\textit{ LVV-T377 } }
test case in Jira.

Verify that the DMS system provides software to calculate photometric
performance metrics, and that the algorithms are properly calculating
the desired quantities. Note that because the DMS requirement is that
the software shall be provided (and not on the actual measured values of
the metrics), we verify all of the requirements via a single test case.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
`DATA/path', then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
\begin{verbatim}
from lsst.daf.butler import Butler
repo = 'Data/path'
collection = 'collection'
butler = Butler(repo, collections=collection)
\end{verbatim}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Point the butler to a simulated dataset containing data in all filters,
that is sufficient for the purposes of measuring photometric performance
metrics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute the LSST Stack package `validate\_drp` (or an alternate package
that is relevant) on this dataset to perform the measurements of the
metrics.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Measurements of validation metrics and the presence of QA plots
resulting from the validation pipeline.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Compare measured photometry to known values from input simulated data,
and confirm that the output values for all of the photometric
performance metrics are as expected.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Measured astrometry metrics that are within reasonable values given the
(known) input dataset.

}

\paragraph{ LVV-T1846 - Verify calculation of band-to-band color zero-point accuracy including
u-band }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1846}{\textit{ LVV-T1846 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
accuracy of absolute band-to-band color zero-points for all colors
constructed from any filter pair, including the u-band, is less than
\textbf{PA5u = 10 millimagnitudes}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1843 - Verify calculation of significance of imperfect crosstalk corrections }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1843}{\textit{ LVV-T1843 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum local significance integrated over the PSF of imperfect
crosstalk corrections is less than \textbf{Xtalk = 3 sigma}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1757 - Verify calculation of photometric repeatability in gri filters }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1757}{\textit{ LVV-T1757 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the RMS
photometric repeatability of bright non-saturated unresolved point
sources in the g, r, and i filters, and assess whether it meets the
requirement that it shall be less than \textbf{PA1gri = 5.0
millimagnitudes}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field in each of the g, r,
and i filters with multiple overlapping visits.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric PA1gri has been calculated, and that its values
are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that PA1gri has been calculated.

}

\paragraph{ LVV-T1842 - Verify calculation of zeropoint error fraction exceeding the outlier
limit }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1842}{\textit{ LVV-T1842 } }
test case in Jira.

Verify that the DM system provides software to calculate the fraction of
zeropoint errors that exceed the zero point error outlier limit, and
confirm that it is less than \textbf{PF2 = 10 percent.}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1841 - Verify calculation of scientifically unusable pixel fraction }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1841}{\textit{ LVV-T1841 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum fraction of pixels scientifically unusable per sensor out of the
total allowable fraction of sensors meeting this performance is less
than~\textbf{PixFrac = 1 percent}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1840 - Verify calculation of sky brightness precision }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1840}{\textit{ LVV-T1840 } }
test case in Jira.

Verify that the DM system provides software to assess whether the
maximum error in the precision of the sky brightness determination is
less than \textbf{SBPrec = 1 percent.}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1839 - Verify calculation of RMS width of photometric zeropoint }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1839}{\textit{ LVV-T1839 } }
test case in Jira.

Verify that the DM system provides code to assess whether the RMS width
of the internal photometric zero-point (precision of system uniformity
across the sky) for all bands except u-band is less than \textbf{PA3 =
10 millimagnitudes}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1838 - Verify calculation of image fraction affected by ghosts }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1838}{\textit{ LVV-T1838 } }
test case in Jira.

Verify that the DM system provides code to assess whether the percentage
of image area that has ghosts with surface brightness gradient amplitude
of more than 1/3 of the sky noise over 1 arcsec is less than
\textbf{GhostAF = 1 percent}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1837 - Verify calculation of band-to-band color zero-point accuracy }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1837}{\textit{ LVV-T1837 } }
test case in Jira.

Verify that the DM system provides code to assess whether the accuracy
of absolute band-to-band color zero-points for all colors constructed
from any filter pair, excluding the u-band, is less than \textbf{PA5 = 5
millimagnitudes}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T1836 - Verify calculation of resolved-to-unresolved flux ratio errors }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1836}{\textit{ LVV-T1836 } }
test case in Jira.

Verify that the DM system has provided code to assess whether the
maximum RMS of the ratio of the error in integrated flux measurement
between bright, isolated, resolved sources less than 10 arcsec in
diameter and bright, isolated unresolved point sources is less than
\textbf{ResSource = 2}.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T2202 - Verify that the of zero-point error outlier limit threshold (PA4) can be
applied. }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2202}{\textit{ LVV-T2202 } }
test case in Jira.

Verify that the DMS has provided the code to apply the zero-point error
outlier limit threshold (PA4) to computed values of metrics.~

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Inspect the PF2 pipeline code to see if the PA4 threshold has been
specified.~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
\begin{verbatim}
config.measure.threshPA4 = 15.0
\end{verbatim}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The PA4 threshold is specified as part of the PA4 pipeline

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the PA4 threshold was applied to the assessment of the
computed metric PF2

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The dataset ~has been ingested into a Gen3 Butler repository and is
accessible

}

\paragraph{ LVV-T1746 - Verify calculation of fraction of relative astrometric measurement error
on 5 arcminute scales exceeding outlier limit }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1746}{\textit{ LVV-T1746 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the maximum
fraction of relative astrometric measurements on 5 arcminute scales that
exceed the 5 arcminute outlier limit \textbf{AD1 = 20 milliarcseconds},
and assess whether it meets the requirement that it shall be less than
\textbf{AF1 = 10 percent.}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster (``lsst-dev''):
  /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

From the command line, execute the commands below in the example
code:\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
source `path`\\
setup lsst\_distrib

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, `obs' packages such as `obs\_subaru`), then
additional `setup` commands will be necessary.\\[2\baselineskip]To check
versions in use, type:\\
eups list -s

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AF1 has been calculated using the outlier limit
AD1, and that its values are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AF1 has been calculated (and used the limit AD1).

}

\paragraph{ LVV-T1749 - Verify calculation of fraction of relative astrometric measurement error
on 20 arcminute scales exceeding outlier limit }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1749}{\textit{ LVV-T1749 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the maximum
fraction of relative astrometric measurements on 20 arcminute scales
that exceed the 20 arcminute outlier limit \textbf{AD2 = 20
milliarcseconds}, and assess whether it meets the requirement that it
shall be less than \textbf{AF2 = 10 percent.}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster (``lsst-dev''):
  /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

From the command line, execute the commands below in the example
code:\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
source `path`\\
setup lsst\_distrib

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, `obs' packages such as `obs\_subaru`), then
additional `setup` commands will be necessary.\\[2\baselineskip]To check
versions in use, type:\\
eups list -s

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AF2 has been calculated using the outlier limit
AD2, and that its values are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AF2 has been calculated (and used the limit AD2).

}

\paragraph{ LVV-T1750 - Verify calculation of separations relative to r-band exceeding color
difference outlier limit }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1750}{\textit{ LVV-T1750 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the
separations measured relative to the r-band that exceed the color
difference outlier limit \textbf{AB2 = 20 milliarcseconds}, and assess
whether it meets the requirement that it shall be less than \textbf{ABF1
= 10 percent.~}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and including at least one visit in r-band.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster (``lsst-dev''):
  /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

From the command line, execute the commands below in the example
code:\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
source `path`\\
setup lsst\_distrib

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, `obs' packages such as `obs\_subaru`), then
additional `setup` commands will be necessary.\\[2\baselineskip]To check
versions in use, type:\\
eups list -s

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric ABF1 has been calculated using the outlier limit
AB2, and that its values are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that ABF1 has been calculated (and used the limit AB2).

}

\paragraph{ LVV-T1751 - Verify calculation of median relative astrometric measurement error on
200 arcminute scales }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1751}{\textit{ LVV-T1751 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the median
relative astrometric measurement error on 200 arcminute scales and
assess whether it meets the requirement that it shall be no more than
AM3 = 15 milliarcseconds.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and that covers an area larger than 200 arcminutes.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster (``lsst-dev''):
  /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

From the command line, execute the commands below in the example
code:\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
source `path`\\
setup lsst\_distrib

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, `obs' packages such as `obs\_subaru`), then
additional `setup` commands will be necessary.\\[2\baselineskip]To check
versions in use, type:\\
eups list -s

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AM3 has been calculated, and that its values are
reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AM3 has been calculated.

}

\paragraph{ LVV-T1752 - Verify calculation of fraction of relative astrometric measurement error
on 200 arcminute scales exceeding outlier limit }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1752}{\textit{ LVV-T1752 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the maximum
fraction of relative astrometric measurements on 200 arcminute scales
that exceed the 200 arcminute outlier limit \textbf{AD3 = 30
milliarcseconds}, and assess whether it meets the requirement that it
shall be less than \textbf{AF3 = 10 percent.}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and that covers an area larger than 200 arcminutes.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster (``lsst-dev''):
  /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

From the command line, execute the commands below in the example
code:\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
source `path`\\
setup lsst\_distrib

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, `obs' packages such as `obs\_subaru`), then
additional `setup` commands will be necessary.\\[2\baselineskip]To check
versions in use, type:\\
eups list -s

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AF3 has been calculated using the outlier limit
AD3, and that its values are reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AF3 has been calculated (and used the limit AD3).

}

\paragraph{ LVV-T1753 - Verify calculation of RMS difference of separations relative to r-band }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1753}{\textit{ LVV-T1753 } }
test case in Jira.

Verify that the DM system has provided the code to calculate the
separations measured relative to the r-band, and assess whether it meets
the requirement that it shall be less than \textbf{AB1 =
10~milliarcseconds.}

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify a dataset containing at least one field with multiple
overlapping visits, and including at least one visit in r-band.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A dataset that has been ingested into a Butler repository.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
The `path` that you will use depends on where you are running the
science pipelines. Options:\\[2\baselineskip]

\begin{itemize}
\tightlist
\item
  local (newinstall.sh - based
  install):{[}path\_to\_installation{]}/loadLSST.bash
\item
  development cluster (``lsst-dev''):
  /software/lsstsw/stack/loadLSST.bash
\item
  LSP Notebook aspect (from a terminal):
  /opt/lsst/software/stack/loadLSST.bash
\end{itemize}

From the command line, execute the commands below in the example
code:\\[2\baselineskip]

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
source `path`\\
setup lsst\_distrib

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Science pipeline software is available for use. If additional packages
are needed (for example, `obs' packages such as `obs\_subaru`), then
additional `setup` commands will be necessary.\\[2\baselineskip]To check
versions in use, type:\\
eups list -s

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Execute `faro` on a repository containing processed data. Identify the
path to the data, which we will call `DATA/path', then execute something
similar to the following (with paths, datasets, and flags replaced or
additionally specified as needed):

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
pipetask --long-log run -j 2 -b DATA/path/butler.yaml
--register-dataset-types -p \$FARO\_DIR/pipelines/metrics\_pipeline.yaml
-d ``band in ('g', `r', `i') AND tract=9813 AND skymap='hsc\_rings\_v1'
AND instrument='HSC''' --output u/username/faro\_metrics -i
HSC/runs/RC2/w\_2021\_06 2\textgreater{}\&1 \textbar{} tee
w06\_2021\_tract9813\_faro.txt

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
The output collection (in this case, ``u/username/faro\_metrics'')
containing metric measurements and any associated extras and metadata is
available via the butler.

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that the metric AB1 has been calculated, and that its values are
reasonable.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
A JSON file (and/or a report generated from that JSON file)
demonstrating that AB1 has been calculated.

}

\paragraph{ LVV-T1831 - Verify Implementation of Data Management Nightly Reporting }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T1831}{\textit{ LVV-T1831 } }
test case in Jira.

Verify that the LSST Data Management subsystem produces a searchable -
interactive nightly report(s), from information published in the EFD by
each subsystem, summarizing performance and behavior over a user defined
period of time (e.g. the previous 24 hours).

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T2329 - Verify the archiving of ancilliary data }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2329}{\textit{ LVV-T2329 } }
test case in Jira.

Verufy that the Science Data Archive ~contains all necessary engineering
and calibration data for the full understanding of the performance and
operation of the Observatory.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\paragraph{ LVV-T129 - Verify implementation of Provide Calibrated Photometry }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T129}{\textit{ LVV-T129 } }
test case in Jira.

Verify that the DMS provides photometry calibrated in AB mags and fluxes
(in nJy) for all measured objects and sources. Must be tested for both
DRP and AP products.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Identify the path to the data repository, which we will refer to as
`DATA/path', then execute the following:

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Example Code \\
{\footnotesize
\begin{verbatim}
from lsst.daf.butler import Butler
repo = 'Data/path'
collection = 'collection'
butler = Butler(repo, collections=collection)
\end{verbatim}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Butler repo available for reading.

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest the data products from an appropriate DRP-processed dataset.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that AB-calibrated magnitudes and fluxes are available for all
measured Sources and Objects. {[}An enhanced verification could include
matching the sources to an external source catalog and comparing the
magnitudes to show that they are well-calibrated.{]}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Calibrated fluxes and magnitudes are available for all sources, as well
as tools to convert measured fluxes to magnitudes (and vice-versa).

}

\begin{tabular}{p{2cm}}
\toprule
Step 4  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Ingest the data products from an appropriate AP processing dataset.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 5  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Confirm that AB-calibrated magnitudes and fluxes are available for all
measured Sources, DIASources, and Objects. {[}An enhanced verification
could include matching the sources to an external source catalog and
comparing the magnitudes to show that they are well-calibrated.{]}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Calibrated fluxes and magnitudes are available for all Sources,
DIASources, and Objects, as well as tools to convert measured fluxes to
magnitudes (and vice-versa).

}

\paragraph{ LVV-T30 - Verify implementation of Wavefront Sensor Data Acquisition }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T30}{\textit{ LVV-T30 } }
test case in Jira.

Verify successful ingestion of wavefront sensor data from L1 Test Stand
DAQ while simulating all modes.

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
{Ingest wavefront sensor data from L1 Test Stand DAQ while simulating
all modes}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Observe wavefront sensor data and metadata archived in the Data
Backbone.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Well-formed wavefront sensor image data with appropriate associated
metadata.

}

\paragraph{ LVV-T29 - Verify implementation of Raw Science Image Data Acquisition }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T29}{\textit{ LVV-T29 } }
test case in Jira.

Verify acquisition of raw data from L1 Test Stand DAQ while simulating
all modes

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
{Ingest raw data from L1 Test Stand DAQ, simulating each observing
mode\\
}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
O{bserve image and its metadata is present and queryable in the Data
Backbone.}

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize
Well-formed image data with appropriate associated metadata.

}

\paragraph{ LVV-T2297 - Verify implementation of Science Data Archive }\mbox{}\\

Version \textbf{1}.
Open  \href{https://jira.lsstcorp.org/secure/Tests.jspa#/testCase/LVV-T2297}{\textit{ LVV-T2297 } }
test case in Jira.

Verify that a Science Data Archive has been created ~and that all LSST
public data products have been archived together with the raw data
necessary to reproduce them. ~Verify that the archive is scalable to the
data from the full survey and all Data Releases.\\[2\baselineskip]This
requirement will be verified by analysis. Verification must demonstrate
that we have a a written plan for how data will be archived and that the
storage systems needed exist. The plan should include details on
recovery. ~This is needed before commissioning to support commissioning
data taking.~

\textbf{ Preconditions}:\\


Final comment:\\


Detailed steps :

\begin{tabular}{p{2cm}}
\toprule
Step 1  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Check that all LSST public data products have been archived at the
Science Data Archive

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 2  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test that the the public data products can be reproduced from the raw
data stored at the archive.

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}

\begin{tabular}{p{2cm}}
\toprule
Step 3  \\ \hline
\end{tabular}
 Description \\
{\footnotesize
Test that the archive is scalable to the full survy data volume.~

}
\hdashrule[0.5ex]{\textwidth}{1pt}{3mm}
  Expected Result \\
{\footnotesize

}



\input{appendix.tex}
\end{document}
